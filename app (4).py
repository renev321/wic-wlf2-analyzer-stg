import streamlit as st
import pandas as pd
import numpy as np
import json
import plotly.express as px

st.set_page_config(page_title="WIC_WLF2 Analizador", layout="wide")

def _best_group_for_categorical(df: pd.DataFrame, col: str, min_trades: int):
    if col not in df.columns:
        return None
    rows = []
    for g, sub in df.groupby(col):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        rows.append((g, n, exp, pf, score))
    if not rows:
        return None
    rows.sort(key=lambda x: (x[4], x[1]), reverse=True)
    g, n, exp, pf, score = rows[0]
    return {"grupo": g, "n": n, "exp": exp, "pf": pf, "score": score}


def _best_range_for_numeric(df: pd.DataFrame, col: str, q: int, min_trades: int):
    if col not in df.columns:
        return None
    s = pd.to_numeric(df[col], errors="coerce")
    if s.notna().sum() < max(15, min_trades * 2):
        return None
    try:
        cuts = pd.qcut(s, q=q, duplicates="drop")
    except Exception:
        return None

    tmp = df.copy()
    tmp["_r"] = cuts.astype(str)

    best = None
    for g, sub in tmp.groupby("_r"):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        cand = {"rango": str(g), "n": n, "exp": exp, "pf": pf, "score": score}
        if (best is None) or (cand["score"] > best["score"]):
            best = cand
    if best is None:
        return None

    # Intentar extraer l√≠mites num√©ricos del rango "(a, b]"
    lo = hi = None
    rg = best["rango"].strip()
    if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
        inner = rg[1:-1]
        parts = inner.split(",")
        if len(parts) == 2:
            try:
                lo = float(parts[0])
                hi = float(parts[1])
            except Exception:
                lo = hi = None
    best["lo"] = lo
    best["hi"] = hi
    return best


def recommend_settings_block(known_df: pd.DataFrame, min_trades: int, recommended_trades: int):
    """
    Resume recomendaciones 'tipo NinjaTrader' basadas en lo que rinde mejor en ESTA muestra.
    No inventa campos: solo usa lo que existe en el JSON.
    """
    if known_df is None or known_df.empty:
        st.info("No hay suficientes trades con ENTRY para sugerir ajustes.")
        return

    n_total = int(len(known_df))
    st.subheader("üéØ Ajustes sugeridos (seg√∫n esta muestra)")
    st.caption("Esto NO es una optimizaci√≥n cient√≠fica; es una gu√≠a r√°pida. Con poca muestra, √∫salo como hip√≥tesis.")

    if n_total < recommended_trades:
        st.warning(f"Muestra peque√±a: {n_total} trades con ENTRY. Recomendado ‚â• {recommended_trades} para decisiones fuertes.")

    # 1) Entry: StopMarket vs Limit
    if "orderType" in known_df.columns:
        tmp = known_df.copy()
        ot = tmp["orderType"].astype(str).str.lower()
        tmp["EntryType"] = np.where(ot.str.contains("stop"), "StopMarket", np.where(ot.str.contains("limit"), "Limit", tmp["orderType"].astype(str)))
        best_entry = _best_group_for_categorical(tmp, "EntryType", min_trades=min_trades)
    else:
        best_entry = None

    # 2) UseAtrEngine (bool)
    best_atr_mode = _best_group_for_categorical(known_df, "useAtrEngine", min_trades=min_trades)

    # 3) Rangos num√©ricos clave (si existen)
    q_small = 3  # con 40 trades: rangos pocos, m√°s estables
    best_or = _best_range_for_numeric(known_df, "orSize", q=q_small, min_trades=min_trades)
    best_ewo = None
    if "ewo" in known_df.columns:
        tmp = known_df.copy()
        tmp["ewoAbs"] = pd.to_numeric(tmp["ewo"], errors="coerce").abs()
        best_ewo = _best_range_for_numeric(tmp, "ewoAbs", q=q_small, min_trades=min_trades)

    best_atr = _best_range_for_numeric(known_df, "atr", q=q_small, min_trades=min_trades)
    best_atr_sl = _best_range_for_numeric(known_df, "atrSlMult", q=q_small, min_trades=min_trades)
    best_tp1 = _best_range_for_numeric(known_df, "tp1R", q=q_small, min_trades=min_trades)
    best_tp2 = _best_range_for_numeric(known_df, "tp2R", q=q_small, min_trades=min_trades)
    best_ts = _best_range_for_numeric(known_df, "tsBehindTP1Atr", q=q_small, min_trades=min_trades)
    best_step = _best_range_for_numeric(known_df, "trailStepTicks", q=q_small, min_trades=min_trades)

    # 4) Render: salida tipo "par√°metro -> sugerencia"
    lines = []

    def add_line(name, suggestion, note=None):
        s = f"- **{name}**: {suggestion}"
        if note:
            s += f"  \n  {note}"
        lines.append(s)

    if best_entry:
        use_stop = "True" if str(best_entry["grupo"]).lower() == "stopmarket" else "False"
        add_line("UseStopMarketEntry", use_stop, f"(mejor grupo: {best_entry['grupo']} | n={best_entry['n']} | PF={best_entry['pf']:.2f} | prom={best_entry['exp']:.0f})")

    if best_atr_mode:
        add_line("UseAtrEngine", str(best_atr_mode["grupo"]), f"(n={best_atr_mode['n']} | PF={best_atr_mode['pf']:.2f} | prom={best_atr_mode['exp']:.0f})")

    if best_or and best_or.get("lo") is not None and best_or.get("hi") is not None:
        add_line("MinORSize / MaxORSize", f"{best_or['lo']:.2f}  ‚Üí  {best_or['hi']:.2f}",
                 f"(mejor rango ORSize | n={best_or['n']} | PF={best_or['pf']:.2f} | prom={best_or['exp']:.0f})")

    if best_ewo and best_ewo.get("lo") is not None:
        add_line("MinEWOMagnitude", f"‚âà {best_ewo['lo']:.3f} (o mayor)",
                 f"(basado en |EWO| | n={best_ewo['n']} | PF={best_ewo['pf']:.2f} | prom={best_ewo['exp']:.0f})")

    if best_atr_sl and best_atr_sl.get("lo") is not None and best_atr_sl.get("hi") is not None:
        mid = (best_atr_sl["lo"] + best_atr_sl["hi"]) / 2
        add_line("AtrSlMult", f"‚âà {mid:.2f} (rango {best_atr_sl['lo']:.2f}‚Äì{best_atr_sl['hi']:.2f})",
                 f"(n={best_atr_sl['n']} | PF={best_atr_sl['pf']:.2f} | prom={best_atr_sl['exp']:.0f})")

    if best_tp1 and best_tp1.get("lo") is not None and best_tp1.get("hi") is not None:
        mid = (best_tp1["lo"] + best_tp1["hi"]) / 2
        add_line("TP1_RMult", f"‚âà {mid:.2f} (rango {best_tp1['lo']:.2f}‚Äì{best_tp1['hi']:.2f})",
                 f"(n={best_tp1['n']} | PF={best_tp1['pf']:.2f} | prom={best_tp1['exp']:.0f})")

    if best_tp2 and best_tp2.get("lo") is not None and best_tp2.get("hi") is not None:
        mid = (best_tp2["lo"] + best_tp2["hi"]) / 2
        add_line("TP2_RMult", f"‚âà {mid:.2f} (rango {best_tp2['lo']:.2f}‚Äì{best_tp2['hi']:.2f})",
                 f"(n={best_tp2['n']} | PF={best_tp2['pf']:.2f} | prom={best_tp2['exp']:.0f})")

    if best_ts and best_ts.get("lo") is not None and best_ts.get("hi") is not None:
        mid = (best_ts["lo"] + best_ts["hi"]) / 2
        add_line("TSBehindTP1_ATR", f"‚âà {mid:.2f} (rango {best_ts['lo']:.2f}‚Äì{best_ts['hi']:.2f})",
                 f"(n={best_ts['n']} | PF={best_ts['pf']:.2f} | prom={best_ts['exp']:.0f})")

    if best_step and best_step.get("lo") is not None and best_step.get("hi") is not None:
        # ticks: mejor entero
        mid = int(round((best_step["lo"] + best_step["hi"]) / 2))
        add_line("TrailStepTicks", f"‚âà {mid} (rango {best_step['lo']:.0f}‚Äì{best_step['hi']:.0f})",
                 f"(n={best_step['n']} | PF={best_step['pf']:.2f} | prom={best_step['exp']:.0f})")

    if not lines:
        st.info("No hay suficientes campos/muestra para sugerir ajustes autom√°ticos.")
    else:
        st.markdown("\n".join(lines))

    st.caption("‚ö†Ô∏è Consejo: aplica 1 cambio a la vez y vuelve a medir. Evita optimizar 5 par√°metros con 40 trades.")


# ============================================================
# (Opcional) Password: define APP_PASSWORD en Streamlit Secrets
# ============================================================
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
if APP_PASSWORD:
    st.sidebar.subheader("üîê Acceso")
    pwd = st.sidebar.text_input("Contrase√±a", type="password")
    if pwd != APP_PASSWORD:
        st.sidebar.warning("Contrase√±a incorrecta.")
        st.stop()

# ============================================================
# Helpers parse/normalize
# ============================================================
def parse_jsonl_bytes(b: bytes):
    txt = b.decode("utf-8", errors="replace")
    recs, bad = [], 0
    for line in txt.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            recs.append(json.loads(line))
        except Exception:
            bad += 1
    return recs, bad


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "ts" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["ts"], errors="coerce")
    elif "timestamp" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["timestamp"], errors="coerce")
    else:
        df["ts_parsed"] = pd.NaT

    if "type" not in df.columns:
        df["type"] = ""

    return df

# ============================================================
# Arrays (volumen/delta/OHLC) y m√©tricas pre-entrada
# ============================================================
def _as_list(x):
    """Convierte a lista si viene como list/tuple/np.array o string tipo '[...]'."""
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return []
    if isinstance(x, list):
        return x
    if isinstance(x, (tuple, np.ndarray)):
        return list(x)
    if isinstance(x, str):
        s = x.strip()
        if s.startswith("[") and s.endswith("]"):
            try:
                return json.loads(s)
            except Exception:
                return []
    return []


def add_pressure_activity_features(trades: pd.DataFrame) -> pd.DataFrame:
    """A√±ade m√©tricas de 'Presi√≥n y Actividad' usando arrays LastN (contexto pre-entrada).
    Si no existen arrays, devuelve el DF sin cambios.
    """
    if trades is None or trades.empty:
        return trades

    t = trades.copy()

    # Asegura num√©ricos base si existen
    for c in ["tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "volEntrySoFar", "deltaEntrySoFar", "dir"]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    def _row_feat(r):
        dl = _as_list(r.get("deltaLastN"))
        vl = _as_list(r.get("volLastN"))
        ol = _as_list(r.get("openLastN"))
        hl = _as_list(r.get("highLastN"))
        ll = _as_list(r.get("lowLastN"))
        cl = _as_list(r.get("closeLastN"))

        if not dl or not vl or not hl or not ll or not cl or not ol:
            return pd.Series({
                "pre_presion_sum": np.nan,
                "pre_presion_abs": np.nan,
                "pre_vol_sum": np.nan,
                "pre_precio_neto": np.nan,
                "pre_rango_precio": np.nan,
                "pre_mov_ticks": np.nan,
                "pre_absorcion": np.nan,
                "pre_actividad_rel": np.nan,
                "pre_presion_por_vol": np.nan,
                "pre_sin_apoyo": False,
            })

        presion_sum = float(np.nansum(dl))
        presion_abs = float(abs(presion_sum))
        vol_sum = float(np.nansum(vl))

        # Movimiento de precio pre-entrada
        try:
            precio_neto = float(cl[-1] - ol[0])
        except Exception:
            precio_neto = np.nan

        try:
            rango = float(np.nanmax(hl) - np.nanmin(ll))
        except Exception:
            rango = np.nan

        tick = r.get("tickSize")
        if tick is None or (isinstance(tick, float) and np.isnan(tick)) or tick == 0 or rango != rango:
            mov_ticks = np.nan
        else:
            mov_ticks = rango / float(tick)

        # Absorci√≥n: presi√≥n alta + avance bajo (normalizado por ticks movidos)
        absorcion = (presion_abs / max(mov_ticks, 1.0)) if mov_ticks == mov_ticks else np.nan

        # Actividad relativa: vol hasta entrada vs mediana del vol reciente
        med_vol = float(np.nanmedian(vl)) if len(vl) else np.nan
        vol_entry = r.get("volEntrySoFar")
        if med_vol == med_vol and med_vol > 0 and vol_entry == vol_entry:
            actividad_rel = float(vol_entry / med_vol)
        else:
            actividad_rel = np.nan

        # Presi√≥n por volumen (magnitud relativa)
        presion_por_vol = float(presion_abs / vol_sum) if vol_sum == vol_sum and vol_sum > 0 else np.nan

        # ‚ÄúSin apoyo‚Äù: precio avanza en una direcci√≥n pero la presi√≥n va al lado opuesto
        d = r.get("dir")
        sin_apoyo = False
        if d == d and precio_neto == precio_neto:
            if d > 0 and precio_neto > 0 and presion_sum < 0:
                sin_apoyo = True
            elif d < 0 and precio_neto < 0 and presion_sum > 0:
                sin_apoyo = True

        return pd.Series({
            "pre_presion_sum": presion_sum,
            "pre_presion_abs": presion_abs,
            "pre_vol_sum": vol_sum,
            "pre_precio_neto": precio_neto,
            "pre_rango_precio": rango,
            "pre_mov_ticks": mov_ticks,
            "pre_absorcion": absorcion,
            "pre_actividad_rel": actividad_rel,
            "pre_presion_por_vol": presion_por_vol,
            "pre_sin_apoyo": sin_apoyo,
        })

    feats = t.apply(_row_feat, axis=1)
    for c in feats.columns:
        t[c] = feats[c]

    return t


# ============================================================
# Formatting & traffic-light helpers
# ============================================================
def pct(x, d=1):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}%"

def fmt(x, d=2):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}"

def traffic_pf(pf: float):
    if pf is None or np.isnan(pf):
        return "‚ö™ PF N/A"
    if pf < 1.0:  return "üî¥ PF < 1 (pierde)"
    if pf < 1.2:  return "üü° PF 1.0‚Äì1.2 (d√©bil)"
    if pf < 1.5:  return "üü¢ PF 1.2‚Äì1.5 (bueno)"
    return "üü£ PF > 1.5 (muy bueno)"

def traffic_exp(exp: float):
    if exp is None or np.isnan(exp):
        return "‚ö™ Promedio N/A"
    if exp < 0:   return "üî¥ Promedio < 0"
    if exp < 10:  return "üü° Promedio bajo pero positivo"
    return "üü¢ Promedio s√≥lido"


# ============================================================
# Core metrics
# ============================================================
def profit_factor(trades) -> float:
    """Profit Factor = suma de ganancias / suma absoluta de p√©rdidas.

    Acepta:
      - DataFrame con columna 'tradeRealized'
      - Serie de PnL (tradeRealized)
    """
    if trades is None:
        return np.nan

    # Permite pasar directamente la Serie tradeRealized
    if isinstance(trades, pd.Series):
        s = trades.dropna()
    else:
        if not isinstance(trades, pd.DataFrame) or "tradeRealized" not in trades.columns:
            return np.nan
        s = trades["tradeRealized"].dropna()

    wins = float(s[s > 0].sum())
    losses = float(s[s < 0].sum())  # negativo

    loss_abs = abs(losses)
    if loss_abs <= 0:
        # Sin p√©rdidas: PF infinito si hay ganancias, sino NaN
        return float("inf") if wins > 0 else np.nan

    return wins / loss_abs



def _dd_mag_from_df(df_: pd.DataFrame) -> float:
    """M√°x ca√≠da (drawdown) en magnitud ($) usando la curva de equity por trade.
    Devuelve np.nan si df est√° vac√≠o o None.
    """
    if df_ is None or getattr(df_, "empty", True):
        return np.nan
    z = df_.copy()
    sort_col = "exit_time" if "exit_time" in z.columns else ("entry_time" if "entry_time" in z.columns else None)
    if sort_col is not None:
        # Orden consistente; NaT/NaN al final
        z = z.sort_values(sort_col, na_position="last")
    pnl = pd.to_numeric(z.get("tradeRealized", pd.Series([], dtype=float)), errors="coerce").fillna(0.0)
    if pnl.empty:
        return np.nan
    eq = pnl.cumsum()
    peak = eq.cummax()
    dd = eq - peak
    if dd.empty:
        return np.nan
    v = dd.min()
    try:
        return float(abs(v))
    except Exception:
        return np.nan


def max_streak(outcomes: pd.Series, target: str):
    best_len, cur = 0, 0
    best_end = None
    for i, o in enumerate(outcomes.tolist()):
        if o == target:
            cur += 1
            if cur > best_len:
                best_len = cur
                best_end = i
        else:
            cur = 0
    if best_len == 0:
        return 0, None, None
    start = best_end - best_len + 1
    return best_len, start, best_end


def drawdown_details(t: pd.DataFrame):
    if t.empty:
        return np.nan, None, None
    dd = t["drawdown"].fillna(0)
    trough_idx = int(dd.idxmin())
    trough_time = t.loc[trough_idx, "exit_time"]
    peak_idx = int(t.loc[:trough_idx, "equity"].idxmax())
    peak_time = t.loc[peak_idx, "exit_time"]
    return float(dd.min()), peak_time, trough_time


def hour_bucket_label(h):
    if pd.isna(h):
        return "Sin hora"
    h = int(h)
    return f"{h:02d}:00‚Äì{h:02d}:59"



def pair_trades(df: pd.DataFrame) -> pd.DataFrame:
    """
    1 fila por trade (atmId):
    - EXIT: √∫ltimo por atmId
    - ENTRY: primero por atmId
    Si falta ENTRY -> lado = "Sin datos (falt√≥ ENTRY)" (NO inventamos)
    """
    entries = df[df["type"] == "ENTRY"].copy()
    exits = df[df["type"] == "EXIT"].copy()

    entry_cols = [
        "atmId", "ts_parsed", "dir",
        "instrument", "tickSize", "pointValue",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar",
        "volEntrySoFar", "deltaEntrySoFar",
        "snapN", "snapIncludesEntryBar",
        "volLastN", "deltaLastN",
        "openLastN", "highLastN", "lowLastN", "closeLastN"
    ]
    entry_cols = [c for c in entry_cols if c in entries.columns]

    if len(entry_cols) == 0:
        e1 = pd.DataFrame(columns=["atmId", "entry_time"])
    else:
        e1 = (entries.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[entry_cols]
                    .first()
                    .rename(columns={"ts_parsed": "entry_time"}))

    exit_cols = [
        "atmId", "ts_parsed",
        "outcome", "exitReason", "tradeRealized", "dayRealized",
        "maxUnreal", "minUnreal", "forcedCloseReason", "dailyHalt",
        "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "cvd", "deltaBar", "deltaPrevBar"
    ]
    exit_cols = [c for c in exit_cols if c in exits.columns]

    if len(exit_cols) == 0:
        x1 = pd.DataFrame(columns=["atmId", "exit_time", "tradeRealized"])
    else:
        x1 = (exits.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[exit_cols]
                    .last()
                    .rename(columns={"ts_parsed": "exit_time"}))

    t = pd.merge(x1, e1, on="atmId", how="left")

    # Unifica columnas duplicadas de EXIT/ENTRY (pandas crea sufijos _x/_y)
    def _coalesce(name: str):
        x = f"{name}_x"
        y = f"{name}_y"
        if name in t.columns:
            return
        if (x in t.columns) or (y in t.columns):
            base = t[y] if y in t.columns else pd.Series([np.nan]*len(t))
            if x in t.columns:
                base = base.where(base.notna(), t[x])
            t[name] = base
            drop_cols = [c for c in [x, y] if c in t.columns]
            if drop_cols:
                t.drop(columns=drop_cols, inplace=True)

    for nm in [
        "dir", "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar"
    ]:
        _coalesce(nm)

    t["has_entry"] = t.get("entry_time").notna() if "entry_time" in t.columns else False

    # Num√©ricos
    for c in [
        "tradeRealized", "dayRealized", "maxUnreal", "minUnreal",
        "orSize", "atr", "ewo", "deltaRatio", "dir",
        "atrSlMult", "tp1R", "tp2R", "trailStepTicks",
        "tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "volEntrySoFar", "deltaEntrySoFar"
    ]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    # outcome robusto si falta
    if "tradeRealized" in t.columns:
        calc_outcome = np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS")
        if "outcome" not in t.columns:
            t["outcome"] = calc_outcome
        else:
            t["outcome"] = t["outcome"].where(t["outcome"].notna(), calc_outcome)

    # Duraci√≥n
    if "entry_time" in t.columns and "exit_time" in t.columns:
        t["duration_sec"] = (t["exit_time"] - t["entry_time"]).dt.total_seconds()
    else:
        t["duration_sec"] = np.nan

    # Equity / drawdown
    t = t.sort_values("exit_time").reset_index(drop=True)
    t["equity"] = t["tradeRealized"].fillna(0).cumsum()
    t["equity_peak"] = t["equity"].cummax()
    t["drawdown"] = t["equity"] - t["equity_peak"]

    # Hora
    t["exit_hour"] = t["exit_time"].dt.hour
    t["exit_hour_label"] = t["exit_hour"].apply(hour_bucket_label)

    # Lado (Compra/Venta) solo si hay dir
    def side_label(x):
        if pd.isna(x):
            return "Sin datos (falt√≥ ENTRY)"
        if x > 0:
            return "Compra (Long)"
        if x < 0:
            return "Venta (Short)"
        return "Sin datos (dir=0)"

    if "dir" in t.columns:
        t["lado"] = t["dir"].apply(side_label)
    else:
        t["lado"] = "Sin datos (falt√≥ ENTRY)"

    # ============================================================
    # M√©tricas tuning: Riesgo estimado, Ganancia/Riesgo, Captura/Devoluci√≥n
    # ============================================================
    if "tickSize" in t.columns and "pointValue" in t.columns:
        t["tick_value"] = t["tickSize"] * t["pointValue"]
    else:
        t["tick_value"] = np.nan

    if "qtyTP1" in t.columns or "qtyRunner" in t.columns:
        q1 = t["qtyTP1"] if "qtyTP1" in t.columns else 0
        qr = t["qtyRunner"] if "qtyRunner" in t.columns else 0
        t["qty_total"] = pd.to_numeric(q1, errors="coerce").fillna(0) + pd.to_numeric(qr, errors="coerce").fillna(0)
    else:
        t["qty_total"] = np.nan

    if "slTicks" in t.columns and "tick_value" in t.columns and "qty_total" in t.columns:
        t["risk_$"] = t["slTicks"] * t["tick_value"] * t["qty_total"]
        t.loc[t["risk_$"] <= 0, "risk_$"] = np.nan
    else:
        t["risk_$"] = np.nan

    if "tradeRealized" in t.columns:
        t["rr"] = t["tradeRealized"] / t["risk_$"]
    else:
        t["rr"] = np.nan

    if "tradeRealized" in t.columns and "maxUnreal" in t.columns:
        winners = t["tradeRealized"] > 0
        t["captura_pct"] = np.where(winners & (t["maxUnreal"] > 0), t["tradeRealized"] / t["maxUnreal"], np.nan)
        t["devolucion_pct"] = np.where(winners & (t["maxUnreal"] > 0),
                                       (t["maxUnreal"] - t["tradeRealized"]) / t["maxUnreal"], np.nan)
    else:
        t["captura_pct"] = np.nan
        t["devolucion_pct"] = np.nan

    # Presi√≥n/Actividad pre-entrada (si hay arrays)
    t = add_pressure_activity_features(t)

    return t


def summarize(t: pd.DataFrame) -> dict:
    if t.empty:
        return {}
    n = len(t)
    wins = int((t["tradeRealized"] > 0).sum())
    losses = int((t["tradeRealized"] < 0).sum())
    win_rate = (wins / n * 100) if n else np.nan

    pf = profit_factor(t)
    expectancy = float(t["tradeRealized"].mean()) if n else np.nan

    max_dd, dd_peak_time, dd_trough_time = drawdown_details(t)

    max_win = float(t["tradeRealized"].max())
    max_loss = float(t["tradeRealized"].min())

    outcomes = pd.Series(np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS"))
    wlen, _, _ = max_streak(outcomes, "WIN")
    llen, _, _ = max_streak(outcomes, "LOSS")

    return {
        "n": n, "wins": wins, "losses": losses, "win_rate": win_rate,
        "pnl_total": float(t["tradeRealized"].sum()),
        "pf": pf, "expectancy": expectancy,
        "max_dd": max_dd, "dd_peak_time": dd_peak_time, "dd_trough_time": dd_trough_time,
        "max_win": max_win, "max_loss": max_loss,
        "best_win_streak": wlen, "best_loss_streak": llen,
    }


# ============================================================
# Grouping / bins
# ============================================================
def make_bins_quantiles(df: pd.DataFrame, col: str, q: int):
    s = df[col].dropna()
    if len(s) < q * 10:
        return None
    try:
        return pd.qcut(df[col], q=q, duplicates="drop")
    except Exception:
        return None



def group_metrics(df: pd.DataFrame, group_col: str, min_trades: int, recommended_trades: int = None):
    """M√©tricas por grupo con control de muestra.
    - NO oculta grupos peque√±os: los marca como üü¢/üü°/üî¥.
    - 'WinRate (ajustado)' evita que 2/2 (=100%) gane contra 30 trades.
    """
    if recommended_trades is None:
        recommended_trades = max(60, min_trades)

    rows = []
    for g, sub in df.groupby(group_col):
        n = int(len(sub))
        if n == 0:
            continue

        tr = pd.to_numeric(sub.get("tradeRealized"), errors="coerce")
        wins = int((tr > 0).sum()) if tr is not None else 0
        wr = wins / n * 100 if n else np.nan
        wr_adj = (wins + 1) / (n + 2) * 100  # suavizado

        pf = profit_factor(sub) if "tradeRealized" in sub.columns else np.nan
        exp = float(tr.mean()) if tr is not None else np.nan
        pnl = float(tr.sum()) if tr is not None else np.nan

        score = exp * np.log1p(n) if exp == exp else np.nan

        if n >= recommended_trades:
            estado = "üü¢ Suficiente"
        elif n >= min_trades:
            estado = "üü° Muestra peque√±a"
        else:
            estado = "üî¥ No concluyente"

        rows.append({
            "Grupo": str(g),
            "Trades": n,
            "Estado": estado,
            "WinRate %": wr,
            "WinRate (ajustado) %": wr_adj,
            "Profit Factor": pf,
            "Promedio por trade": exp,
            "PnL Total": pnl,
            "Score (ponderado)": score,
        })

    out = pd.DataFrame(rows)
    if not out.empty:
        out = out.sort_values(["Score (ponderado)", "Trades"], ascending=[False, False], na_position="last").reset_index(drop=True)
    return out


# ============================================================
# Advice engines (NEXT LEVEL)
# ============================================================
def advice_from_table(tbl: pd.DataFrame, title: str, min_trades: int):
    if tbl is None or tbl.empty:
        st.info(f"En **{title}** no hay suficiente muestra (m√≠nimo {min_trades} trades por grupo).")
        return

    best = tbl.iloc[0]
    worst = tbl.iloc[-1]

    st.markdown("**‚úÖ Consejos r√°pidos (tabla):**")
    st.write(
        f"üèÜ Mejor: **{best['Grupo']}** | Trades={int(best['Trades'])} | PF={fmt(best['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(best['Promedio por trade'],1)} | PnL={fmt(best['PnL Total'],0)}"
    )
    st.write(
        f"üß® Peor: **{worst['Grupo']}** | Trades={int(worst['Trades'])} | PF={fmt(worst['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(worst['Promedio por trade'],1)} | PnL={fmt(worst['PnL Total'],0)}"
    )

    # warnings
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è El mejor grupo tiene muestra peque√±a. Ideal confirmar con m√°s meses de logs.")
    if not np.isnan(best["Profit Factor"]) and best["Profit Factor"] < 1.0:
        st.error("üö® Incluso el mejor grupo tiene PF < 1 ‚Üí este filtro no est√° salvando el sistema en estos datos.")
    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning("üëâ Hay grupos con PF < 1 ‚Üí candidatos a filtrar/evitar.")

    st.caption("Nota: WinRate Ajustado + Score ponderado evitan que 2 trades al 100% ‚Äúganen‚Äù contra 30 trades.")


def pnl_shape_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].dropna()
    if pnl.empty:
        return []

    med = float(pnl.median())
    p25 = float(pnl.quantile(0.25))
    p75 = float(pnl.quantile(0.75))
    p10 = float(pnl.quantile(0.10))
    p90 = float(pnl.quantile(0.90))

    max_win = float(pnl.max())
    max_loss = float(pnl.min())
    avg_win = float(pnl[pnl > 0].mean()) if (pnl > 0).any() else np.nan
    avg_loss = float(pnl[pnl < 0].mean()) if (pnl < 0).any() else np.nan

    insights = []
    insights.append(f"üìå Mediana PnL: **{med:.1f}** | IQR (25‚Äì75%): **[{p25:.1f}, {p75:.1f}]**")

    if not np.isnan(avg_win) and not np.isnan(avg_loss) and avg_loss != 0:
        ratio = abs(avg_win / avg_loss)
        if ratio < 0.8:
            insights.append("‚ö†Ô∏è P√©rdidas promedio > ganancias promedio ‚Üí revisa SL, entradas tard√≠as, o horarios peligrosos.")
        elif ratio < 1.2:
            insights.append("üü° Ganancia y p√©rdida promedio similares ‚Üí el edge depende m√°s del winrate + filtros.")
        else:
            insights.append("üü¢ Ganancias promedio > p√©rdidas promedio ‚Üí buena relaci√≥n base si el winrate acompa√±a.")

    if max_win != 0:
        bomb = abs(max_loss) / abs(max_win)
        if bomb >= 1.5:
            insights.append("üö® P√©rdidas gigantes vs la mayor ganancia. Revisa stops, slippage, noticias, o ‚Äúchasing‚Äù.")
        elif bomb >= 1.0:
            insights.append("‚ö†Ô∏è La peor p√©rdida compite con la mejor ganancia. Controla los outliers.")

    insights.append(f"üß≠ Zona t√≠pica (10‚Äì90%): **[{p10:.1f}, {p90:.1f}]**. Fuera de esto son outliers.")
    return insights


def equity_recovery_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].fillna(0)
    exp = float(pnl.mean()) if len(pnl) else np.nan
    std = float(pnl.std()) if len(pnl) > 2 else np.nan

    max_dd, peak_t, trough_t = drawdown_details(t)

    insights = []
    if peak_t is not None and trough_t is not None:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}** (desde {peak_t} hasta {trough_t})")
    else:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}**")

    if exp < 0:
        insights.append("üö® Promedio por trade negativo: necesitas filtros fuertes o cambiar l√≥gica antes de ‚Äútunear fino‚Äù.")
    else:
        insights.append(f"‚úÖ Promedio por trade: **{exp:.1f}** ({traffic_exp(exp)})")

    if not np.isnan(std) and std > 0 and not np.isnan(exp):
        cv = abs(std / exp) if exp != 0 else np.inf
        if exp > 0 and cv > 6:
            insights.append("‚ö†Ô∏è PnL muy vol√°til vs el promedio ‚Üí sube muestra o filtra momentos de alta variabilidad.")
        elif exp > 0 and cv > 3:
            insights.append("üü° Variabilidad moderada-alta ‚Üí usa guardias diarias conservadoras.")
        elif exp > 0:
            insights.append("üü¢ PnL relativamente estable vs el promedio.")

    if exp > 0 and not np.isnan(max_dd):
        dd_trades_equiv = abs(max_dd / exp)
        if dd_trades_equiv > 80:
            insights.append("üö® Drawdown enorme relativo al promedio ‚Üí recuperaci√≥n puede tardar mucho.")
        elif dd_trades_equiv > 40:
            insights.append("‚ö†Ô∏è Drawdown alto relativo al promedio ‚Üí requiere disciplina (guardia diaria / filtros).")
        else:
            insights.append("üü¢ Drawdown razonable relativo al promedio.")

    return insights


def factor_danger_zone_insights(df_known: pd.DataFrame, xcol: str, q: int, min_trades: int, title: str):
    bins = make_bins_quantiles(df_known, xcol, q)
    if bins is None:
        return ["‚ÑπÔ∏è No hay suficiente data para detectar zonas por rangos."]

    tmp = df_known.copy()
    tmp["_bin"] = bins.astype(str)
    tbl = group_metrics(tmp, "_bin", min_trades=min_trades)

    if tbl.empty:
        return [f"‚ÑπÔ∏è No hay rangos con ‚â• {min_trades} trades para {title}."]

    # zonas malas
    bad = tbl[(tbl["Promedio por trade"] < 0) & (tbl["Profit Factor"] < 1.0)].copy()
    good = tbl[(tbl["Promedio por trade"] > 0) & (tbl["Profit Factor"] >= 1.2)].copy()

    insights = []
    if not bad.empty:
        b = bad.sort_values("Score (ponderado)").iloc[0]
        insights.append(f"üö´ Zona peligrosa: **{b['Grupo']}** ‚Üí promedio<0 y PF<1 (candidato a EVITAR).")
    else:
        insights.append("‚úÖ No se detectan rangos claramente peligrosos (con muestra suficiente).")

    if not good.empty:
        g = good.sort_values("Score (ponderado)", ascending=False).iloc[0]
        insights.append(f"‚úÖ Zona fuerte: **{g['Grupo']}** ‚Üí PF‚â•1.2 y promedio>0 (candidato a priorizar).")

    spread = float(tbl["Promedio por trade"].max() - tbl["Promedio por trade"].min())
    if spread < 5:
        insights.append("‚ÑπÔ∏è Este factor casi no separa rendimiento (spread peque√±o) ‚Üí filtro d√©bil por s√≠ solo.")
    else:
        insights.append("üìå Este factor S√ç separa rendimiento ‚Üí √∫til para tunear rangos.")
    return insights


# ============================================================
# Charts
# ============================================================
def plot_equity_drawdown(t: pd.DataFrame):
    fig1 = px.line(t, x="exit_time", y="equity", title="Equity (curva de capital acumulada)")
    fig1.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))

    fig2 = px.line(t, x="exit_time", y="drawdown", title="Drawdown (ca√≠da desde el m√°ximo de equity)")
    fig2.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))
    fig2.add_hline(y=0, line_width=1, line_dash="dash")
    return fig1, fig2


def plot_pnl_hist(t: pd.DataFrame):
    """Histograma de PnL realizado (dinero). tradeRealized est√° en la moneda de la cuenta (normalmente $)."""
    tmp = t.copy()
    tr = pd.to_numeric(tmp.get("tradeRealized"), errors="coerce")
    tmp["Resultado"] = np.where(tr >= 0, "Ganancia", "P√©rdida")

    fig = px.histogram(
        tmp,
        x="tradeRealized",
        color="Resultado",
        nbins=40,
        barmode="overlay",
        title="Distribuci√≥n de PnL ($) por operaci√≥n",
        labels={"tradeRealized": "PnL ($)"},
    )
    fig.update_traces(opacity=0.75)
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    fig.add_vline(x=0, line_width=1, line_dash="dash")
    return fig


def plot_scatter_advanced(df_known: pd.DataFrame, xcol: str, title: str):
    cols = [c for c in [xcol, "tradeRealized", "exit_time", "lado", "exitReason"] if c in df_known.columns]
    tmp = df_known[cols].dropna(subset=[xcol, "tradeRealized"]).copy()
    if tmp.empty:
        st.info("No hay suficiente data para el scatter.")
        return

    tmp["Resultado"] = np.where(tmp["tradeRealized"] >= 0, "Ganancia", "P√©rdida")

    fig = px.scatter(
        tmp,
        x=xcol,
        y="tradeRealized",
        color="Resultado",
        hover_data=[c for c in ["exit_time", "lado", "exitReason", "tradeRealized"] if c in tmp.columns],
        title=title
    )
    fig.update_traces(marker=dict(size=7, opacity=0.60))
    fig.add_hline(y=0, line_width=1, line_dash="dash")
    fig.update_layout(height=440, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.caption("Lectura: verde = PnL ‚â• 0, rojo = PnL < 0. Con muestra peque√±a, √∫salo como idea, no como regla.")




def plot_factor_bins(df_known: pd.DataFrame, col: str, q: int, min_trades: int, recommended_trades: int, title: str,
                     show_scatter: bool, scatter_df: pd.DataFrame):
    """
    Panel por rangos (cuantiles) para un factor (OR/ATR/EWO/etc).
    - Colores consistentes: verde = mejor, rojo = peor.
    - Sin 'bins' en UI: todo se llama 'rangos'.
    - Etiquetas humanas para rangos (ej: 60‚Äì94).
    """
    def nice_range_label(s: str) -> str:
        if not isinstance(s, str):
            return str(s)
        s2 = s.strip()
        # Formatos t√≠picos: "(60.0, 94.0]" o "[14.5, 60.0)"
        if ("," in s2) and (s2[0] in "([") and (s2[-1] in "])"):
            inner = s2[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    a = float(parts[0])
                    b = float(parts[1])
                    # Redondeo ‚Äúhumano‚Äù
                    if abs(a) >= 100 or abs(b) >= 100:
                        return f"{a:.0f}‚Äì{b:.0f}"
                    if abs(a) >= 10 or abs(b) >= 10:
                        return f"{a:.1f}‚Äì{b:.1f}"
                    return f"{a:.2f}‚Äì{b:.2f}"
                except Exception:
                    return s2
        return s2

    bins = make_bins_quantiles(df_known, col, q)
    if bins is None:
        st.info(f"No hay suficiente data para crear rangos en **{title}**.")
        return

    tmp = df_known.copy()
    tmp["_range"] = bins.astype(str)

    tbl = group_metrics(tmp, "_range", min_trades=min_trades, recommended_trades=recommended_trades)
    if tbl.empty:
        st.info(f"En **{title}** no hay data para agrupar.")
        return

    # Etiquetas humanas (m√°s f√°ciles de leer)
    _orig = tbl["Grupo"].astype(str).tolist()
    _nice = [nice_range_label(x) for x in _orig]

    def _parse_left(rg: str):
        rg = str(rg).strip()
        if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
            inner = rg[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    return float(parts[0])
                except Exception:
                    return np.nan
        return np.nan

    lefts = [(_parse_left(o), i) for i, o in enumerate(_orig)]
    order = [i for _, i in sorted(lefts, key=lambda x: (np.nan_to_num(x[0], nan=1e18), x[1]))]

    k = len(_nice)
    if k == 3:
        names = ["Bajo", "Medio", "Alto"]
    elif k == 4:
        names = ["Bajo", "Medio-bajo", "Medio-alto", "Alto"]
    elif k == 5:
        names = ["Muy bajo", "Bajo", "Medio", "Alto", "Muy alto"]
    else:
        names = [f"R{i+1}" for i in range(k)]

    label_map = {}
    for rank, idx in enumerate(order):
        base = names[rank] if rank < len(names) else f"R{rank+1}"
        label_map[_orig[idx]] = f"{base} ({_nice[idx]})"

    tbl["Grupo"] = tbl["Grupo"].astype(str).map(label_map).fillna(tbl["Grupo"].astype(str))

    # Leyenda de muestra
    n_ok = int((tbl["Estado"] == "üü¢ Suficiente").sum())
    n_small = int((tbl["Estado"] == "üü° Muestra peque√±a").sum())
    n_bad = int((tbl["Estado"] == "üî¥ No concluyente").sum())
    st.caption(
        f"Muestra por rango: üü¢{n_ok} üü°{n_small} üî¥{n_bad}  | "
        f"M√≠nimo para mirar: {min_trades}  | Recomendado para decidir: {recommended_trades}"
    )

    # Para gr√°ficos: solo rangos con muestra m√≠nima
    tbl_chart = tbl[tbl["Trades"] >= min_trades].copy()

    if not tbl_chart.empty:
        # Promedio por trade: verde = mejor, rojo = peor. Centramos en 0 (negativos quedan rojos).
        fig_exp = px.bar(
            tbl_chart,
            x="Grupo",
            y="Promedio por trade",
            color="Promedio por trade",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=0,
            title=f"{title} ‚Üí Promedio por trade (rangos)",
            text="Promedio por trade",
        )
        fig_exp.update_traces(texttemplate="%{text:.0f}", textposition="inside")
        fig_exp.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="Promedio",
        )
        fig_exp.add_hline(y=0, line_width=1, line_dash="dash")

        # Profit Factor: verde = alto (mejor), rojo = bajo (peor). Punto neutro en 1.0.
        fig_pf = px.bar(
            tbl_chart,
            x="Grupo",
            y="Profit Factor",
            color="Profit Factor",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=1.0,
            title=f"{title} ‚Üí Profit Factor (rangos)",
            text="Profit Factor",
        )
        fig_pf.update_traces(texttemplate="%{text:.2f}", textposition="inside")
        fig_pf.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="PF",
        )
        fig_pf.add_hline(y=1.0, line_width=1, line_dash="dash")

        st.plotly_chart(fig_exp, use_container_width=True)
        st.plotly_chart(fig_pf, use_container_width=True)

        st.caption("Profit Factor (PF) = Ganancias totales / P√©rdidas totales. PF>1 indica que el conjunto gana. "
                   "PF>1.5 suele ser s√≥lido si la muestra es suficiente (üü¢).")

        advice_from_table(tbl_chart, title, min_trades=min_trades)
    else:
        st.info("‚ö†Ô∏è Con el m√≠nimo actual, todos los rangos quedan con poca muestra. √ösalo como idea, no como regla.")

    st.dataframe(tbl, use_container_width=True)

    if show_scatter:
        st.markdown("**Scatter (solo para ver dispersi√≥n / outliers)**")
        if col in scatter_df.columns and scatter_df[col].notna().sum() >= max(20, min_trades):
            plot_scatter_advanced(scatter_df, col, title=f"{title} ‚Üí Scatter")
        else:
            st.info("No hay suficiente data para scatter en este factor.")

def plot_hour_analysis(t: pd.DataFrame, min_trades: int):
    tbl = group_metrics(t, "exit_hour_label", min_trades=min_trades)
    if tbl.empty:
        st.info(f"No hay suficientes trades por hora para min_trades={min_trades}.")
        return None

    fig = px.bar(tbl, x="Grupo", y="Score (ponderado)",
                 title="Horas m√°s prometedoras (Score ponderado por tama√±o de muestra)")
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.dataframe(tbl, use_container_width=True)
    advice_from_table(tbl, title="Hora", min_trades=min_trades)
    return tbl



def plot_heatmap_weekday_hour(t: pd.DataFrame, min_trades: int):
    tmp = t.copy()

    if "exit_time" not in tmp.columns or tmp["exit_time"].isna().all():
        st.info("No hay exit_time v√°lido para generar el heatmap.")
        return

    tmp = tmp.dropna(subset=["exit_time"]).copy()
    tmp["weekday"] = tmp["exit_time"].dt.day_name()
    if "exit_hour" not in tmp.columns or tmp["exit_hour"].isna().all():
        tmp["exit_hour"] = tmp["exit_time"].dt.hour

    weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    tmp["weekday_order"] = pd.Categorical(tmp["weekday"], categories=weekday_order, ordered=True)

    agg = tmp.groupby(["weekday_order", "exit_hour"]).agg(
        Trades=("tradeRealized", "size"),
        Promedio=("tradeRealized", "mean"),
    ).reset_index()

    agg.loc[agg["Trades"] < min_trades, "Promedio"] = np.nan
    pivot = agg.pivot(index="weekday_order", columns="exit_hour", values="Promedio")

    # Si con el m√≠nimo actual no queda nada visible, avisamos y no dibujamos un heatmap vac√≠o.
    if pivot.count().sum() == 0:
        st.info(
            f"No hay celdas con ‚â• {min_trades} trades para el heatmap. "
            "Baja el m√≠nimo o usa el panel por hora (arriba), que requiere menos muestra."
        )
        return

    # Escala azul‚Üírojo (negativo‚Üípositivo). Centramos en 0 para lectura r√°pida.
    vals = pivot.values.astype(float)
    max_abs = np.nanmax(np.abs(vals)) if np.isfinite(vals).any() else None
    zmin = -max_abs if max_abs else None
    zmax = max_abs if max_abs else None

    # Compatibilidad: algunas versiones de Plotly no soportan text_auto en imshow.
    try:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
            text_auto=True,
        )
    except TypeError:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
        )
        # A√±adimos etiquetas manuales (valores)
        for yi, day in enumerate(pivot.index.astype(str).tolist()):
            for xi, hour in enumerate(pivot.columns.tolist()):
                v = pivot.loc[pivot.index[yi], hour]
                if pd.notna(v):
                    fig.add_annotation(
                        x=hour,
                        y=day,
                        text=f"{v:.0f}",
                        showarrow=False,
                        font=dict(size=11, color="black"),
                    )

    fig.update_layout(height=460, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)
    st.caption("Azul = promedio negativo, rojo = promedio positivo. Si casi todo queda vac√≠o, baja el m√≠nimo (muestra peque√±a).")

# ============================================================
# UI
# ============================================================
st.title("üìä WIC_WLF2 Analizador")

uploaded = st.file_uploader(
    "üì§ Sube uno o varios archivos .jsonl (meses)",
    type=["jsonl"],
    accept_multiple_files=True
)
if not uploaded:
    st.stop()

all_records, bad_total = [], 0
for uf in uploaded:
    recs, bad = parse_jsonl_bytes(uf.getvalue())
    bad_total += bad
    all_records.extend(recs)

if not all_records:
    st.error("No se pudo leer ning√∫n registro JSON v√°lido.")
    st.stop()

df = pd.DataFrame(all_records)
df = normalize_columns(df)
t = pair_trades(df)

if bad_total > 0:
    st.caption(f"‚ÑπÔ∏è L√≠neas inv√°lidas ignoradas al parsear: **{bad_total}**")

missing_entry = int((~t["has_entry"]).sum())
if missing_entry > 0:
    st.warning(
        f"‚ö†Ô∏è **{missing_entry} operaciones no tienen ENTRY** en los archivos cargados. "
        "En esas, no se puede saber Compra/Venta ni ORSize/ATR/EWO/DeltaRatio. "
        "Se muestran como: ‚ÄúSin datos (falt√≥ ENTRY)‚Äù."
    )

# Sidebar controls
st.sidebar.subheader("‚öôÔ∏è Ajustes")
min_trades = st.sidebar.slider("M√≠nimo trades por grupo (para mirar)", 5, 120, 30, 5)
recommended_trades = st.sidebar.slider("Trades recomendados por grupo (para decidir)", 20, 300, 80, 10)
q_bins = st.sidebar.slider("N√∫mero de rangos (cuantiles)", 3, 12, 5, 1)

show_adv_scatter = st.sidebar.checkbox("Mostrar scatter (√∫til para ver outliers)", value=False)
last_n_scatter = st.sidebar.slider("Scatter: √∫ltimos N trades (0=todo)", 0, 3000, 800, 100)

summary = summarize(t)

# ============================================================
# Summary
# ============================================================
st.subheader("‚úÖ Resumen r√°pido (lo m√°s importante)")

c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric("Operaciones", f"{summary['n']}")
c2.metric("Ganadas", f"{summary['wins']}")
c3.metric("Perdidas", f"{summary['losses']}")
c4.metric("% Acierto", f"{summary['win_rate']:.1f}%")
c5.metric("PnL Total", f"{summary['pnl_total']:.0f}")
c6.metric("Profit Factor", f"{summary['pf']:.2f}" if not np.isnan(summary["pf"]) else "N/A")

c7, c8, c9, c10, c11, c12 = st.columns(6)
c7.metric("Promedio por trade (Expectancia)", f"{summary['expectancy']:.1f}")
c8.metric("Max Drawdown", f"{summary['max_dd']:.0f}")
c9.metric("Racha wins seguidos", f"{summary['best_win_streak']}")
c10.metric("Racha losses seguidos", f"{summary['best_loss_streak']}")
c11.metric("Mayor win", f"{summary['max_win']:.1f}")
c12.metric("Mayor loss", f"{summary['max_loss']:.1f}")

with st.expander("üìå C√≥mo leer estas m√©tricas (simple)"):
    st.write("**Promedio por trade (Expectancia)**: lo que ganas/pierdes en promedio por operaci√≥n. Si es positivo, bien.")
    st.write("**Profit Factor**: ganancias totales / p√©rdidas totales. PF > 1.0 indica ventaja. PF > 1.2 suele ser m√°s s√≥lido.")
    st.write("**Drawdown**: la peor ca√≠da desde el m√°ximo de tu equity; representa el ‚Äúdolor m√°ximo‚Äù del sistema.")
    st.write("**Rachas**: cu√°ntas operaciones ganadas/perdidas seguidas (√∫til para guardias diarias y sizing).")

st.markdown("### ‚öôÔ∏è Avisos seg√∫n tus ajustes")
total_n = int(summary.get("n", 0))
if total_n < 60:
    st.info("Muestra peque√±a (menos de 60 trades). √ösalo para orientar el tuning, pero evita cambiar reglas por 3 trades.")

# Si el usuario pide demasiados rangos o m√≠nimos para la muestra, casi todo quedar√° vac√≠o.
if q_bins * max(1, min_trades) > max(1, total_n):
    st.warning(
        "‚ö†Ô∏è Con estos ajustes vas a ver muchos paneles vac√≠os: est√°s pidiendo demasiados rangos o un m√≠nimo demasiado alto para tu muestra. "
        "Sugerencia con esta cantidad de trades: 3‚Äì5 rangos y m√≠nimo 10‚Äì20 trades por grupo."
    )
if min_trades > max(10, total_n // 2):
    st.warning("‚ö†Ô∏è M√≠nimo por grupo muy alto vs tu total de trades. Baja el m√≠nimo si quieres ver m√°s comparaciones (con cuidado).")
if recommended_trades > total_n:
    st.info("Recomendaci√≥n: tu 'trades recomendados para decidir' es mayor que tu muestra actual, as√≠ que todas las conclusiones son provisionales.")

# ============================================================
# Main charts
# ============================================================
st.subheader("üìà Gr√°ficos principales (claros + consejos)")

fig_eq, fig_dd = plot_equity_drawdown(t)
colA, colB = st.columns(2)
with colA:
    st.plotly_chart(fig_eq, use_container_width=True)
with colB:
    st.plotly_chart(fig_dd, use_container_width=True)

st.markdown("### üß† Consejos autom√°ticos (Equity / Drawdown)")
for s in equity_recovery_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.success(s)

st.plotly_chart(plot_pnl_hist(t), use_container_width=True)
st.caption("PnL ($) = dinero realizado por trade (tradeRealized). Si quieres verlo en ticks/points, se puede derivar con tickSize/pointValue, pero aqu√≠ mostramos la realidad de la cuenta.")

st.markdown("### üß† Consejos autom√°ticos (Distribuci√≥n de PnL)")
for s in pnl_shape_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.info(s)


# ============================================================
# Ganancia vs Riesgo (RR) + Captura / Devoluci√≥n
# ============================================================
st.subheader("üéØ Ganancia vs Riesgo (RR) y manejo de la operaci√≥n")

if "rr" not in t.columns or t["rr"].dropna().empty:
    st.info(
        "No hay datos suficientes para calcular RR. Para esto necesitas en el log (ENTRY o EXIT): "
        "tickSize, pointValue, slTicks y cantidades (qtyTP1/qtyRunner)."
    )
else:
    rr_df = t[t["rr"].notna()].copy()

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("RR mediana", f"{rr_df['rr'].median():.2f}")
    c2.metric("RR promedio", f"{rr_df['rr'].mean():.2f}")
    c3.metric("% RR ‚â• 1", f"{(rr_df['rr'] >= 1).mean()*100:.1f}%")
    c4.metric("% RR ‚â• 2", f"{(rr_df['rr'] >= 2).mean()*100:.1f}%")
    c5.metric("Trades con RR", f"{len(rr_df)}")

    # M√©tricas extra (m√°s f√°ciles de leer con muestras peque√±as)
    rr_wins = rr_df.loc[rr_df["rr"] > 0, "rr"]
    rr_losses = rr_df.loc[rr_df["rr"] < 0, "rr"]
    small_losses = rr_df[(rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)]

    c6, c7, c8 = st.columns(3)
    c6.metric("RR promedio (ganadores)", f"{rr_wins.mean():.2f}" if not rr_wins.empty else "N/A")
    c7.metric("RR promedio (perdedores)", f"{rr_losses.mean():.2f}" if not rr_losses.empty else "N/A")
    c8.metric("% p√©rdidas peque√±as (-0.5R a 0)", f"{len(small_losses)/len(rr_df)*100:.1f}%" if len(rr_df) else "N/A")

    rr_tmp = rr_df.copy()
    rr_tmp["Resultado"] = np.where(rr_tmp["rr"] >= 0, "Ganancia", "P√©rdida")
    fig_rr = px.histogram(
        rr_tmp,
        x="rr",
        color="Resultado",
        nbins=30,
        barmode="overlay",
        title="Distribuci√≥n de RR (Ganancia/Riesgo)",
        labels={"rr": "RR"},
    )
    fig_rr.update_traces(opacity=0.75)
    fig_rr.add_vline(x=0, line_width=1, line_dash="dash")
    fig_rr.add_vline(x=1, line_width=1, line_dash="dash")
    fig_rr.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig_rr, use_container_width=True)

    st.markdown("**C√≥mo leer RR (r√°pido)**")
    rr_med = rr_df["rr"].median()
    rr_mean = rr_df["rr"].mean()
    if rr_mean > 0 and rr_med < 0:
        st.info("Promedio > 0 y mediana < 0: el resultado depende de pocos trades grandes; la mayor√≠a pierde.")
    elif rr_mean > 0 and rr_med > 0:
        st.info("Promedio > 0 y mediana > 0: la mayor√≠a de trades aporta; comportamiento m√°s estable.")
    elif rr_mean < 0:
        st.info("Promedio < 0: el sistema est√° perdiendo (tuning o filtros urgentes).")
    st.caption("Con pocas operaciones, confirma con m√°s trades antes de cambiar reglas.")

    st.markdown("### üß† Pistas r√°pidas (RR)")
    pct_rr1 = (rr_df["rr"] >= 1).mean()
    pct_stop = (rr_df["rr"] <= -1).mean()
    pct_small_loss = ((rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)).mean()

    if pct_rr1 < 0.35:
        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if pct_stop > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if pct_small_loss < 0.05 and pct_stop > 0.15:
        st.info("üü° Casi no hay p√©rdidas peque√±as: cuando pierdes, sueles perder ~1R completo. Eso suele indicar 'stop-out' frecuente (poco margen para salir antes). Buen candidato: mejorar filtros de entrada/horario o invalidaci√≥n temprana.")

    if rr_df["rr"].median() > 0.3 and pct_rr1 > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if (rr_df["rr"] <= -1).mean() > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if rr_df["rr"].median() > 0.3 and (rr_df["rr"] >= 1).mean() > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

    # Captura / Devoluci√≥n (solo ganadores)
    if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
        wincap = t["captura_pct"].dropna()
        wingb = t["devolucion_pct"].dropna()

        c6, c7, c8 = st.columns(3)
        c6.metric("Captura mediana", f"{wincap.median()*100:.0f}%")
        c7.metric("Devoluci√≥n mediana", f"{wingb.median()*100:.0f}%")
        c8.metric("Ganadores con datos", f"{len(wincap)}")

        # Mostrar en % (0‚Äì100). Si ves valores >100%, suele ser inconsistencia de log (maxUnreal no captur√≥ el pico real).
        raw_cap = t["captura_pct"].dropna()
        n_weird = int((raw_cap > 1.05).sum())
        if n_weird > 0:
            st.warning("‚ö†Ô∏è Veo algunos valores de 'captura' > 100%. Eso suele pasar cuando maxUnreal no captur√≥ el pico real (o por parciales). "
                       "Para no confundir, el gr√°fico se limita a 0‚Äì100%.")

        cap_plot = (raw_cap.clip(0, 1) * 100.0)
        cap_df = pd.DataFrame({"Captura (%)": cap_plot})

        fig_cap = px.histogram(
            cap_df,
            x="Captura (%)",
            nbins=20,
            title="Qu√© tan cerca del pico cierras (solo ganadores)",
        )
        fig_cap.add_vline(x=50, line_width=1, line_dash="dash")
        fig_cap.update_layout(height=300, margin=dict(l=10, r=10, t=50, b=10))
        st.plotly_chart(fig_cap, use_container_width=True)

        st.markdown("**Qu√© significa esto (en simple)**")
        st.write(
            "Solo se calcula en trades **ganadores**. "
            "La idea es responder: **¬øcerr√© cerca del mejor punto, o dej√© devolver mucho?**"
        )
        st.write(
            "- **Pico del trade** = el mejor PnL flotante que tuvo antes de cerrar (*maxUnreal*).\n"
            "- **Te quedas (captura)** = qu√© % de ese pico terminaste cobrando al cerrar.\n"
            "- **Devolviste (devoluci√≥n)** = qu√© % retrocedi√≥ desde el pico hasta el cierre."
        )
        st.write(
            "Ejemplo: el trade lleg√≥ a **+$500** (pico) y cerr√≥ en **+$475** ‚Üí "
            "Te quedas ‚âà **95%** y devolviste ‚âà **5%**."
        )

        st.markdown("**üß† Consejos autom√°ticos (salidas / trailing)**")
        cap_med = wincap.median() if not wincap.empty else np.nan
        gb_med = wingb.median() if not wingb.empty else np.nan

        if cap_med == cap_med and cap_med < 0.35:
            st.warning("‚ö†Ô∏è Captura mediana baja (<35%). Est√°s cerrando muy lejos del mejor punto: revisa trailing, TP, o reglas de salida temprana.")
        elif cap_med == cap_med and cap_med > 0.60:
            st.success("‚úÖ Captura mediana alta (>60%). Buen manejo de salida (en esta muestra).")
        else:
            st.info("üü° Captura mediana intermedia. Puede estar bien; valida con m√°s trades.")

        if gb_med == gb_med and gb_med > 0.60:
            st.warning("‚ö†Ô∏è Devoluci√≥n mediana alta (>60%). Est√°s devolviendo mucho: prueba trailing m√°s agresivo o TP parcial mejor definido.")
        elif gb_med == gb_med and gb_med < 0.35:
            st.success("‚úÖ Devoluci√≥n mediana baja (<35%). Sueles proteger ganancias a tiempo.")
        else:
            st.info("üü° Devoluci√≥n mediana intermedia. Ajusta solo si ves que afecta RR/expectancia.")

        st.caption("Interpretaci√≥n r√°pida: Captura alta suele indicar salidas eficientes; Devoluci√≥n alta suele indicar trailing/TP tarde o dejar correr sin proteger.")

    # RR por plantilla / tipo de orden
    split_cols = []
    # Evitamos 'trigger' porque suele ser demasiado gen√©rico y confunde a usuarios finales.
    for c in ["template", "orderType", "exitReason", "lado"]:
        if c in rr_df.columns and rr_df[c].notna().sum() > 0:
            split_cols.append(c)

    if split_cols:
        pick = st.selectbox("Comparar RR por:", split_cols, index=0)
        rr_tbl = group_metrics(rr_df, pick, min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.dataframe(rr_tbl, use_container_width=True)
        st.caption("Tip: usa 'Estado' üü¢/üü°/üî¥ para no enamorarte de grupos con 3 trades.")

# ============================================================
# Motivos de salida
# ============================================================
st.subheader("üö™ Motivos de salida (qu√© est√° cerrando tus trades)")

colA, colB = st.columns(2)

with colA:
    if "exitReason" in t.columns and t["exitReason"].notna().sum() > 0:
        tbl_exit = group_metrics(t, "exitReason", min_trades=min_trades, recommended_trades=recommended_trades)
        st.markdown("**ExitReason**")
        st.dataframe(tbl_exit, use_container_width=True)

        # Pistas
        if not tbl_exit.empty:
            worst = tbl_exit.sort_values("Promedio por trade").iloc[0]
            if float(worst["Promedio por trade"]) < 0 and int(worst["Trades"]) >= min_trades:
                st.warning(f"‚ö†Ô∏è Peor motivo (por promedio): **{worst['Grupo']}**. Revisa ese flujo/condici√≥n.")
    else:
        st.info("No hay exitReason en los logs.")

with colB:
    if "forcedCloseReason" in t.columns and t["forcedCloseReason"].notna().sum() > 0:
        tbl_fc = group_metrics(t, "forcedCloseReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.markdown("**ForcedCloseReason**")
        st.dataframe(tbl_fc, use_container_width=True)

        if not tbl_fc.empty:
            hot = tbl_fc.sort_values("Trades", ascending=False).iloc[0]
            if int(hot["Trades"]) >= min_trades and float(hot["Promedio por trade"]) < 0:
                st.warning(f"üö® Forced close frecuente y negativo: **{hot['Grupo']}**. Esto suele ser 'regla' o 'protecci√≥n' mal calibrada.")
    else:
        st.info("No hay forcedCloseReason en los logs.")

st.caption("OJO: el motivo de salida es diagn√≥stico, no filtro m√°gico. √ösalo para detectar patrones (stops, daily halt, cierre forzado, etc.).")


# ============================================================
# Long vs Short
# ============================================================
st.subheader("üß≠ Compra vs Venta (solo donde hay ENTRY)")

col1, col2, col3 = st.columns(3)
col1.metric("Compras (Long)", int((t["lado"] == "Compra (Long)").sum()))
col2.metric("Ventas (Short)", int((t["lado"] == "Venta (Short)").sum()))
col3.metric("Sin datos (falt√≥ ENTRY)", int((t["lado"].str.startswith("No definida")).sum()))

known = t[t["lado"].isin(["Compra (Long)", "Venta (Short)"])].copy()
if known.empty:
    st.info("No hay suficientes trades con ENTRY para separar Compra/Venta.")
else:
    side_tbl = group_metrics(known, "lado", min_trades=max(5, min_trades // 2))
    st.dataframe(side_tbl, use_container_width=True)
    advice_from_table(side_tbl, title="Compra/Venta", min_trades=max(5, min_trades // 2))

# ============================================================
# Tuning factors
# ============================================================
st.subheader("üõ†Ô∏è Ajuste de filtros (tunear settings con datos reales)")

if known.empty:
    st.info("Estos an√°lisis necesitan ENTRY (para tener ORSize/ATR/EWO/DeltaRatio por trade).")
else:
    df_known = known.copy()
    df_scatter = df_known.sort_values("exit_time")
    if last_n_scatter and last_n_scatter > 0:
        df_scatter = df_scatter.tail(last_n_scatter)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["OR Size", "ATR", "EWO", "Balance C/V", "Presi√≥n y Actividad"])

    with tab1:
        with st.expander("üìå OR Size: qu√© significa y c√≥mo usarlo"):
            st.write("OR Size = tama√±o del rango inicial (Opening Range).")
            st.write("- OR grande ‚Üí mercado m√°s 'movido'. Si tu PF cae aqu√≠, suele ser por whipsaws y entradas tard√≠as.")
            st.write("- OR peque√±o ‚Üí mercado m√°s 'apretado'. Si tu PF cae aqu√≠, suele ser por falta de recorrido.")
            st.write("Consejo: busca rangos con **PF>1**, **promedio > 0** y muestra üü¢ antes de convertirlo en filtro.")
        if "orSize" in df_known.columns and df_known["orSize"].notna().sum() > 30:
            plot_factor_bins(df_known, "orSize", q_bins, min_trades, recommended_trades, "OR Size (tama√±o del rango)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de OR Size en los logs.")

    with tab2:
        with st.expander("üìå ATR: qu√© significa y c√≥mo usarlo"):
            st.write("ATR = volatilidad (cu√°nto se mueve el precio en promedio).")
            st.write("- ATR alto ‚Üí movimientos amplios: necesitas stops/targets coherentes o te saca el ruido.")
            st.write("- ATR bajo ‚Üí poco recorrido: si tu TP es fijo, puede que no llegue.")
            st.write("Consejo: si tu estrategia tiene ATR engine, aqu√≠ ver√°s si te est√° ayudando o empeorando.")
        if "atr" in df_known.columns and df_known["atr"].notna().sum() > 30:
            plot_factor_bins(df_known, "atr", q_bins, min_trades, recommended_trades, "ATR (volatilidad)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de ATR en los logs.")

    with tab3:
        with st.expander("üìå EWO: qu√© significa y c√≥mo usarlo"):
            st.write("EWO (aqu√≠ usamos |EWO|) = fuerza de tendencia. M√°s alto suele implicar tendencia m√°s marcada.")
            st.write("- |EWO| alto ‚Üí tendencia: suele favorecer continuaciones/breakouts.")
            st.write("- |EWO| bajo ‚Üí chop/rango: suele castigar entradas por impulso.")
            st.write("Consejo: si ves PF<1 en |EWO| bajo, es un buen candidato a filtro de 'no-trade'.")
        if "ewo" in df_known.columns and df_known["ewo"].notna().sum() > 30:
            df_known2 = df_known.copy()
            df_known2["ewo_abs"] = df_known2["ewo"].abs()

            df_scatter2 = df_scatter.copy()
            df_scatter2["ewo_abs"] = df_scatter2["ewo"].abs()

            plot_factor_bins(df_known2, "ewo_abs", q_bins, min_trades, recommended_trades, "EWO (fuerza de tendencia)", show_adv_scatter, df_scatter2)
        else:
            st.info("No hay suficientes valores de EWO en los logs.")

    with tab4:
        with st.expander("üìå Balance comprador-vendedor: qu√© significa y c√≥mo usarlo"):
            st.write("Balance C/V = delta/vol (intensidad neta de compras vs ventas).")
            st.write("- Valores altos (en magnitud) ‚Üí desequilibrio fuerte (posible impulso).")
            st.write("- Cerca de 0 ‚Üí poca ventaja de flujo (m√°s f√°cil que el precio se 'devuelva').")
            st.write("Consejo: √∫salo para evitar entradas cuando no hay participaci√≥n real.")
        if "deltaRatio" in df_known.columns and df_known["deltaRatio"].notna().sum() > 30:
            plot_factor_bins(df_known, "deltaRatio", q_bins, min_trades, recommended_trades, "Balance comprador-vendedor (delta/vol)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de Balance C/V en los logs.")

    with tab5:
        st.markdown("### Qu√© es esto (en simple)")
        st.write(
            "Usamos los arrays pre-entrada (delta/volumen y OHLC de los √∫ltimos N segundos) para medir "
            "**actividad** y **presi√≥n** antes de entrar. Esto ayuda a detectar entradas 'con gasolina' "
            "vs entradas 'sin apoyo' o con **absorci√≥n**."
        )
        st.caption(
            "‚ö†Ô∏è OJO: con 40 trades esto es exploratorio. √ösalo para generar hip√≥tesis y valida con m√°s muestra."
        )

        needed_any = any(c in df_known.columns for c in ["pre_absorcion", "pre_actividad_rel", "pre_presion_por_vol", "pre_presion_sum"])
        if not needed_any:
            st.info("No veo arrays pre-entrada en tus logs (deltaLastN/volLastN/OHLC). Si est√°n, revisa que se est√©n logueando en ENTRY.")
        else:
            # Ajuste de bins m√°s conservador cuando la muestra es peque√±a
            q_small = min(q_bins, 6)

            colA, colB = st.columns(2)
            with colA:
                if "pre_absorcion" in df_known.columns and df_known["pre_absorcion"].notna().sum() > 20:
                    st.markdown("#### 1) Absorci√≥n (presi√≥n fuerte, avance peque√±o)")
                    plot_factor_bins(df_known, "pre_absorcion", q_small, min_trades, recommended_trades,
                                     "Absorci√≥n (presi√≥n fuerte + avance peque√±o)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Absorci√≥n'.")

            with colB:
                if "pre_actividad_rel" in df_known.columns and df_known["pre_actividad_rel"].notna().sum() > 20:
                    st.markdown("#### 2) Actividad (volumen relativo antes de entrar)")
                    plot_factor_bins(df_known, "pre_actividad_rel", q_small, min_trades, recommended_trades,
                                     "Actividad relativa (volumen hasta entrada vs mediana reciente)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Actividad relativa'.")

            st.markdown("#### 3) Se√±ales sin apoyo (precio avanza, presi√≥n va en contra)")
            if "pre_sin_apoyo" in df_known.columns:
                tmp = df_known.copy()
                tmp["Sin apoyo"] = np.where(tmp["pre_sin_apoyo"] == True, "S√≠", "No")
                tbl = group_metrics(tmp, "Sin apoyo", min_trades=min_trades, recommended_trades=recommended_trades)
                st.dataframe(tbl, use_container_width=True)

                # Consejos r√°pidos
                if not tbl.empty and "Grupo" in tbl.columns:
                    row_si = tbl[tbl["Grupo"] == "S√≠"]
                    row_no = tbl[tbl["Grupo"] == "No"]
                    if not row_si.empty and not row_no.empty:
                        exp_si = float(row_si.iloc[0]["Promedio por trade"])
                        exp_no = float(row_no.iloc[0]["Promedio por trade"])
                        if exp_si < exp_no:
                            st.warning("‚ö†Ô∏è Tus trades marcados como 'Sin apoyo = S√≠' rinden peor en promedio. Buen candidato para FILTRAR.")
                        else:
                            st.info("üü° Por ahora 'Sin apoyo' no empeora rendimiento, pero confirma con m√°s muestra.")
            else:
                st.info("No se detecta la bandera 'pre_sin_apoyo' (requiere arrays + dir).")

            st.markdown("### Pistas pr√°cticas (tuning)")
            st.write("‚úÖ Si **Actividad alta** + buen PF ‚Üí suele indicar entradas con participaci√≥n real.")
            st.write("üö´ Si **Absorci√≥n muy alta** + PF<1 ‚Üí suele ser 'lucha' / absorci√≥n antes del giro (candidato a evitar).")
            st.write("‚ö†Ô∏è Si 'Sin apoyo = S√≠' aparece mucho en p√©rdidas ‚Üí evita perseguir precio cuando el delta no acompa√±a.")


# ============================================================
# Hours
# ============================================================
st.subheader("‚è∞ Horarios (justo y confiable)")

hour_tbl = plot_hour_analysis(t, min_trades=min_trades)
plot_heatmap_weekday_hour(t, min_trades=min_trades)

st.markdown("### üß† Consejos autom√°ticos (Horarios)")
if hour_tbl is None or hour_tbl.empty:
    st.info("No hay datos suficientes por hora con el m√≠nimo configurado.")
else:
    best = hour_tbl.iloc[0]
    worst = hour_tbl.iloc[-1]

    st.info(
        f"üèÜ Hora recomendada: **{best['Grupo']}** | Trades={int(best['Trades'])} | "
        f"{traffic_pf(best['Profit Factor'])} | {traffic_exp(best['Promedio por trade'])}"
    )
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è La mejor hora a√∫n tiene muestra peque√±a. Confirma con m√°s logs.")

    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning(f"üö´ Hora candidata a evitar: **{worst['Grupo']}** (PF < 1 y promedio bajo).")

    st.caption("Regla de oro: prefiere horas con buen Score ponderado + buen PF + buena muestra, no solo winrate.")

# ============================================================
# ============================================================
# Entradas por d√≠a y orden del trade (tuning realista)
# ============================================================
st.subheader("üìÖ Entradas por d√≠a y orden del trade")
st.caption("Aqu√≠ miramos **cu√°ntas entradas haces por d√≠a** y si el **trade #1 / #2 / #3...** suele ser mejor o peor. "
           "Sirve para decisiones realistas como **MaxSetupsPerSession**, evitar el 'revenge trade' y cortar d√≠as malos.")

if "entry_time" in t.columns and t["entry_time"].notna().any():
    te = t.copy()
    te = te[te["entry_time"].notna()].copy()
    te = te.sort_values("entry_time").reset_index(drop=True)
    te["entry_date"] = te["entry_time"].dt.date
    te["entry_hour"] = te["entry_time"].dt.hour

    # Trades por d√≠a
    per_day = (te.groupby("entry_date", as_index=False)
                 .agg(trades=("tradeRealized","size"),
                      pnl=("tradeRealized","sum"),
                      winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    colA, colB, colC, colD = st.columns(4)
    colA.metric("Promedio trades / d√≠a", f"{per_day['trades'].mean():.2f}" if len(per_day) else "N/A")
    colB.metric("M√°ximo trades en un d√≠a", f"{int(per_day['trades'].max())}" if len(per_day) else "N/A")
    colC.metric("D√≠as con 3+ trades", f"{int((per_day['trades']>=3).sum())}" if len(per_day) else "0")
    colD.metric("D√≠as totales", f"{len(per_day)}")

    c1, c2 = st.columns([1,1])
    n_days = len(per_day)
    with c1:
        if n_days > 90:
            dist = per_day.groupby("trades", as_index=False).size().rename(columns={"size":"dias"})
            fig = px.bar(dist, x="trades", y="dias", title="Distribuci√≥n: # trades por d√≠a")
            fig.update_layout(xaxis_title="# trades en el d√≠a", yaxis_title="D√≠as")
            st.plotly_chart(fig, use_container_width=True)
            st.caption("Con muchos d√≠as, esta distribuci√≥n suele ser m√°s √∫til que una barra por fecha.")
        else:
            fig = px.bar(per_day, x="entry_date", y="trades", title="Trades por d√≠a")
            fig.update_layout(xaxis_title="D√≠a", yaxis_title="Trades")
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        fig = px.scatter(per_day, x="trades", y="pnl",
                         title="¬øM√°s trades = mejor d√≠a? (PnL d√≠a vs # trades)",
                         hover_data=["entry_date","winrate"])
        fig.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="PnL del d√≠a ($)")
        st.plotly_chart(fig, use_container_width=True)

        by_n = (per_day.groupby("trades", as_index=False)
                    .agg(dias=("entry_date","size"),
                         pnl_prom=("pnl","mean"),
                         pnl_med=("pnl","median")))
        fig2 = px.bar(by_n, x="trades", y="pnl_prom", color="pnl_prom",
                      color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                      title="Promedio PnL del d√≠a por # trades")
        fig2.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="Promedio PnL del d√≠a ($)")
        st.plotly_chart(fig2, use_container_width=True)

        try:
            mean_12 = by_n[by_n["trades"].isin([1,2])]["pnl_prom"].mean()
            mean_3p = by_n[by_n["trades"]>=3]["pnl_prom"].mean()
            n_3p_days = int(by_n[by_n["trades"]>=3]["dias"].sum()) if len(by_n[by_n["trades"]>=3]) else 0
            if pd.notna(mean_12) and pd.notna(mean_3p) and n_3p_days >= 5 and mean_3p < mean_12:
                st.warning("‚ö†Ô∏è En esta muestra, los d√≠as con **3+ trades** rinden peor en promedio. "
                           "Prueba en el Lab **M√°x trades/d√≠a = 2** o **MaxSetupsPerSession=2**.")
        except Exception:
            pass

    # Orden del trade dentro del d√≠a
    te["trade_num_day"] = te.groupby("entry_date").cumcount() + 1
    te["orden_trade"] = te["trade_num_day"].apply(lambda n: "1¬∫" if n==1 else ("2¬∫" if n==2 else ("3¬∫" if n==3 else "4¬∫+")))

    # Resumen por orden
    def _pf(sub):
        return profit_factor(sub) if len(sub) else np.nan

    by_order = (te.groupby("orden_trade", as_index=False)
                  .agg(trades=("tradeRealized","size"),
                       pnl_prom=("tradeRealized","mean"),
                       pnl_med=("tradeRealized","median"),
                       winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    # PF por orden
    pf_map = {k:_pf(v) for k,v in te.groupby("orden_trade")}
    by_order["pf"] = by_order["orden_trade"].map(pf_map)

    # Orden de presentaci√≥n
    orden_cat = ["1¬∫","2¬∫","3¬∫","4¬∫+"]
    by_order["orden_trade"] = pd.Categorical(by_order["orden_trade"], categories=orden_cat, ordered=True)
    by_order = by_order.sort_values("orden_trade")

    st.markdown("### üîé ¬øCu√°l trade del d√≠a suele ser el peor?")
    st.write("Si ves que **#3 o #4+** baja fuerte (PF<1 o promedio<0), suele ser se√±al de **sobre-trading**.")
    st.dataframe(by_order, use_container_width=True, hide_index=True)

    # Consejos r√°pidos por orden (con muestra m√≠nima)
    try:
        bo = by_order.copy()
        bo["orden_trade"] = bo["orden_trade"].astype(str)
        # Elegimos "peor" por promedio (y PF si existe)
        bo_sort = bo.sort_values(["pnl_prom"], ascending=True)
        worst_row = bo_sort.iloc[0] if len(bo_sort) else None
        if worst_row is not None and int(worst_row["trades"]) >= max(5, min_trades):
            if float(worst_row["pnl_prom"]) < 0:
                st.warning(f"‚ö†Ô∏è El **{worst_row['orden_trade']} trade** es el m√°s flojo en esta muestra "
                           f"(prom={float(worst_row['pnl_prom']):.0f}$, PF={float(worst_row['pf']):.2f}). "
                           "Candidato a **limitar setups** o a subir confirmaci√≥n despu√©s de 1‚Äì2 trades.")
        # Si 4¬∫+ existe y es negativo con algo de muestra
        row4 = bo[bo["orden_trade"]=="4¬∫+"]
        if len(row4) and int(row4.iloc[0]["trades"]) >= max(5, min_trades) and float(row4.iloc[0]["pnl_prom"]) < 0:
            st.warning("üö´ Los trades **4¬∫+** salen negativos en promedio con muestra suficiente: "
                       "muy t√≠pico de **sobre-trading**. Prueba **MaxSetupsPerSession=2** o **M√°x trades/d√≠a=2** en el Lab.")
    except Exception:
        pass

    fig = px.bar(by_order, x="orden_trade", y="pnl_prom", color="pnl_prom",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                 title="Promedio por trade seg√∫n orden en el d√≠a")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Promedio PnL por trade ($)")
    st.plotly_chart(fig, use_container_width=True)

    fig = px.bar(by_order, x="orden_trade", y="pf", color="pf",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=1.0,
                 title="Profit Factor seg√∫n orden en el d√≠a")
    fig.add_hline(y=1.0, line_dash="dash")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Profit Factor")
    st.plotly_chart(fig, use_container_width=True)

    # Heatmap: hora vs orden (promedio y conteo)
    st.markdown("### üïí Hora de entrada vs orden del trade")
    st.write("√ötil para detectar cosas tipo: **'el 2¬∫ trade despu√©s de cierta hora es malo'**.")
    tmp = te.copy()
    tmp["h"] = tmp["entry_hour"].astype("Int64")
    tmp["ord"] = tmp["orden_trade"].astype(str)
    pivot_mean = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="mean")
    pivot_n = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="size")

    # Solo mostramos si hay algo
    if pivot_mean.notna().sum().sum() > 0:
        # Formatear horas como HH:00 para que el eje sea legible (y no salga 9.5, 10.5, etc.)
        pivot_mean = pivot_mean.sort_index(axis=1)
        pivot_n = pivot_n.reindex(columns=pivot_mean.columns)

        hour_labels = [f"{int(h):02d}:00" for h in pivot_mean.columns]
        pivot_mean.columns = hour_labels
        pivot_n.columns = hour_labels

        # Texto dentro de cada celda: "promedio (n=..)"
        text = pivot_mean.copy()
        for r in text.index:
            for c in text.columns:
                a = pivot_mean.loc[r, c]
                n = pivot_n.loc[r, c]
                if pd.isna(a) or pd.isna(n) or n == 0:
                    text.loc[r, c] = ""
                else:
                    text.loc[r, c] = f"{a:.0f} (n={int(n)})"

        try:
            fig = px.imshow(
                pivot_mean,
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                aspect="auto",
            )
            fig.update_traces(
                text=text,
                texttemplate="%{text}",
                customdata=pivot_n.values,
                hovertemplate="Hora: %{x}<br>Orden: %{y}<br>Promedio: %{z:.0f}$<br>n=%{customdata}<extra></extra>",
            )
            fig.update_layout(
                title="Heatmap (promedio PnL $) ‚Äî muestra por celda",
                xaxis_title="Hora (entrada)",
                yaxis_title="Orden del trade",
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.info("Tu versi√≥n de Plotly no soporta este heatmap con texto. (No afecta el an√°lisis.)")
    else:
        st.info("No hay suficientes datos con hora de entrada para el heatmap.")
else:
    st.info("No hay entry_time en los datos (faltan logs ENTRY). Esta secci√≥n necesita ENTRY.")

# ============================================================
# üß™ Lab: Simulador de reglas diarias y filtros (tuning realista)
# ============================================================
st.subheader("üß™ Lab: Simulador de reglas diarias y filtros")
st.caption("Simula reglas reales: **MaxLoss/MaxProfit por d√≠a**, **m√°ximo trades por d√≠a**, **racha de p√©rdidas**, y filtros (OR/EWO/ATR/Absorci√≥n/Actividad). "
           "La simulaci√≥n es 'what-if': te dice c√≥mo habr√≠a cambiado tu curva con esas reglas.")
def _hour_label(h: int) -> str:
    """Etiqueta humana para una hora completa (ej: 9:00‚Äì9:59 AM)."""
    h = int(h)
    ampm = "AM" if h < 12 else "PM"
    h12 = h % 12
    if h12 == 0:
        h12 = 12
    return f"{h12}:00‚Äì{h12}:59 {ampm}"

def _finite_minmax(s: pd.Series):
    s2 = pd.to_numeric(s, errors="coerce")
    s2 = s2[np.isfinite(s2)]
    if s2.empty:
        return None, None
    return float(s2.min()), float(s2.max())



def _lab_quick_suggestions(t):
    """
    Sugerencias r√°pidas basadas SOLO en tu historial REAL (sin reglas ni filtros del lab).

    Devuelve:
      {"filters": [(titulo, texto), ...], "rules": [(titulo, texto), ...]}
    """
    out = {"filters": [], "rules": []}
    if t is None or getattr(t, "empty", True):
        return out

    base = t.copy()

    # --- Columnas robustas para an√°lisis ---
    # Hora: prioriza entry_time, si falta usa exit_time, y si no existe usa _lab_ts.
    hour = None
    if "entry_time" in base.columns and pd.api.types.is_datetime64_any_dtype(base["entry_time"]):
        hour = base["entry_time"].dt.hour
    elif "_lab_ts" in base.columns and pd.api.types.is_datetime64_any_dtype(base["_lab_ts"]):
        hour = base["_lab_ts"].dt.hour
    else:
        hour = pd.Series(np.nan, index=base.index)

    if "exit_time" in base.columns and pd.api.types.is_datetime64_any_dtype(base["exit_time"]):
        hour = hour.where(~hour.isna(), base["exit_time"].dt.hour)

    base["_hour"] = pd.to_numeric(hour, errors="coerce")

    # Direcci√≥n: usa dir num√©rico si existe; si no, intenta inferir de 'lado'.
    if "dir" in base.columns:
        dir_num = pd.to_numeric(base["dir"], errors="coerce")
    elif "tradeDirection" in base.columns:
        dir_num = pd.to_numeric(base["tradeDirection"], errors="coerce")
    else:
        dir_num = pd.Series(np.nan, index=base.index)

    base["_dir_num"] = dir_num
    base["_dir_label"] = np.where(
        base["_dir_num"] > 0,
        "Compra",
        np.where(base["_dir_num"] < 0, "Venta", "No definida")
    )

    if "lado" in base.columns:
        lado = base["lado"].astype(str)
        base["_dir_label"] = np.where(
            lado.str.contains("Compra", na=False),
            "Compra",
            np.where(lado.str.contains("Venta", na=False), "Venta", base["_dir_label"])
        )

    # Asegura tradeRealized num√©rico
    if "tradeRealized" in base.columns:
        base["tradeRealized"] = pd.to_numeric(base["tradeRealized"], errors="coerce")

    # --- 1) Horas sugeridas (bloque HH:00‚ÄìHH:59) ---
    min_n_hour = 5
    if "_hour" in base.columns and "tradeRealized" in base.columns:
        tmp = base.dropna(subset=["_hour", "tradeRealized"]).copy()
        if not tmp.empty:
            tmp["_hour"] = tmp["_hour"].astype(int)
            g = tmp.groupby("_hour")["tradeRealized"].agg(["count", "mean"])
            g = g[g["count"] >= min_n_hour]
            if len(g) >= 2:
                best = g.sort_values("mean", ascending=False).head(2).index.tolist()
                worst = g.sort_values("mean", ascending=True).head(2).index.tolist()

                def _fmt_hour(h):
                    return f"{int(h):02d}:00‚Äì{int(h):02d}:59"

                best_lbl = ", ".join(_fmt_hour(h) for h in best)
                worst_lbl = ", ".join(_fmt_hour(h) for h in worst)

                out["filters"].append((
                    "üïí Horas",
                    f"Sugerido: {best_lbl}. Evitar: {worst_lbl}. (n‚â•{min_n_hour} por hora)"
                ))
            else:
                out["filters"].append((
                    "üïí Horas",
                    f"No concluyente (necesitas n‚â•{min_n_hour} por bloque horario)."
                ))
        else:
            out["filters"].append(("üïí Horas", "No concluyente (no hay timestamps suficientes)."))

    # --- 2) Direcci√≥n sugerida (Compra/Venta/No definida) ---
    min_n_dir = 10
    if "_dir_label" in base.columns and "tradeRealized" in base.columns:
        d = base.dropna(subset=["tradeRealized"]).copy()
        if not d.empty:
            stats = d.groupby("_dir_label")["tradeRealized"].agg(["count", "mean"])
            buy_n = int(stats.loc["Compra", "count"]) if "Compra" in stats.index else 0
            sell_n = int(stats.loc["Venta", "count"]) if "Venta" in stats.index else 0
            buy_mean = float(stats.loc["Compra", "mean"]) if "Compra" in stats.index else np.nan
            sell_mean = float(stats.loc["Venta", "mean"]) if "Venta" in stats.index else np.nan

            msg = f"Compra prom: {buy_mean:.1f} (n={buy_n}) | Venta prom: {sell_mean:.1f} (n={sell_n})."
            # Recomendaci√≥n simple si hay muestra suficiente en ambos lados
            if buy_n >= min_n_dir and sell_n >= min_n_dir and not (np.isnan(buy_mean) or np.isnan(sell_mean)):
                if buy_mean > sell_mean * 1.15:
                    msg += " ‚Üí Hist√≥ricamente te va mejor en **Compra**."
                elif sell_mean > buy_mean * 1.15:
                    msg += " ‚Üí Hist√≥ricamente te va mejor en **Venta**."
                else:
                    msg += " ‚Üí Diferencia peque√±a (no concluyente)."
            else:
                msg += f" (Recomendaci√≥n requiere n‚â•{min_n_dir} por lado)."

            out["filters"].append(("üìà Direcci√≥n", msg))

    # --- 3) OR/ATR sugeridos (por cuantiles; usa PF) ---
    def _suggest_range_by_pf(col, label):
        if col not in base.columns or "tradeRealized" not in base.columns:
            return None
        x = pd.to_numeric(base[col], errors="coerce")
        y = pd.to_numeric(base["tradeRealized"], errors="coerce")
        tmp = pd.DataFrame({"x": x, "y": y}).dropna()
        if len(tmp) < 30:
            return None

        # 3 buckets por cuantiles (evita 'bin' en texto)
        try:
            tmp["grp"] = pd.qcut(tmp["x"], q=3, duplicates="drop")
        except Exception:
            return None

        rows = []
        for grp, g in tmp.groupby("grp"):
            n = len(g)
            pf = profit_factor(g["y"])
            if pd.isna(pf):
                continue
            rows.append((grp.left, grp.right, float(pf), int(n)))

        if len(rows) < 2:
            return None

        rows = sorted(rows, key=lambda r: r[2], reverse=True)
        best = rows[0]
        worst = rows[-1]

        def _rng(a, b):
            return f"{a:.2f}‚Äì{b:.2f}"

        return f"{label}: { _rng(best[0], best[1]) } (PF {best[2]:.2f}, n={best[3]}) | evitar { _rng(worst[0], worst[1]) } (PF {worst[2]:.2f}, n={worst[3]})."

    or_msg = _suggest_range_by_pf("orSize", "OR sugerido")
    if or_msg:
        out["filters"].append(("üß± OR", or_msg))

    atr_msg = _suggest_range_by_pf("atr", "ATR sugerido")
    if atr_msg:
        out["filters"].append(("üìè ATR", atr_msg))

    # --- 4) Reglas sugeridas (Daily Guard): M√°x trades/d√≠a / M√°x p√©rdidas seguidas ---
    if "tradeRealized" in base.columns:
        base_pnl = float(pd.to_numeric(base["tradeRealized"], errors="coerce").fillna(0).sum())
        dd_base = _dd_mag_from_df(base)

        # candidatos seg√∫n distribuci√≥n real (acota a algo razonable)
        if "entry_time" in base.columns and pd.api.types.is_datetime64_any_dtype(base["entry_time"]):
            dt_for_day = base["entry_time"]
        elif "exit_time" in base.columns and pd.api.types.is_datetime64_any_dtype(base["exit_time"]):
            dt_for_day = base["exit_time"]
        else:
            dt_for_day = None

        if dt_for_day is not None:
            day_counts = dt_for_day.dt.date.value_counts()
            max_obs = int(day_counts.max()) if len(day_counts) else 0
        else:
            max_obs = 0

        cand_trades = [v for v in [1, 2, 3, 4, 5] if max_obs == 0 or v <= max(1, max_obs)]
        cand_losses = [1, 2, 3, 4]

        min_days_rule = 5  # antes estaba muy alto; con n‚â•5 ya se puede sugerir algo

        def _best_rule(kind, candidates):
            results = []
            for val in candidates:
                if kind == "max_trades":
                    sim_df, stops_df = _simulate_daily_rules(
                        base, max_loss=0, max_profit=0, max_trades=val, max_consec_losses=0,
                        stop_big_loss=False, stop_big_win=False
                    )
                    label = f"M√°x trades/d√≠a = {val}"
                else:
                    sim_df, stops_df = _simulate_daily_rules(
                        base, max_loss=0, max_profit=0, max_trades=0, max_consec_losses=val,
                        stop_big_loss=False, stop_big_win=False
                    )
                    label = f"M√°x p√©rdidas seguidas = {val}"

                sim_pnl = float(pd.to_numeric(sim_df["tradeRealized"], errors="coerce").fillna(0).sum()) if (sim_df is not None and not sim_df.empty and "tradeRealized" in sim_df.columns) else 0.0
                dd_sim = _dd_mag_from_df(sim_df) if (sim_df is not None and not sim_df.empty) else np.nan

                delta_pnl = sim_pnl - base_pnl
                mejora_dd = (dd_base - dd_sim) if (not np.isnan(dd_base) and not np.isnan(dd_sim)) else np.nan

                days_cut = 0
                if stops_df is not None and not stops_df.empty and "fecha" in stops_df.columns:
                    days_cut = int(pd.to_datetime(stops_df["fecha"], errors="coerce").dt.date.nunique())

                # score ponderado simple (mismo signo: mejor)
                score = delta_pnl + (0.35 * (mejora_dd if not np.isnan(mejora_dd) else 0.0))
                results.append((score, days_cut, label, delta_pnl, mejora_dd))

            # elige el mejor score; si hay empate, el que se activ√≥ m√°s d√≠as
            results.sort(key=lambda r: (r[0], r[1]), reverse=True)
            best = results[0] if results else None
            return best

        # M√°x trades/d√≠a
        best_tr = _best_rule("max_trades", cand_trades)
        if best_tr:
            score, days_cut, label, delta_pnl, mejora_dd = best_tr
            if days_cut < min_days_rule:
                out["rules"].append(("üéõÔ∏è M√°x trades/d√≠a", f"{label}: no concluyente (activada {days_cut} d√≠as)."))
            else:
                quad = "Mejora PnL y DD" if (delta_pnl > 0 and (not np.isnan(mejora_dd) and mejora_dd > 0)) \
                       else "Mejora PnL pero empeora DD" if (delta_pnl > 0) \
                       else "Reduce DD pero cuesta PnL" if (not np.isnan(mejora_dd) and mejora_dd > 0) \
                       else "Empeora PnL y DD"
                out["rules"].append((
                    "üéõÔ∏è M√°x trades/d√≠a",
                    f"{label} ‚Üí {quad} (ŒîPnL {delta_pnl:+.0f}, ŒîDD {mejora_dd:+.0f}, d√≠as={days_cut})."
                ))

        # M√°x p√©rdidas seguidas
        best_ls = _best_rule("max_losses", cand_losses)
        if best_ls:
            score, days_cut, label, delta_pnl, mejora_dd = best_ls
            if days_cut < min_days_rule:
                out["rules"].append(("üßØ M√°x p√©rdidas seguidas", f"{label}: no concluyente (activada {days_cut} d√≠as)."))
            else:
                quad = "Mejora PnL y DD" if (delta_pnl > 0 and (not np.isnan(mejora_dd) and mejora_dd > 0)) \
                       else "Mejora PnL pero empeora DD" if (delta_pnl > 0) \
                       else "Reduce DD pero cuesta PnL" if (not np.isnan(mejora_dd) and mejora_dd > 0) \
                       else "Empeora PnL y DD"
                out["rules"].append((
                    "üßØ M√°x p√©rdidas seguidas",
                    f"{label} ‚Üí {quad} (ŒîPnL {delta_pnl:+.0f}, ŒîDD {mejora_dd:+.0f}, d√≠as={days_cut})."
                ))

    return out

def _apply_filters(df_in: pd.DataFrame):
    """
    Lab filters (opcional) aplicados ANTES de simular reglas diarias.
    Devuelve: (df_filtrado, notas:list[str])
    """
    df = df_in.copy()
    notes: list[str] = []

    # --- toggle: incluir trades con datos faltantes (NaN) ---
    include_missing = bool(st.session_state.get("lab_include_missing", True))

    # --- timestamp por fila para filtrar horas (ENTRY preferido, si no EXIT) ---
    ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
    ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)

    df["_lab_ts"] = ts_entry
    # fallback a EXIT solo para filas sin ENTRY
    df.loc[df["_lab_ts"].isna(), "_lab_ts"] = ts_exit[df["_lab_ts"].isna()]
    df["_lab_hour"] = pd.to_datetime(df["_lab_ts"], errors="coerce").dt.hour

    # horas disponibles seg√∫n dataset (si no hay nada, 0..23)
    avail_hours = sorted([int(x) for x in df["_lab_hour"].dropna().unique().tolist()])
    if len(avail_hours) == 0:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours] if "_hour_label" in globals() else [f"{h:02d}:00‚Äì{h:02d}:59" for h in avail_hours]
    label_to_hour = {lab: h for lab, h in zip(hour_labels, avail_hours)}

    # --- helper UI: slider rango basado en min/max del dataset ---
    def _range_slider_for(col: str, key: str, title: str, unit_hint: str = ""):
        if col not in df.columns:
            return None
        lo0, hi0 = _finite_minmax(df[col]) if "_finite_minmax" in globals() else (None, None)
        if lo0 is None or hi0 is None:
            return None
        # default: rango completo (no filtra)
        default = st.session_state.get(key, (float(lo0), float(hi0)))
        try:
            default = (float(default[0]), float(default[1]))
        except Exception:
            default = (float(lo0), float(hi0))

        step = max((float(hi0) - float(lo0)) / 200.0, 0.01)
        label = f"{title}" + (f" ({unit_hint})" if unit_hint else "")
        rng = st.slider(label, float(lo0), float(hi0), default, step=step, key=key)
        return rng

    # --- helper: aplicar rango inclusivo (con opci√≥n de incluir NaN) ---
    def _apply_range_mask(dfx: pd.DataFrame, col: str, rng):
        if col not in dfx.columns or rng is None:
            return dfx
        lo, hi = rng
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = (s >= float(lo)) & (s <= float(hi))
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- helper: threshold m√≠nimo (>=) ---
    def _apply_min_mask(dfx: pd.DataFrame, col: str, thr):
        if col not in dfx.columns or thr is None:
            return dfx
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = s >= float(thr)
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- UI ---
    with st.container():
        st.markdown("### Filtros (opcional)")
        st.caption("Estos filtros afectan **solo** la simulaci√≥n. En Reset no deber√≠an eliminar nada.")

        include_missing = st.checkbox(
            "Incluir trades con datos faltantes (NaN) en filtros (recomendado)",
            value=include_missing,
            key="lab_include_missing",
            help="Si un trade no tiene ENTRY (o alg√∫n indicador), aparecer√° como 'Sin datos'. Activado = no se excluye por defecto."
        )

        # Direcci√≥n (Compra/Venta)
        dir_col = None
        for c in ["dir", "tradeDirection", "direction"]:
            if c in df.columns:
                dir_col = c
                break

        if dir_col:
            dnum = pd.to_numeric(df[dir_col], errors="coerce")
        else:
            dnum = pd.Series(np.nan, index=df.index)

        is_long = dnum > 0
        is_short = dnum < 0
        is_unknown = dnum.isna() | (dnum == 0)

        dir_opts = ["Venta", "Compra", "No definida"]
        dir_default = st.session_state.get("lab_dirs_allowed", dir_opts) or []
        dir_default = [x for x in dir_default if x in dir_opts]
        if not dir_default:
            dir_default = dir_opts
        sel_dirs = st.multiselect("Direcci√≥n permitida (entrada)", dir_opts, default=dir_default, key="lab_dirs_allowed")

        # Horas (ENTRY preferido; si falta, EXIT como respaldo)
        # Nota Streamlit: `default` debe ser subconjunto de `options`.
        if not hour_labels:
            st.info("No se detectaron horas v√°lidas (faltan timestamps en ENTRY/EXIT). Se omite el filtro por hora.")
            sel_hours = None
        else:
            default_hours = st.session_state.get("lab_hours_allowed", hour_labels) or []
            default_hours = [x for x in default_hours if x in hour_labels]
            if not default_hours:
                default_hours = hour_labels
            sel_hour_labels = st.multiselect(
                "Horas permitidas (entrada)",
                options=hour_labels,
                default=default_hours,
                key="lab_hours_allowed",
                help="Cada hora representa el bloque completo HH:00‚ÄìHH:59. Si falta ENTRY, se usa EXIT como respaldo."
            )
            sel_hours = [label_to_hour[x] for x in sel_hour_labels if x in label_to_hour]

        # Rangos (si existen columnas)
        or_rng = _range_slider_for("orSize", "lab_or_rng", "OR Size permitido", unit_hint="(seg√∫n tu log)")
        atr_rng = _range_slider_for("atr", "lab_atr_rng", "ATR permitido", unit_hint="(seg√∫n tu log)")

        # EWO (umbral m√≠nimo sobre |EWO|)
        ewo_col = "ewo" if "ewo" in df.columns else ("ewoMag" if "ewoMag" in df.columns else None)
        ewo_thr = None
        if ewo_col:
            ewo_abs = pd.to_numeric(df[ewo_col], errors="coerce").abs()
            lo_ewo, hi_ewo = _finite_minmax(ewo_abs) if "_finite_minmax" in globals() else (None, None)
            if lo_ewo is not None and hi_ewo is not None:
                ewo_thr = st.slider("|EWO| m√≠nimo", float(lo_ewo), float(hi_ewo), float(st.session_state.get("lab_ewo_thr", float(lo_ewo))), step=max((float(hi_ewo)-float(lo_ewo))/200.0, 0.0001), key="lab_ewo_thr")

        # Absorci√≥n / Actividad (si existen)
        abs_max = None
        if "absorption" in df.columns:
            lo_a, hi_a = _finite_minmax(df["absorption"]) if "_finite_minmax" in globals() else (None, None)
            if lo_a is not None and hi_a is not None:
                abs_max = st.slider("Absorci√≥n m√°xima (evitar extremos)", float(lo_a), float(hi_a), float(st.session_state.get("lab_abs_max", float(hi_a))), step=max((float(hi_a)-float(lo_a))/200.0, 0.01), key="lab_abs_max")

        act_min = None
        if "activity_rel" in df.columns:
            lo_r, hi_r = _finite_minmax(df["activity_rel"]) if "_finite_minmax" in globals() else (None, None)
            if lo_r is not None and hi_r is not None:
                act_min = st.slider("Actividad m√≠nima (volumen relativo antes de entrar)", float(lo_r), float(hi_r), float(st.session_state.get("lab_act_min", float(lo_r))), step=max((float(hi_r)-float(lo_r))/200.0, 0.0001), key="lab_act_min")

        # Evitar "sin apoyo" (si existe una columna compatible)
        no_support_col = None
        for c in ["noSupport", "sinApoyo", "no_support", "no_support_flag"]:
            if c in df.columns:
                no_support_col = c
                break
        avoid_no_support = False
        if no_support_col:
            avoid_no_support = st.checkbox("Evitar 'sin apoyo' (presi√≥n vs avance en contra)", value=bool(st.session_state.get("lab_avoid_no_support", False)), key="lab_avoid_no_support")

    # --- aplicar filtros ---
    # Direcci√≥n
    dir_mask = pd.Series(False, index=df.index)
    if "Compra" in sel_dirs:
        dir_mask |= is_long
    if "Venta" in sel_dirs:
        dir_mask |= is_short
    if "No definida" in sel_dirs:
        dir_mask |= is_unknown
    if dir_mask.any():
        df = df[dir_mask].copy()
    else:
        notes.append("‚ö†Ô∏è No seleccionaste ninguna direcci√≥n; se ignora el filtro de direcci√≥n.")

    # Horas
    if (sel_hours is not None) and (len(sel_hours) > 0) and "_lab_hour" in df.columns:
        h = pd.to_numeric(df["_lab_hour"], errors="coerce")
        hmask = h.isin(sel_hours)
        if include_missing:
            hmask = hmask | h.isna()
        df = df[hmask].copy()

    # Rangos
    df = _apply_range_mask(df, "orSize", or_rng)
    df = _apply_range_mask(df, "atr", atr_rng)

    # EWO min
    if ewo_col and ewo_thr is not None:
        s = pd.to_numeric(df[ewo_col], errors="coerce").abs()
        mask = s >= float(ewo_thr)
        if include_missing:
            mask = mask | s.isna()
        df = df[mask].copy()

    # Absorci√≥n max
    if "absorption" in df.columns and abs_max is not None:
        s = pd.to_numeric(df["absorption"], errors="coerce")
        mask = s <= float(abs_max)
        if include_missing:
            mask = mask | s.isna()
        df = df[mask].copy()

    # Actividad min
    if "activity_rel" in df.columns and act_min is not None:
        df = _apply_min_mask(df, "activity_rel", act_min)

    # Evitar sin apoyo
    if no_support_col and avoid_no_support:
        s = df[no_support_col]
        # tratamos True/1/"true" como "sin apoyo" (mal) -> excluir
        bad = s.astype(str).str.lower().isin(["1", "true", "t", "y", "yes"])
        if include_missing:
            bad = bad.fillna(False)
        df = df[~bad].copy()

    return df, notes


# ============================================================
# Lab: simulaci√≥n de reglas diarias (Daily Guard "what-if")
# ============================================================
def _simulate_daily_rules(df: pd.DataFrame,
                          max_loss: float = 0.0,
                          max_profit: float = 0.0,
                          max_trades: int = 0,
                          max_consec_losses: int = 0,
                          stop_big_loss: bool = False,
                          stop_big_win: bool = False):
    """Simula reglas diarias sobre un DataFrame de trades.

    Devuelve:
      - kept_df: trades que "habr√≠an ocurrido" con esas reglas
      - stops_df: 1 fila por d√≠a donde se activ√≥ un corte (motivo + cu√°ntos trades se omitieron)

    Reglas (si valor == 0 / False => no aplica):
      - max_loss: corta si PnL acumulado del d√≠a <= -max_loss
      - max_profit: corta si PnL acumulado del d√≠a >= max_profit
      - max_trades: corta tras ejecutar N trades en el d√≠a
      - max_consec_losses: corta tras N p√©rdidas seguidas
      - stop_big_loss: corta tras un trade con RR <= -1
      - stop_big_win: corta tras un trade con RR >= 2

    Nota:
      - Se ordena por entry_time si existe; si no, por exit_time.
      - Trades sin timestamp no se pueden asignar a un d√≠a: se dejan pasar (no se recortan).
    """
    if df is None or df.empty:
        return (df.copy() if df is not None else pd.DataFrame()), pd.DataFrame()

    work = df.copy()

    time_col = "entry_time" if "entry_time" in work.columns else ("exit_time" if "exit_time" in work.columns else None)
    if time_col is None:
        # Sin tiempo no podemos simular "por d√≠a"
        return work, pd.DataFrame()

    # Asegurar datetime
    if not np.issubdtype(work[time_col].dtype, np.datetime64):
        work[time_col] = pd.to_datetime(work[time_col], errors="coerce")

    with_time = work[work[time_col].notna()].copy()
    no_time = work[work[time_col].isna()].copy()

    if with_time.empty:
        return work, pd.DataFrame()

    with_time = with_time.sort_values(time_col)
    with_time["day"] = with_time[time_col].dt.date

    kept_idx = []
    stop_rows = []

    # Prioridad cuando varias reglas se disparan en el mismo trade
    def _pick_motivo(candidates):
        priority = [
            "Max p√©rdida/d√≠a",
            "Max ganancia/d√≠a",
            "M√°x trades/d√≠a",
            f"{max_consec_losses} p√©rdidas seguidas" if max_consec_losses > 0 else None,
            "Stop‚Äëout fuerte (‚â§ -1R)",
            "Cierre tras ganador grande (‚â• 2R)",
        ]
        priority = [p for p in priority if p is not None]
        for p in priority:
            if p in candidates:
                return p
        return candidates[0] if candidates else "Regla"

    for d, sub in with_time.groupby("day", sort=False):
        pnl_cum = 0.0
        consec_losses = 0
        executed = 0
        stopped = False

        rows = sub.to_dict("records")
        for i, r in enumerate(rows):
            # "Ejecutamos" este trade
            executed += 1
            idx = sub.index[i]
            kept_idx.append(idx)

            pnl = float(r.get("tradeRealized", 0.0) or 0.0)
            pnl_cum += pnl

            if pnl < 0:
                consec_losses += 1
            else:
                consec_losses = 0

            rr = r.get("rr", np.nan)
            try:
                rr = float(rr) if rr is not None else np.nan
            except Exception:
                rr = np.nan

            # ¬øAlguna regla se activ√≥ tras este trade?
            fired = []

            if max_trades and max_trades > 0 and executed >= int(max_trades):
                fired.append("M√°x trades/d√≠a")

            if max_loss and max_loss > 0 and pnl_cum <= -float(max_loss):
                fired.append("Max p√©rdida/d√≠a")

            if max_profit and max_profit > 0 and pnl_cum >= float(max_profit):
                fired.append("Max ganancia/d√≠a")

            if max_consec_losses and max_consec_losses > 0 and consec_losses >= int(max_consec_losses):
                fired.append(f"{int(max_consec_losses)} p√©rdidas seguidas")

            if stop_big_loss and not np.isnan(rr) and rr <= -1.0:
                fired.append("Stop‚Äëout fuerte (‚â§ -1R)")

            if stop_big_win and not np.isnan(rr) and rr >= 2.0:
                fired.append("Cierre tras ganador grande (‚â• 2R)")

            if fired and not stopped:
                motivo = _pick_motivo(fired)
                trades_omitidos = max(0, len(sub) - executed)
                stop_rows.append({
                    "fecha": d,      # compat
                    "day": d,        # compat
                    "motivo": motivo,
                    "trades_ejecutados": executed,
                    "trades_filtrados_por_stop": trades_omitidos,
                })
                stopped = True
                break

        # si stopped, no a√±adimos el resto de idx
        # si no stopped, el loop ya a√±adi√≥ todos

    kept_df = work.loc[kept_idx].copy()
    # A√±adimos los trades sin timestamp (no se pueden cortar por d√≠a)
    if not no_time.empty:
        kept_df = pd.concat([kept_df, no_time], ignore_index=False)

    # Orden final estable por el mismo time_col (si existe)
    if time_col in kept_df.columns:
        try:
            kept_df = kept_df.sort_values(time_col)
        except Exception:
            pass

    stops_df = pd.DataFrame(stop_rows)
    return kept_df, stops_df

def _reset_lab_state(base_df: pd.DataFrame):
    """Resetea el Lab para que arranque 1:1 con el Resumen r√°pido (REAL vs SIMULADO sin cortes)."""
    if base_df is None:
        base_df = pd.DataFrame()

    # -------------------- Reglas (0 = sin l√≠mite) --------------------
    st.session_state["lab_max_loss"] = 0.0
    st.session_state["lab_max_profit"] = 0.0
    st.session_state["lab_max_trades"] = 0
    st.session_state["lab_max_consec_losses"] = 0
    st.session_state["lab_stop_big_loss"] = False
    st.session_state["lab_stop_big_win"] = False

    # -------------------- Helpers --------------------
    def _minmax(col: str, default=(0.0, 1.0)):
        if col in base_df.columns:
            mn, mx = _finite_minmax(base_df[col])
            if mn is None or mx is None:
                return default
            if mn == mx:
                # Evita sliders degenerados (mismo min/max)
                eps = 1e-9 if mn == 0 else abs(mn) * 1e-6
                return float(mn - eps), float(mx + eps)
            return float(mn), float(mx)
        return default

    def _min_abs(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            s = s.abs()
            return float(s.min())
        return default

    def _min_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.min())
        return default

    def _max_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.max())
        return default

    # -------------------- Filtros (opcionales) --------------------
        # Horas disponibles desde tu dataset (ENTRY preferido, si falta usa EXIT)
    ts_entry = pd.to_datetime(base_df["entry_time"], errors="coerce") if "entry_time" in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_exit  = pd.to_datetime(base_df["exit_time"],  errors="coerce") if "exit_time"  in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_lab   = ts_entry.fillna(ts_exit)

    if ts_lab.notna().any():
        avail_hours = sorted([int(h) for h in ts_lab.dt.hour.dropna().unique().tolist()])
    else:
        avail_hours = list(range(24))
    if not avail_hours:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours]
    st.session_state["lab_hours_allowed"] = hour_labels[:]
    st.session_state["lab_dirs_allowed"] = ["Compra", "Venta", "No definida"]
    st.session_state["lab_include_missing"] = True


    # Rangos num√©ricos -> por defecto NO filtra (rango completo / umbral m√≠nimo)
    st.session_state["lab_or_rng"] = _minmax("orSize")
    st.session_state["lab_atr_rng"] = _minmax("atr")
    st.session_state["lab_ewo_thr"] = _min_abs("ewo", default=0.0)
    st.session_state["lab_abs_max"] = _max_val("pre_absorcion", default=0.0)
    st.session_state["lab_act_min"] = _min_val("pre_actividad_rel", default=0.0)
    st.session_state["lab_avoid_sin_apoyo"] = False



reset_col, reset_info = st.columns([1, 3])
with reset_col:
    if st.button("üîÑ Reset experimento", help="Resetea TODO (reglas sin l√≠mite + sin filtros) para que el Lab coincida 1:1 con el Resumen r√°pido."):
        _reset_lab_state(t)
with reset_info:
    st.caption("Idea: el Lab **empieza igual que el Resumen r√°pido**. Luego ajustas reglas/filtros para ver el impacto (what‚Äëif).")

lab_left, lab_right = st.columns([1, 1])

with lab_left:
    st.markdown("**Reglas diarias**")
    max_loss = st.number_input(
        "Max p√©rdida por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_loss", 0.0)), step=50.0,
        key="lab_max_loss",
        help="0 = sin l√≠mite. Si el d√≠a llega a -MaxLoss, se corta el trading del d√≠a."
    )
    max_profit = st.number_input(
        "Max ganancia por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_profit", 0.0)), step=100.0,
        key="lab_max_profit",
        help="0 = sin l√≠mite. Si el d√≠a llega a +MaxProfit, se corta el trading del d√≠a."
    )
    max_trades = st.slider("M√°x trades por d√≠a (0 = sin l√≠mite)", min_value=0, max_value=10,
                           value=int(st.session_state.get("lab_max_trades", 0)), key="lab_max_trades")
    max_consec_losses = st.slider("M√°x p√©rdidas seguidas (0 = sin l√≠mite)", min_value=0, max_value=10,
                                  value=int(st.session_state.get("lab_max_consec_losses", 0)), key="lab_max_consec_losses")
    stop_big_loss = st.checkbox("Cortar el d√≠a tras un stop-out fuerte (RR ‚â§ -1)", value=bool(st.session_state.get("lab_stop_big_loss", False)),
                                key="lab_stop_big_loss")
    stop_big_win = st.checkbox("Cortar el d√≠a tras un ganador grande (RR ‚â• 2)", value=bool(st.session_state.get("lab_stop_big_win", False)),
                               key="lab_stop_big_win")


    st.markdown("---")
    st.markdown("**üß≠ Sugerencias r√°pidas (seg√∫n tu historial real)**")
    sugg = _lab_quick_suggestions(t)

    st.markdown("#### üß∞ Filtros sugeridos (entrada) (Horas / Direcci√≥n / OR / ATR)")
    if sugg.get("filters"):
        for title, msg in sugg["filters"]:
            st.markdown(f"- {title}: {msg}")
    else:
        st.caption("No concluyente: no hubo suficiente muestra para sugerir filtros.")

    st.markdown("#### üéõÔ∏è Reglas sugeridas (Daily Guard) (M√°x trades/d√≠a / M√°x p√©rdidas seguidas)")
    if sugg.get("rules"):
        for title, msg in sugg["rules"]:
            st.markdown(f"- {title}: {msg}")
    else:
        st.caption("No concluyente: no hubo suficiente muestra para sugerir reglas.")

    # Referencia: qu√© valores NO cortan nada en tu hist√≥rico real (sirve como 'reset mental')
    _dt_for_day = None
    if "entry_time" in t.columns and pd.api.types.is_datetime64_any_dtype(t["entry_time"]):
        _dt_for_day = t["entry_time"]
    elif "exit_time" in t.columns and pd.api.types.is_datetime64_any_dtype(t["exit_time"]):
        _dt_for_day = t["exit_time"]

    if _dt_for_day is not None and "tradeRealized" in t.columns:
        _daily = t.copy()
        _daily["__day"] = _dt_for_day.dt.date
        _daily["__pnl"] = pd.to_numeric(_daily["tradeRealized"], errors="coerce").fillna(0)
        _day_pnl = _daily.groupby("__day")["__pnl"].sum()
        if len(_day_pnl) > 0:
            _max_loss = float(abs(_day_pnl.min())) if _day_pnl.min() < 0 else 0.0
            _max_profit = float(_day_pnl.max()) if _day_pnl.max() > 0 else 0.0
            st.caption(f"Referencia: para no cortar nada, usa M√°x p√©rdida/d√≠a = {_max_loss:.0f} y M√°x ganancia/d√≠a = {_max_profit:.0f}.")
with lab_right:
    st.markdown("**Filtros (opcional)**")
    base_for_lab = t.copy()  # <-- mismo universo que Resumen r√°pido

    # Aviso si faltan ENTRY (solo afecta a filtros que dependan de ENTRY/OR/EWO/ATR)
    missing_entry = int(base_for_lab["entry_time"].isna().sum()) if ("entry_time" in base_for_lab.columns) else 0
    if missing_entry > 0:
        st.warning(f"{missing_entry} operaciones no tienen ENTRY. En esas no se conoce Compra/Venta ni OR/EWO/ATR/DeltaRatio; "
                   "solo se podr√°n filtrar por hora usando EXIT como respaldo.", icon="‚ö†Ô∏è")

    filtered, filter_notes = _apply_filters(base_for_lab)

    st.write(f"Trades tras filtros: **{len(filtered)}** (de {len(base_for_lab)})")
    if filter_notes:
        st.caption("Filtros activos: " + ", ".join(filter_notes))
    else:
        st.caption("Filtros activos: ninguno (equivale al Resumen r√°pido).")
# Simulaci√≥n
if filtered is None or filtered.empty:
    st.info("Con los filtros actuales no quedan trades para simular.")
else:
    sim_kept, stops_df = _simulate_daily_rules(filtered, max_loss, max_profit, max_trades, max_consec_losses, stop_big_loss, stop_big_win)

    # Comparativa principal: real vs simulado (filtros + reglas)
    
    # ------------------------------------------------------------
    # Comparativa principal: REAL (historial) vs SIMULADO (real + filtros + reglas)
    # ------------------------------------------------------------
    real_df = base_for_lab
    cand_df = filtered        # candidatos tras filtros
    sim_df  = sim_kept        # candidatos tras reglas diarias

    n_real = int(len(real_df))
    n_cand = int(len(cand_df))
    n_sim  = int(len(sim_df))

    omit_filtros = max(0, n_real - n_cand)
    omit_reglas  = max(0, n_cand - n_sim)

    pnl_real = float(real_df["tradeRealized"].fillna(0).sum()) if ("tradeRealized" in real_df.columns and len(real_df)) else 0.0
    pnl_sim  = float(sim_df["tradeRealized"].fillna(0).sum()) if ("tradeRealized" in sim_df.columns and len(sim_df)) else 0.0

    pf_real = profit_factor(real_df) if len(real_df) else np.nan
    pf_sim  = profit_factor(sim_df)  if len(sim_df)  else np.nan

    st.markdown("### üìä Resultados del Lab (real vs simulado)")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("Trades reales", f"{n_real}")
    c2.metric("Trades simulados", f"{n_sim}", delta=f"{n_sim - n_real}")
    c3.metric("PnL real ($)", f"{pnl_real:.0f}")
    c4.metric("PnL simulado ($)", f"{pnl_sim:.0f}", delta=f"{(pnl_sim - pnl_real):.0f}")
    c5.metric("PF real / sim", f"{fmt(pf_real,2)} / {fmt(pf_sim,2)}")

    d1, d2, d3 = st.columns(3)
    d1.metric("Omitidos por filtros", f"{omit_filtros}")
    d2.metric("Omitidos por reglas", f"{omit_reglas}")
    dias_cortados = int(stops_df["fecha"].nunique()) if (stops_df is not None and not stops_df.empty and "fecha" in stops_df.columns) else 0
    d3.metric("D√≠as 'cortados' (reglas)", f"{dias_cortados}")

    # Drawdown (aprox) por curva de equity
    def _equity_df(df_):
        z = df_.copy()
        z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
        z["equity"] = z["tradeRealized"].fillna(0).cumsum()
        z["equity_peak"] = z["equity"].cummax()
        z["drawdown"] = z["equity"] - z["equity_peak"]
        return z

    real_eq = _equity_df(real_df) if len(real_df) else pd.DataFrame()
    sim_eq  = _equity_df(sim_df)  if len(sim_df)  else pd.DataFrame()

    dd_real = float(real_eq["drawdown"].min()) if len(real_eq) else np.nan
    dd_sim  = float(sim_eq["drawdown"].min())  if len(sim_eq)  else np.nan

    colx, coly = st.columns(2)
    colx.metric("M√°x ca√≠da real ($)", f"{abs(dd_real):.0f}" if not np.isnan(dd_real) else "‚Äî")
    coly.metric("M√°x ca√≠da sim ($)",  f"{abs(dd_sim):.0f}"  if not np.isnan(dd_sim)  else "‚Äî",
                delta=f"{(abs(dd_real) - abs(dd_sim)):.0f}" if (not np.isnan(dd_real) and not np.isnan(dd_sim)) else None)

    st.caption("Nota: el **simulado** aplica tus filtros (selectividad) y luego reglas diarias (corte). "
               "Por eso puede tener menos trades que lo real. Para que coincida 1:1, deja filtros en 'todo' y reglas en 0.")

    # Equity curve
    st.markdown("#### Curva de equity (real vs simulado)")
    if len(real_eq) and len(sim_eq) and ("exit_time" in real_eq.columns) and ("exit_time" in sim_eq.columns):
        real_plot = real_eq[["exit_time","equity"]].rename(columns={"equity":"Equity real"})
        sim_plot  = sim_eq[["exit_time","equity"]].rename(columns={"equity":"Equity sim"})
        plot_df = pd.merge_asof(real_plot.sort_values("exit_time"),
                                sim_plot.sort_values("exit_time"),
                                on="exit_time", direction="nearest", tolerance=pd.Timedelta("1D"))
        plot_df = plot_df.sort_values("exit_time")
        fig = px.line(plot_df, x="exit_time", y=["Equity real","Equity sim"], title="Equity ($)")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No hay datos suficientes para comparar curvas de equity.")
# Impacto de las reglas (en vez de solo frecuencia)
    if stops_df is not None and not stops_df.empty:
        st.markdown("#### ¬øQu√© regla detuvo el d√≠a y qu√© impacto tuvo?")

        # Construimos, por d√≠a, la secuencia de PnL en el orden real de entrada
        _lab_base = filtered.copy()
        _time_col = "entry_time" if "entry_time" in _lab_base.columns else "exit_time"
        _lab_base = _lab_base[_lab_base[_time_col].notna()].copy()
        _lab_base = _lab_base.sort_values(_time_col)
        _lab_base["lab_day"] = _lab_base[_time_col].dt.date

        def _day_dd_mag(pnls):
            if pnls is None or len(pnls) == 0:
                return 0.0
            c = np.cumsum(pnls)
            peak = np.maximum.accumulate(c)
            dd = c - peak
            return float(abs(np.min(dd))) if len(dd) else 0.0

        day_to_pnls = {}
        for d, subd in _lab_base.groupby("lab_day"):
            pnls = subd["tradeRealized"].fillna(0).astype(float).tolist()
            day_to_pnls[d] = pnls

        enriched = stops_df.copy()

        # Enriquecemos con "qu√© PnL qued√≥ fuera" y "mejora de DD intrad√≠a" (aprox)
        pnl_total_base = []
        pnl_omitido = []
        delta_pnl = []
        dd_day_base = []
        dd_day_sim = []
        delta_dd = []
        stop_ahorra = []
        trades_totales = []
        pnl_hasta_stop_list = []

        for _, r in enriched.iterrows():
            d = r["fecha"]
            taken = int(r.get("trades_ejecutados", 0) or 0)
            pnls = day_to_pnls.get(d, [])
            base_total = float(np.sum(pnls)) if pnls else 0.0
            kept_total = float(np.sum(pnls[:taken])) if pnls else 0.0
            trades_totales.append(int(len(pnls)))
            pnl_hasta_stop_list.append(float(kept_total))
            skipped = base_total - kept_total              # lo que "se pierde" por cortar
            d_pnl = kept_total - base_total                # impacto vs base (positivo = mejora)

            dd_b = _day_dd_mag(pnls)
            dd_s = _day_dd_mag(pnls[:taken])
            d_dd = dd_b - dd_s                             # positivo = reduce ca√≠da intrad√≠a

            pnl_total_base.append(base_total)
            pnl_omitido.append(skipped)
            delta_pnl.append(d_pnl)
            dd_day_base.append(dd_b)
            dd_day_sim.append(dd_s)
            delta_dd.append(d_dd)
            stop_ahorra.append(skipped < 0)                # si lo omitido era negativo, el corte evit√≥ p√©rdidas

        enriched["pnl_total_dia_base"] = pnl_total_base
        enriched["pnl_omitido_por_corte"] = pnl_omitido
        enriched["delta_pnl_vs_base"] = delta_pnl
        enriched["dd_dia_base"] = dd_day_base
        enriched["dd_dia_sim"] = dd_day_sim
        enriched["mejora_dd_dia"] = delta_dd
        enriched["evito_perdidas"] = stop_ahorra
        enriched["trades_totales_dia"] = trades_totales
        enriched["pnl_hasta_stop"] = pnl_hasta_stop_list

        # Resumen por motivo (lo realmente √∫til)
        impact = (
            enriched.groupby("motivo", as_index=False)
            .agg(
                dias=("fecha", "count"),
                trades_omitidos=("trades_filtrados_por_stop", "sum"),
                delta_pnl_total=("delta_pnl_vs_base", "sum"),
                delta_pnl_prom=("delta_pnl_vs_base", "mean"),
                mejora_dd_total=("mejora_dd_dia", "sum"),
                mejora_dd_prom=("mejora_dd_dia", "mean"),
                pct_evito_perdidas=("evito_perdidas", "mean"),
            )
        )
        impact["pct_evito_perdidas"] = (impact["pct_evito_perdidas"] * 100).round(0)

        # Gr√°ficos de impacto (PnL y DD) ‚Äî mucho m√°s interpretables que "frecuencia"
        leftg, rightg = st.columns(2)

        with leftg:
            st.markdown("**Impacto en PnL al cortar el d√≠a**")
            figp = px.bar(
                impact.sort_values("delta_pnl_total"),
                x="motivo",
                y="delta_pnl_total",
                color="delta_pnl_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("delta_pnl_total")["delta_pnl_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="ŒîPnL total vs base ($) ‚Äî positivo = mejora",
            )
            figp.update_layout(xaxis_title="Regla", yaxis_title="ŒîPnL ($)")
            st.plotly_chart(figp, use_container_width=True)

        with rightg:
            st.markdown("**Impacto en Drawdown intrad√≠a (aprox.)**")
            figd = px.bar(
                impact.sort_values("mejora_dd_total"),
                x="motivo",
                y="mejora_dd_total",
                color="mejora_dd_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("mejora_dd_total")["mejora_dd_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="Mejora DD total ($) ‚Äî positivo = reduce ca√≠das",
            )
            figd.update_layout(xaxis_title="Regla", yaxis_title="Mejora DD ($)")
            
            st.plotly_chart(figd, use_container_width=True)

        # Relaci√≥n entre reglas: trade-off PnL vs reducci√≥n de drawdown (visi√≥n de cuadrantes)
        if len(impact) >= 1:
            impact_sc = impact.copy()
            def _quad(row):
                dp = float(row.get("delta_pnl_total", 0) or 0)
                dd = float(row.get("mejora_dd_total", 0) or 0)
                if dp >= 0 and dd >= 0:
                    return "Mejora PnL y reduce DD"
                if dp < 0 and dd >= 0:
                    return "Reduce DD pero cuesta PnL"
                if dp >= 0 and dd < 0:
                    return "Mejora PnL pero empeora DD"
                return "Empeora ambos"
            impact_sc["cuadrante"] = impact_sc.apply(_quad, axis=1)

            st.markdown("**Mapa PnL vs Drawdown por regla (trade‚Äëoff)**")
            figs = px.scatter(
                impact_sc,
                x="delta_pnl_total",
                y="mejora_dd_total",
                size="dias" if "dias" in impact_sc.columns else None,
                color="cuadrante",
                hover_name="motivo",
                hover_data={
                    "dias": True,
                    "trades_omitidos": True,
                    "pct_evito_perdidas": True,
                    "delta_pnl_total": ":.0f",
                    "mejora_dd_total": ":.0f",
                },
                labels={
                    "delta_pnl_total": "ŒîPnL vs base ($)",
                    "mejora_dd_total": "Mejora DD total ($)",
                    "dias": "D√≠as activada",
                },
                title="Cada punto = una regla. Derecha/arriba = mejor. Tama√±o = d√≠as activada.",
            )
            figs.add_vline(x=0, line_dash="dash", opacity=0.4)
            figs.add_hline(y=0, line_dash="dash", opacity=0.4)
            figs.update_layout(xaxis_title="ŒîPnL ($)  (positivo = mejora)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figs, use_container_width=True)

            if len(impact_sc) >= 3:
                try:
                    r = float(np.corrcoef(impact_sc["delta_pnl_total"], impact_sc["mejora_dd_total"])[0,1])
                    st.caption(f"Correlaci√≥n entre ŒîPnL y Mejora DD (entre reglas): r = {r:.2f}. "
                               "Con pocas reglas, √∫salo solo como referencia visual.")
                except Exception:
                    pass

        st.caption(

            "Interpretaci√≥n: **ŒîPnL** positivo significa que cortar evit√≥ m√°s p√©rdidas de las que dej√≥ pasar. "
            "**Mejora DD** positiva significa menor ca√≠da intrad√≠a en los d√≠as donde se activ√≥ esa regla. "
            "Esto es una aproximaci√≥n por d√≠a (no reemplaza el DD global)."
        )

        # Tabla detallada (para quien quiera auditar)
        
        # ------------------------------------------------------------
        # Extra: "What-if" por regla (una regla a la vez)
        # Esto evita confusi√≥n cuando varias reglas est√°n activas a la vez.
        # ------------------------------------------------------------
        st.markdown("#### üß© What‚Äëif por regla (una regla a la vez)")
        st.caption("Aqu√≠ se simula **cada regla por separado** (manteniendo los filtros) y se compara contra los **candidatos tras filtros**. "
                   "Sirve para ver el **trade‚Äëoff PnL vs Drawdown** sin mezclar reglas.")

        def _dd_mag_from_df(df_):
            if df_ is None or df_.empty:
                return 0.0
            z = df_.copy()
            z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
            eq = z["tradeRealized"].fillna(0).astype(float).cumsum()
            peak = eq.cummax()
            dd = eq - peak
            return float(abs(dd.min())) if len(dd) else 0.0

        pnl_base_f = float(filtered["tradeRealized"].fillna(0).astype(float).sum()) if (filtered is not None and not filtered.empty) else 0.0
        dd_base_f  = _dd_mag_from_df(filtered)
        pf_base_f  = profit_factor(filtered) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else np.nan

        # Construye escenarios individuales en funci√≥n de lo que el usuario activ√≥
        scenarios = []
        if max_loss > 0:
            scenarios.append(("Max p√©rdida/d√≠a", dict(max_loss=max_loss, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_profit > 0:
            scenarios.append(("Max ganancia/d√≠a", dict(max_loss=0.0, max_profit=max_profit, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_trades > 0:
            scenarios.append(("M√°x trades/d√≠a", dict(max_loss=0.0, max_profit=0.0, max_trades=max_trades, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_consec_losses > 0:
            scenarios.append((f"{max_consec_losses} p√©rdidas seguidas", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=max_consec_losses, stop_big_loss=False, stop_big_win=False)))
        if stop_big_loss:
            scenarios.append(("Stop‚Äëout fuerte (‚â§ -1R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=True, stop_big_win=False)))
        if stop_big_win:
            scenarios.append(("Cierre tras ganador grande (‚â• 2R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=True)))

        rows = []
        for name, params in scenarios:
            sim_one, stops_one = _simulate_daily_rules(filtered, **params)
            pnl_sim_one = float(sim_one["tradeRealized"].fillna(0).astype(float).sum()) if (sim_one is not None and not sim_one.empty) else 0.0
            dd_sim_one  = _dd_mag_from_df(sim_one)
            pf_sim_one  = profit_factor(sim_one) if (sim_one is not None and not sim_one.empty and "tradeRealized" in sim_one.columns) else np.nan

            rows.append({
                "regla": name,
                "trades_sim": int(len(sim_one)) if sim_one is not None else 0,
                "dias_cortados": int(len(stops_one)) if stops_one is not None else 0,
                "delta_pnl": pnl_sim_one - pnl_base_f,
                "mejora_dd": dd_base_f - dd_sim_one,
                "pf_sim": pf_sim_one,
            })

        # Punto "Combinado" (todas las reglas activas) si hay m√°s de 1 regla
        if len(scenarios) >= 2:
            pnl_base_comb = float(filtered["tradeRealized"].sum()) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else 0.0
            pnl_sim_comb  = float(sim_kept["tradeRealized"].sum()) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else 0.0
            dd_sim_mag = _dd_mag_from_df(sim_kept) if (sim_kept is not None and not sim_kept.empty) else 0.0
            cut_days_total = int(stops_df["day"].nunique()) if (stops_df is not None and not stops_df.empty and "day" in stops_df.columns) else 0
            rows.append({
                "regla": "Combinado (todas)",
                "trades_sim": int(len(sim_kept)) if sim_kept is not None else 0,
                "dias_cortados": cut_days_total,
                "delta_pnl": pnl_sim_comb - pnl_base_comb,
                "mejora_dd": dd_base_f - dd_sim_mag,
                "pf_sim": profit_factor(sim_kept) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else np.nan,
            })


        if rows:
            wf = pd.DataFrame(rows)
            def _quad2(r):
                dp = float(r["delta_pnl"])
                ddm = float(r["mejora_dd"])
                if dp >= 0 and ddm >= 0: return "‚úÖ Mejora PnL y DD"
                if dp < 0 and ddm >= 0:  return "üü° Reduce DD pero cuesta PnL"
                if dp >= 0 and ddm < 0:  return "üü† Mejora PnL pero empeora DD"
                return "‚ùå Empeora ambos"
            wf["cuadrante"] = wf.apply(_quad2, axis=1)

            # Gr√°fico trade-off (m√°s estable con muchas reglas)
            figwf = px.scatter(
                wf,
                x="delta_pnl",
                y="mejora_dd",
                size="dias_cortados",
                color="cuadrante",
                hover_name="regla",
                hover_data={"trades_sim": True, "dias_cortados": True, "pf_sim": True},
                title="Mapa (what‚Äëif) por regla ‚Äî ŒîPnL vs mejora DD (cada regla por separado)",
            )
            figwf.add_vline(x=0, line_dash="dash", opacity=0.4)
            figwf.add_hline(y=0, line_dash="dash", opacity=0.4)

            # Asegura que el 0 siempre sea visible (evita ejes ‚Äúpegados‚Äù a un lado)
            try:
                xmin = float(wf["delta_pnl"].min()); xmax = float(wf["delta_pnl"].max())
                ymin = float(wf["mejora_dd"].min()); ymax = float(wf["mejora_dd"].max())
                padx = max(100.0, (xmax - xmin) * 0.15)
                pady = max(100.0, (ymax - ymin) * 0.15)
                figwf.update_xaxes(range=[min(xmin, 0.0) - padx, max(xmax, 0.0) + padx])
                figwf.update_yaxes(range=[min(ymin, 0.0) - pady, max(ymax, 0.0) + pady])
            except Exception:
                pass

            figwf.update_layout(xaxis_title="ŒîPnL vs base ($)  (positivo = mejor)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figwf, use_container_width=True)

            with st.expander("Ver tabla (what‚Äëif por regla)"):
                st.markdown(
                    """**C√≥mo leer esta tabla (simple):**  

**ŒîPnL** = cu√°nto habr√≠a cambiado tu PnL total vs lo real (positivo = mejora).  

**Mejora DD** = cu√°nto se reduce la peor ca√≠da (positivo = mejor).  

**D√≠as cortados** = d√≠as donde la regla detuvo el trading.  

**Trades sim** = trades que quedar√≠an con esa regla.  

**PF sim** = Profit Factor del simulado.  

**Cuadrante** = resumen del trade‚Äëoff (mejora DD pero cuesta PnL, etc.)."""
                )
                wf2 = wf.sort_values(["cuadrante","mejora_dd","delta_pnl"], ascending=[True, False, False]).copy()
                wf2["delta_pnl"] = wf2["delta_pnl"].round(0).astype(int)
                wf2["mejora_dd"] = wf2["mejora_dd"].round(0).astype(int)
                st.dataframe(wf2[["regla","delta_pnl","mejora_dd","dias_cortados","trades_sim","pf_sim","cuadrante"]], use_container_width=True, hide_index=True)

            # Consejo r√°pido autom√°tico
            best = wf[wf["regla"] != "Combinado (todas)"].copy()
            if not best.empty and (best["dias_cortados"].sum() > 0):
                cand = best.sort_values(["mejora_dd","delta_pnl"], ascending=False).iloc[0]
                st.success(f"‚úÖ Regla con mejor equilibrio (en esta muestra): **{cand['regla']}** "
                           f"(ŒîPnL {cand['delta_pnl']:.0f}$, mejora DD {cand['mejora_dd']:.0f}$). "
                           "Ojo: valida con m√°s trades y no optimices 5 cosas a la vez.")
        else:
            st.info("Activa al menos una regla diaria para ver el 'what‚Äëif por regla'.")


        # --- Resumen funky + export (CSV) ---
        st.markdown("##### üéõÔ∏è Resumen r√°pido de configuraci√≥n (Lab)")
        cfg = []
        cfg.append(f"üìâ M√°x p√©rdida/d√≠a: {max_loss:.0f}" if max_loss > 0 else "üìâ M√°x p√©rdida/d√≠a: sin l√≠mite")
        cfg.append(f"üìà M√°x ganancia/d√≠a: {max_profit:.0f}" if max_profit > 0 else "üìà M√°x ganancia/d√≠a: sin l√≠mite")
        cfg.append(f"üî¢ M√°x trades/d√≠a: {max_trades}" if max_trades > 0 else "üî¢ M√°x trades/d√≠a: sin l√≠mite")
        cfg.append(f"üß± M√°x p√©rdidas seguidas: {max_consec_losses}" if max_consec_losses > 0 else "üß± M√°x p√©rdidas seguidas: sin l√≠mite")
        if stop_big_loss:
            cfg.append("üõë Stop por stop‚Äëout fuerte (RR ‚â§ -1)")
        if stop_big_win:
            cfg.append("üèÅ Stop por ganador grande (RR ‚â• 2)")
        if filter_notes:
            cfg.append("üîé Filtros: " + " | ".join(filter_notes))
        st.caption(" ‚Ä¢ ".join(cfg))

        # One‚Äëliners por regla (usa la tabla what‚Äëif)
        if 'wf2' in locals() and isinstance(wf2, pd.DataFrame) and not wf2.empty:
            st.markdown("##### ‚ú® One‚Äëliners (what‚Äëif por regla)")
            def _val_for_rule(r):
                r = str(r)
                if "trades/d√≠a" in r:
                    return f"{max_trades}" if max_trades > 0 else "sin l√≠mite"
                if "p√©rdida/d√≠a" in r:
                    return f"{max_loss:.0f}" if max_loss > 0 else "sin l√≠mite"
                if "ganancia/d√≠a" in r:
                    return f"{max_profit:.0f}" if max_profit > 0 else "sin l√≠mite"
                if "p√©rdidas seguidas" in r:
                    return f"{max_consec_losses}" if max_consec_losses > 0 else "sin l√≠mite"
                if "stop-out fuerte" in r:
                    return "RR ‚â§ -1"
                if "ganador grande" in r:
                    return "RR ‚â• 2"
                return ""

            def _emoji_for_quad(q):
                q = str(q)
                if "Mejora PnL y DD" in q:
                    return "üèÜ", "Winner"
                if "Reduce DD" in q and "cuesta PnL" in q:
                    return "üü°", "Reduce DD pero cuesta PnL"
                if "Mejora PnL" in q and "empeora DD" in q:
                    return "üü†", "Mejora PnL pero sube DD"
                if "Empeora" in q:
                    return "üî¥", "Peor"
                return "‚ö™", q

            for _, row in wf2.iterrows():
                regla = str(row.get("regla",""))
                if regla.strip() == "":
                    continue
                val = _val_for_rule(regla)
                delta = row.get("delta_pnl", np.nan)
                ddm = row.get("mejora_dd", np.nan)
                quad = row.get("cuadrante","")
                emj, label = _emoji_for_quad(quad)
                vtxt = f" = {val}" if val not in ("", None) else ""
                try:
                    d1 = f"{float(delta):+.0f}"
                except Exception:
                    d1 = "n/a"
                try:
                    d2 = f"{float(ddm):+.0f}"
                except Exception:
                    d2 = "n/a"
                st.write(f"{emj} **{regla}{vtxt}** ‚Üí {label} (ŒîPnL {d1} / DD {d2})")

        # Export CSV (par√°metros + m√©tricas + tabla what‚Äëif si existe)
        exp_rows = []
        exp_rows.append({"section":"metrics","name":"trades_real","value": int(trades_real) if 'trades_real' in locals() else ""})
        exp_rows.append({"section":"metrics","name":"trades_sim","value": int(trades_sim) if 'trades_sim' in locals() else ""})
        exp_rows.append({"section":"metrics","name":"pnl_real","value": float(pnl_real) if 'pnl_real' in locals() else ""})
        exp_rows.append({"section":"metrics","name":"pnl_sim","value": float(pnl_sim) if 'pnl_sim' in locals() else ""})
        exp_rows.append({"section":"metrics","name":"dd_real","value": float(dd_real_mag) if 'dd_real_mag' in locals() else ""})
        exp_rows.append({"section":"metrics","name":"dd_sim","value": float(dd_sim_mag) if 'dd_sim_mag' in locals() else ""})
        exp_rows.append({"section":"params","name":"max_loss_per_day","value": max_loss})
        exp_rows.append({"section":"params","name":"max_profit_per_day","value": max_profit})
        exp_rows.append({"section":"params","name":"max_trades_per_day","value": max_trades})
        exp_rows.append({"section":"params","name":"max_consec_losses","value": max_consec_losses})
        exp_rows.append({"section":"params","name":"stop_big_loss_rr_le_-1","value": bool(stop_big_loss)})
        exp_rows.append({"section":"params","name":"stop_big_win_rr_ge_2","value": bool(stop_big_win)})
        exp_rows.append({"section":"filters","name":"active_filters","value": " | ".join(filter_notes) if filter_notes else ""})
        if 'wf2' in locals() and isinstance(wf2, pd.DataFrame) and not wf2.empty:
            for _, r in wf2.iterrows():
                exp_rows.append({
                    "section":"whatif",
                    "name": str(r.get("regla","")),
                    "value": "",
                    "delta_pnl": r.get("delta_pnl", np.nan),
                    "mejora_dd": r.get("mejora_dd", np.nan),
                    "dias_cortados": r.get("dias_cortados", np.nan),
                    "trades_sim": r.get("trades_sim", np.nan),
                    "pf_sim": r.get("pf_sim", np.nan),
                    "cuadrante": r.get("cuadrante","")
                })

        exp_df = pd.DataFrame(exp_rows)
        csv_bytes = exp_df.to_csv(index=False).encode("utf-8")
        st.download_button("‚¨áÔ∏è Descargar CSV del experimento", data=csv_bytes,
                           file_name=f"lab_experimento_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                           mime="text/csv")

        with st.expander("Ver detalle por d√≠a (qu√© se omiti√≥ al cortar)"):
            show_cols = [
                "fecha", "motivo",
                "trades_ejecutados", "trades_totales_dia", "trades_filtrados_por_stop",
                "pnl_total_dia_base", "pnl_hasta_stop", "pnl_omitido_por_corte", "delta_pnl_vs_base",
                "dd_dia_base", "dd_dia_sim", "mejora_dd_dia",
            ]
            st.dataframe(
                enriched[show_cols].sort_values(["fecha"]),
                use_container_width=True,
                hide_index=True,
            )
    else:
        st.info("Con estas reglas, no se activ√≥ ning√∫n 'corte del d√≠a'.")
    # Consejos autom√°ticos del Lab
    st.markdown("### üí° Consejos autom√°ticos (Lab)")
    if len(filtered) < 30:
        st.warning("Muestra peque√±a tras filtros: toma estas conclusiones como hip√≥tesis, no como regla.")
    if len(sim_kept) < max(10, int(0.25*len(filtered))):
        st.warning("La simulaci√≥n est√° eliminando demasiados trades. Revisa si est√°s filtrando/cortando en exceso.")

    # Magnitud de DD del simulado (por seguridad, siempre definida)
    dd_sim_mag = _dd_mag_from_df(sim_kept) if (sim_kept is not None and not sim_kept.empty) else np.nan
    # Magnitud de DD del real (por seguridad, siempre definida)
    dd_base_f = _dd_mag_from_df(filtered) if (filtered is not None and not filtered.empty) else np.nan

    # OJO: dd_base/dd_sim son negativos (ca√≠da desde el pico). Para comparar "mejor/peor" usamos magnitudes.
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.success("‚úÖ Menor drawdown con reglas: buen candidato para un 'Daily Guard' realista.")
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.warning("‚ö†Ô∏è El drawdown empeor√≥ en la simulaci√≥n: estas reglas podr√≠an estar cortando recuperaci√≥n o dejando p√©rdidas grandes.")

    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim > pf_real + 0.2 and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.info("Mejor√≥ PF pero empeor√≥ DD: t√≠pico cuando eliminas muchos trades peque√±os pero te quedas con p√©rdidas grandes. Revisa filtros/horarios.")
    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim < pf_real and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.info("Baj√≥ PF pero tambi√©n baj√≥ el DD: a veces vale la pena si tu objetivo es estabilidad (menos estr√©s / menos reset).")
# Resumen final (muy user-friendly)
# ============================================================
st.subheader("üßæ Resumen final y recomendaciones")

st.write(
    "Este bloque resume lo m√°s accionable. No es una verdad absoluta: con muestra peque√±a, √∫salo para orientar, no para 'sobre-optimizar'."
)

# 1) Salud general
pf_val = summary.get("pf", np.nan)
exp_val = summary.get("expectancy", np.nan)
if pf_val == pf_val and pf_val < 1.0:
    st.error("üö® Salud general: Profit Factor < 1 (pierde). Prioridad: filtrar condiciones malas antes de ajustar targets.")
elif exp_val == exp_val and exp_val < 0:
    st.warning("‚ö†Ô∏è Salud general: promedio por trade < 0. Revisa filtros (horario/volatilidad/tendencia) y disciplina de salida.")
else:
    st.success("‚úÖ Salud general: no se ve rojo inmediato (seg√∫n esta muestra). Ahora toca mejorar consistencia.")

# 2) RR y estructura
if "rr" in t.columns and t["rr"].notna().any():
    _rr = t[t["rr"].notna()]["rr"].astype(float)
    rr_median = float(_rr.median())
    rr_mean = float(_rr.mean())
    rr_ge2 = float((_rr >= 2).mean() * 100)
    rr_le_1 = float((_rr <= -1).mean() * 100)

    st.markdown("**Estructura RR**")
    st.write(f"- RR mediana: {rr_median:.2f} | RR promedio: {rr_mean:.2f} | %RR‚â•2: {rr_ge2:.1f}% | %RR‚â§-1: {rr_le_1:.1f}%")
    if rr_mean > 0 and rr_median < 0:
        st.info("Promedio > 0 y mediana < 0: dependes de pocos ganadores grandes. Enf√≥cate en reducir stop-outs feos sin matar tus runners.")
    if rr_le_1 > 15:
        st.warning("‚ö†Ô∏è %RR‚â§-1 alto: est√°s tomando muchas p√©rdidas completas. Buen objetivo: mejorar confirmaci√≥n/evitar chop/horas malas.")

# 3) Manejo de ganadores (captura/devoluci√≥n)
if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
    cap_med = float(t["captura_pct"].dropna().median())
    gb_med = float(t["devolucion_pct"].dropna().median()) if "devolucion_pct" in t.columns and t["devolucion_pct"].notna().any() else np.nan
    st.markdown("**Manejo de ganadores**")
    st.write(f"- Captura mediana: {cap_med*100:.0f}%" + (f" | Devoluci√≥n mediana: {gb_med*100:.0f}%" if gb_med == gb_med else ""))
    if cap_med < 0.35:
        st.warning("‚ö†Ô∏è Captura baja: est√°s dejando mucho en la mesa. Ajusta trailing/TP parcial o reglas de salida temprana.")
    if gb_med == gb_med and gb_med > 0.60:
        st.warning("‚ö†Ô∏è Devoluci√≥n alta: el trade va bien, pero no proteges a tiempo. Prueba trailing m√°s agresivo cuando ya est√©s en +1R.")

# 4) Motivos de salida (top problema)
if "exitReason" in t.columns and t["exitReason"].notna().any():
    _tbl = group_metrics(t, "exitReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
    if not _tbl.empty:
        worst = _tbl.sort_values("Promedio por trade").iloc[0]
        if float(worst["Promedio por trade"]) < 0:
            st.markdown("**Motivo de salida a vigilar**")
            st.write(f"- {worst['Grupo']}: promedio {float(worst['Promedio por trade']):.1f} con {int(worst['Trades'])} trades")

# 5) Horarios (si hay)
if hour_tbl is not None and not hour_tbl.empty:
    best = hour_tbl.iloc[0]
    st.markdown("**Horario con mejor Score (ponderado)**")
    st.write(f"- {best['Grupo']} | Trades={int(best['Trades'])} | PF={float(best['Profit Factor']):.2f} | Promedio={float(best['Promedio por trade']):.1f}")
    if int(best["Trades"]) < min_trades * 2:
        st.info("Nota: el mejor horario a√∫n tiene poca muestra. Confirma con m√°s meses antes de convertirlo en regla.")

recommend_settings_block(known, min_trades=min_trades, recommended_trades=recommended_trades)

st.markdown("**Siguientes pasos recomendados (orden)**")
st.write("1) Primero elimina lo rojo: horarios peores + condiciones con PF<1 (muestra üü¢).")
st.write("2) Luego ajusta manejo: reduce devoluciones grandes y evita stop-outs completos recurrentes.")
st.write("3) Al final optimiza targets/trailing: no mates los winners grandes si tu edge depende de ellos.")

# ============================================================
# Trades table
# ============================================================
with st.expander("üìÑ Tabla de trades (una fila por atmId)", expanded=False):
    cols_show = [c for c in [
        "exit_time", "entry_time", "lado", "outcome", "tradeRealized",
        "maxUnreal", "minUnreal", "exitReason", "forcedCloseReason",
        "orSize", "ewo", "atr", "deltaRatio", "atrSlMult", "tp1R", "tp2R",
        "duration_sec"
    ] if c in t.columns]
    st.dataframe(t[cols_show].sort_values("exit_time", ascending=False), use_container_width=True)

st.caption(
    "Tip: para eliminar ‚ÄúSin datos (falt√≥ ENTRY)‚Äù, aseg√∫rate de cargar meses que contengan los ENTRY y EXIT juntos. "
    "Si quieres 100% robustez, a√±ade `dir` tambi√©n en el EXIT (en NinjaScript) o guarda logs en bloques por trade."
)
