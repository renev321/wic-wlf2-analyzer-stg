import streamlit as st
import pandas as pd
import numpy as np
import json
import plotly.express as px

# Avoid NameError in optional analytics sections; will be overwritten when simulation produces it
stops_df = pd.DataFrame()


st.set_page_config(page_title="WIC_WLF2 Analizador", layout="wide")

# --- TURBO: apply queued preset before widgets are created (prevents session_state/widget-key errors)
if "_turbo_pending_apply" in st.session_state:
    _params = st.session_state.pop("_turbo_pending_apply") or {}
    if isinstance(_params, dict):
        for _k, _v in _params.items():
            st.session_state[_k] = _v
    # Ensure these exist even if user never touched the toggles
    st.session_state.setdefault("lab_use_hours_filter", False)
    st.session_state.setdefault("lab_use_or_filter", False)
    st.session_state.setdefault("lab_use_atr_filter", False)
    st.session_state.setdefault("lab_use_rules", True)

def _best_group_for_categorical(df: pd.DataFrame, col: str, min_trades: int):
    if col not in df.columns:
        return None
    rows = []
    for g, sub in df.groupby(col):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        rows.append((g, n, exp, pf, score))
    if not rows:
        return None
    rows.sort(key=lambda x: (x[4], x[1]), reverse=True)
    g, n, exp, pf, score = rows[0]
    return {"grupo": g, "n": n, "exp": exp, "pf": pf, "score": score}


def _best_range_for_numeric(df: pd.DataFrame, col: str, q: int, min_trades: int):
    if col not in df.columns:
        return None
    s = pd.to_numeric(df[col], errors="coerce")
    if s.notna().sum() < max(15, min_trades * 2):
        return None
    try:
        cuts = pd.qcut(s, q=q, duplicates="drop")
    except Exception:
        return None

    tmp = df.copy()
    tmp["_r"] = cuts.astype(str)

    best = None
    for g, sub in tmp.groupby("_r"):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        cand = {"rango": str(g), "n": n, "exp": exp, "pf": pf, "score": score}
        if (best is None) or (cand["score"] > best["score"]):
            best = cand
    if best is None:
        return None

    # Intentar extraer l√≠mites num√©ricos del rango "(a, b]"
    lo = hi = None
    rg = best["rango"].strip()
    if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
        inner = rg[1:-1]
        parts = inner.split(",")
        if len(parts) == 2:
            try:
                lo = float(parts[0])
                hi = float(parts[1])
            except Exception:
                lo = hi = None
    best["lo"] = lo
    best["hi"] = hi
    return best


def recommend_settings_block(known_df: pd.DataFrame, min_trades: int, recommended_trades: int):
    """
    Resume recomendaciones 'tipo NinjaTrader' basadas en lo que rinde mejor en ESTA muestra.
    No inventa campos: solo usa lo que existe en el JSON.
    """
    if known_df is None or known_df.empty:
        st.info("No hay suficientes trades con ENTRY para sugerir ajustes.")
        return

    n_total = int(len(known_df))
    st.subheader("üéØ Ajustes sugeridos (seg√∫n esta muestra)")
    st.caption("Esto NO es una optimizaci√≥n cient√≠fica; es una gu√≠a r√°pida. Con poca muestra, √∫salo como hip√≥tesis.")

    if n_total < recommended_trades:
        st.warning(f"Muestra peque√±a: {n_total} trades con ENTRY. Recomendado ‚â• {recommended_trades} para decisiones fuertes.")

    # 1) Entry: StopMarket vs Limit
    if "orderType" in known_df.columns:
        tmp = known_df.copy()
        ot = tmp["orderType"].astype(str).str.lower()
        tmp["EntryType"] = np.where(ot.str.contains("stop"), "StopMarket", np.where(ot.str.contains("limit"), "Limit", tmp["orderType"].astype(str)))
        best_entry = _best_group_for_categorical(tmp, "EntryType", min_trades=min_trades)
    else:
        best_entry = None

    # 2) UseAtrEngine (bool)
    best_atr_mode = _best_group_for_categorical(known_df, "useAtrEngine", min_trades=min_trades)

    # 3) Rangos num√©ricos clave (si existen)
    q_small = 3  # con 40 trades: rangos pocos, m√°s estables
    best_or = _best_range_for_numeric(known_df, "orSize", q=q_small, min_trades=min_trades)
    best_ewo = None
    if "ewo" in known_df.columns:
        tmp = known_df.copy()
        tmp["ewoAbs"] = pd.to_numeric(tmp["ewo"], errors="coerce").abs()
        best_ewo = _best_range_for_numeric(tmp, "ewoAbs", q=q_small, min_trades=min_trades)

    best_atr = _best_range_for_numeric(known_df, "atr", q=q_small, min_trades=min_trades)
    best_atr_sl = _best_range_for_numeric(known_df, "atrSlMult", q=q_small, min_trades=min_trades)
    best_tp1 = _best_range_for_numeric(known_df, "tp1R", q=q_small, min_trades=min_trades)
    best_tp2 = _best_range_for_numeric(known_df, "tp2R", q=q_small, min_trades=min_trades)
    best_ts = _best_range_for_numeric(known_df, "tsBehindTP1Atr", q=q_small, min_trades=min_trades)
    best_step = _best_range_for_numeric(known_df, "trailStepTicks", q=q_small, min_trades=min_trades)

    # 4) Render: salida tipo "par√°metro -> sugerencia"
    lines = []

    def add_line(name, suggestion, note=None):
        s = f"- **{name}**: {suggestion}"
        if note:
            s += f"  \n  {note}"
        lines.append(s)

    if best_entry:
        use_stop = "True" if str(best_entry["grupo"]).lower() == "stopmarket" else "False"
        add_line("UseStopMarketEntry", use_stop, f"(mejor grupo: {best_entry['grupo']} | n={best_entry['n']} | PF={best_entry['pf']:.2f} | prom={best_entry['exp']:.0f})")

    if best_atr_mode:
        add_line("UseAtrEngine", str(best_atr_mode["grupo"]), f"(n={best_atr_mode['n']} | PF={best_atr_mode['pf']:.2f} | prom={best_atr_mode['exp']:.0f})")

    if best_or and best_or.get("lo") is not None and best_or.get("hi") is not None:
        add_line("MinORSize / MaxORSize", f"{best_or['lo']:.2f}  ‚Üí  {best_or['hi']:.2f}",
                 f"(mejor rango ORSize | n={best_or['n']} | PF={best_or['pf']:.2f} | prom={best_or['exp']:.0f})")

    if best_ewo and best_ewo.get("lo") is not None:
        add_line("MinEWOMagnitude", f"‚âà {best_ewo['lo']:.3f} (o mayor)",
                 f"(basado en |EWO| | n={best_ewo['n']} | PF={best_ewo['pf']:.2f} | prom={best_ewo['exp']:.0f})")

    if best_atr_sl and best_atr_sl.get("lo") is not None and best_atr_sl.get("hi") is not None:
        mid = (best_atr_sl["lo"] + best_atr_sl["hi"]) / 2
        add_line("AtrSlMult", f"‚âà {mid:.2f} (rango {best_atr_sl['lo']:.2f}‚Äì{best_atr_sl['hi']:.2f})",
                 f"(n={best_atr_sl['n']} | PF={best_atr_sl['pf']:.2f} | prom={best_atr_sl['exp']:.0f})")

    if best_tp1 and best_tp1.get("lo") is not None and best_tp1.get("hi") is not None:
        mid = (best_tp1["lo"] + best_tp1["hi"]) / 2
        add_line("TP1_RMult", f"‚âà {mid:.2f} (rango {best_tp1['lo']:.2f}‚Äì{best_tp1['hi']:.2f})",
                 f"(n={best_tp1['n']} | PF={best_tp1['pf']:.2f} | prom={best_tp1['exp']:.0f})")

    if best_tp2 and best_tp2.get("lo") is not None and best_tp2.get("hi") is not None:
        mid = (best_tp2["lo"] + best_tp2["hi"]) / 2
        add_line("TP2_RMult", f"‚âà {mid:.2f} (rango {best_tp2['lo']:.2f}‚Äì{best_tp2['hi']:.2f})",
                 f"(n={best_tp2['n']} | PF={best_tp2['pf']:.2f} | prom={best_tp2['exp']:.0f})")

    if best_ts and best_ts.get("lo") is not None and best_ts.get("hi") is not None:
        mid = (best_ts["lo"] + best_ts["hi"]) / 2
        add_line("TSBehindTP1_ATR", f"‚âà {mid:.2f} (rango {best_ts['lo']:.2f}‚Äì{best_ts['hi']:.2f})",
                 f"(n={best_ts['n']} | PF={best_ts['pf']:.2f} | prom={best_ts['exp']:.0f})")

    if best_step and best_step.get("lo") is not None and best_step.get("hi") is not None:
        # ticks: mejor entero
        mid = int(round((best_step["lo"] + best_step["hi"]) / 2))
        add_line("TrailStepTicks", f"‚âà {mid} (rango {best_step['lo']:.0f}‚Äì{best_step['hi']:.0f})",
                 f"(n={best_step['n']} | PF={best_step['pf']:.2f} | prom={best_step['exp']:.0f})")

    if not lines:
        st.info("No hay suficientes campos/muestra para sugerir ajustes autom√°ticos.")
    else:
        st.markdown("\n".join(lines))

    st.caption("‚ö†Ô∏è Consejo: aplica 1 cambio a la vez y vuelve a medir. Evita optimizar 5 par√°metros con 40 trades.")


# ============================================================
# (Opcional) Password: define APP_PASSWORD en Streamlit Secrets
# ============================================================
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
if APP_PASSWORD:
    st.sidebar.subheader("üîê Acceso")
    pwd = st.sidebar.text_input("Contrase√±a", type="password")
    if pwd != APP_PASSWORD:
        st.sidebar.warning("Contrase√±a incorrecta.")
        st.stop()

# ============================================================
# Helpers parse/normalize
# ============================================================
def parse_jsonl_bytes(b: bytes):
    txt = b.decode("utf-8", errors="replace")
    recs, bad = [], 0
    for line in txt.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            recs.append(json.loads(line))
        except Exception:
            bad += 1
    return recs, bad


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "ts" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["ts"], errors="coerce")
    elif "timestamp" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["timestamp"], errors="coerce")
    else:
        df["ts_parsed"] = pd.NaT

    if "type" not in df.columns:
        df["type"] = ""

    return df

# ============================================================
# Arrays (volumen/delta/OHLC) y m√©tricas pre-entrada
# ============================================================
def _as_list(x):
    """Convierte a lista si viene como list/tuple/np.array o string tipo '[...]'."""
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return []
    if isinstance(x, list):
        return x
    if isinstance(x, (tuple, np.ndarray)):
        return list(x)
    if isinstance(x, str):
        s = x.strip()
        if s.startswith("[") and s.endswith("]"):
            try:
                return json.loads(s)
            except Exception:
                return []
    return []


def add_pressure_activity_features(trades: pd.DataFrame) -> pd.DataFrame:
    """A√±ade m√©tricas de 'Presi√≥n y Actividad' usando arrays LastN (contexto pre-entrada).
    Si no existen arrays, devuelve el DF sin cambios.
    """
    if trades is None or trades.empty:
        return trades

    t = trades.copy()

    # Asegura num√©ricos base si existen
    for c in ["tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "volEntrySoFar", "deltaEntrySoFar", "dir"]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    def _row_feat(r):
        dl = _as_list(r.get("deltaLastN"))
        vl = _as_list(r.get("volLastN"))
        ol = _as_list(r.get("openLastN"))
        hl = _as_list(r.get("highLastN"))
        ll = _as_list(r.get("lowLastN"))
        cl = _as_list(r.get("closeLastN"))

        if not dl or not vl or not hl or not ll or not cl or not ol:
            return pd.Series({
                "pre_presion_sum": np.nan,
                "pre_presion_abs": np.nan,
                "pre_vol_sum": np.nan,
                "pre_precio_neto": np.nan,
                "pre_rango_precio": np.nan,
                "pre_mov_ticks": np.nan,
                "pre_absorcion": np.nan,
                "pre_actividad_rel": np.nan,
                "pre_presion_por_vol": np.nan,
                "pre_sin_apoyo": False,
            })

        presion_sum = float(np.nansum(dl))
        presion_abs = float(abs(presion_sum))
        vol_sum = float(np.nansum(vl))

        # Movimiento de precio pre-entrada
        try:
            precio_neto = float(cl[-1] - ol[0])
        except Exception:
            precio_neto = np.nan

        try:
            rango = float(np.nanmax(hl) - np.nanmin(ll))
        except Exception:
            rango = np.nan

        tick = r.get("tickSize")
        if tick is None or (isinstance(tick, float) and np.isnan(tick)) or tick == 0 or rango != rango:
            mov_ticks = np.nan
        else:
            mov_ticks = rango / float(tick)

        # Absorci√≥n: presi√≥n alta + avance bajo (normalizado por ticks movidos)
        absorcion = (presion_abs / max(mov_ticks, 1.0)) if mov_ticks == mov_ticks else np.nan

        # Actividad relativa: vol hasta entrada vs mediana del vol reciente
        med_vol = float(np.nanmedian(vl)) if len(vl) else np.nan
        vol_entry = r.get("volEntrySoFar")
        if med_vol == med_vol and med_vol > 0 and vol_entry == vol_entry:
            actividad_rel = float(vol_entry / med_vol)
        else:
            actividad_rel = np.nan

        # Presi√≥n por volumen (magnitud relativa)
        presion_por_vol = float(presion_abs / vol_sum) if vol_sum == vol_sum and vol_sum > 0 else np.nan

        # ‚ÄúSin apoyo‚Äù: precio avanza en una direcci√≥n pero la presi√≥n va al lado opuesto
        d = r.get("dir")
        sin_apoyo = False
        if d == d and precio_neto == precio_neto:
            if d > 0 and precio_neto > 0 and presion_sum < 0:
                sin_apoyo = True
            elif d < 0 and precio_neto < 0 and presion_sum > 0:
                sin_apoyo = True

        return pd.Series({
            "pre_presion_sum": presion_sum,
            "pre_presion_abs": presion_abs,
            "pre_vol_sum": vol_sum,
            "pre_precio_neto": precio_neto,
            "pre_rango_precio": rango,
            "pre_mov_ticks": mov_ticks,
            "pre_absorcion": absorcion,
            "pre_actividad_rel": actividad_rel,
            "pre_presion_por_vol": presion_por_vol,
            "pre_sin_apoyo": sin_apoyo,
        })

    feats = t.apply(_row_feat, axis=1)
    for c in feats.columns:
        t[c] = feats[c]

    return t


# ============================================================
# Formatting & traffic-light helpers
# ============================================================
def pct(x, d=1):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}%"

def fmt(x, d=2):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}"

def traffic_pf(pf: float):
    if pf is None or np.isnan(pf):
        return "‚ö™ PF N/A"
    if pf < 1.0:  return "üî¥ PF < 1 (pierde)"
    if pf < 1.2:  return "üü° PF 1.0‚Äì1.2 (d√©bil)"
    if pf < 1.5:  return "üü¢ PF 1.2‚Äì1.5 (bueno)"
    return "üü£ PF > 1.5 (muy bueno)"

def traffic_exp(exp: float):
    if exp is None or np.isnan(exp):
        return "‚ö™ Promedio N/A"
    if exp < 0:   return "üî¥ Promedio < 0"
    if exp < 10:  return "üü° Promedio bajo pero positivo"
    return "üü¢ Promedio s√≥lido"


# ============================================================
# Core metrics
# ============================================================
def profit_factor(trades) -> float:
    """Profit Factor = suma de ganancias / suma absoluta de p√©rdidas.

    Acepta:
      - DataFrame con columna 'tradeRealized'
      - Serie de PnL (tradeRealized)
    """
    if trades is None:
        return np.nan

    # Permite pasar directamente la Serie tradeRealized
    if isinstance(trades, pd.Series):
        s = trades.dropna()
    else:
        if not isinstance(trades, pd.DataFrame) or "tradeRealized" not in trades.columns:
            return np.nan
        s = trades["tradeRealized"].dropna()

    wins = float(s[s > 0].sum())
    losses = float(s[s < 0].sum())  # negativo

    loss_abs = abs(losses)
    if loss_abs <= 0:
        # Sin p√©rdidas: PF infinito si hay ganancias, sino NaN
        return float("inf") if wins > 0 else np.nan

    return wins / loss_abs


def max_streak(outcomes: pd.Series, target: str):
    best_len, cur = 0, 0
    best_end = None
    for i, o in enumerate(outcomes.tolist()):
        if o == target:
            cur += 1
            if cur > best_len:
                best_len = cur
                best_end = i
        else:
            cur = 0
    if best_len == 0:
        return 0, None, None
    start = best_end - best_len + 1
    return best_len, start, best_end


def drawdown_details(t: pd.DataFrame):
    if t.empty:
        return np.nan, None, None
    dd = t["drawdown"].fillna(0)
    trough_idx = int(dd.idxmin())
    trough_time = t.loc[trough_idx, "exit_time"]
    peak_idx = int(t.loc[:trough_idx, "equity"].idxmax())
    peak_time = t.loc[peak_idx, "exit_time"]
    return float(dd.min()), peak_time, trough_time


def hour_bucket_label(h):
    if pd.isna(h):
        return "Sin hora"
    h = int(h)
    return f"{h:02d}:00‚Äì{h:02d}:59"



def pair_trades(df: pd.DataFrame) -> pd.DataFrame:
    """
    1 fila por trade (atmId):
    - EXIT: √∫ltimo por atmId
    - ENTRY: primero por atmId
    Si falta ENTRY -> lado = "Sin datos (falt√≥ ENTRY)" (NO inventamos)
    """
    entries = df[df["type"] == "ENTRY"].copy()
    exits = df[df["type"] == "EXIT"].copy()

    entry_cols = [
        "atmId", "ts_parsed", "dir",
        "instrument", "tickSize", "pointValue",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar",
        "volEntrySoFar", "deltaEntrySoFar",
        "snapN", "snapIncludesEntryBar",
        "volLastN", "deltaLastN",
        "openLastN", "highLastN", "lowLastN", "closeLastN"
    ]
    entry_cols = [c for c in entry_cols if c in entries.columns]

    if len(entry_cols) == 0:
        e1 = pd.DataFrame(columns=["atmId", "entry_time"])
    else:
        e1 = (entries.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[entry_cols]
                    .first()
                    .rename(columns={"ts_parsed": "entry_time"}))

    exit_cols = [
        "atmId", "ts_parsed",
        "outcome", "exitReason", "tradeRealized", "dayRealized",
        "maxUnreal", "minUnreal", "forcedCloseReason", "dailyHalt",
        "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "cvd", "deltaBar", "deltaPrevBar"
    ]
    exit_cols = [c for c in exit_cols if c in exits.columns]

    if len(exit_cols) == 0:
        x1 = pd.DataFrame(columns=["atmId", "exit_time", "tradeRealized"])
    else:
        x1 = (exits.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[exit_cols]
                    .last()
                    .rename(columns={"ts_parsed": "exit_time"}))

    t = pd.merge(x1, e1, on="atmId", how="left")

    # Unifica columnas duplicadas de EXIT/ENTRY (pandas crea sufijos _x/_y)
    def _coalesce(name: str):
        x = f"{name}_x"
        y = f"{name}_y"
        if name in t.columns:
            return
        if (x in t.columns) or (y in t.columns):
            base = t[y] if y in t.columns else pd.Series([np.nan]*len(t))
            if x in t.columns:
                base = base.where(base.notna(), t[x])
            t[name] = base
            drop_cols = [c for c in [x, y] if c in t.columns]
            if drop_cols:
                t.drop(columns=drop_cols, inplace=True)

    for nm in [
        "dir", "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar"
    ]:
        _coalesce(nm)

    t["has_entry"] = t.get("entry_time").notna() if "entry_time" in t.columns else False

    # Num√©ricos
    for c in [
        "tradeRealized", "dayRealized", "maxUnreal", "minUnreal",
        "orSize", "atr", "ewo", "deltaRatio", "dir",
        "atrSlMult", "tp1R", "tp2R", "trailStepTicks",
        "tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "volEntrySoFar", "deltaEntrySoFar"
    ]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    # outcome robusto si falta
    if "tradeRealized" in t.columns:
        calc_outcome = np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS")
        if "outcome" not in t.columns:
            t["outcome"] = calc_outcome
        else:
            t["outcome"] = t["outcome"].where(t["outcome"].notna(), calc_outcome)

    # Duraci√≥n
    if "entry_time" in t.columns and "exit_time" in t.columns:
        t["duration_sec"] = (t["exit_time"] - t["entry_time"]).dt.total_seconds()
    else:
        t["duration_sec"] = np.nan

    # Equity / drawdown
    t = t.sort_values("exit_time").reset_index(drop=True)
    t["equity"] = t["tradeRealized"].fillna(0).cumsum()
    t["equity_peak"] = t["equity"].cummax()
    t["drawdown"] = t["equity"] - t["equity_peak"]

    # Hora
    t["exit_hour"] = t["exit_time"].dt.hour
    t["exit_hour_label"] = t["exit_hour"].apply(hour_bucket_label)

    # Lado (Compra/Venta) solo si hay dir
    def side_label(x):
        if pd.isna(x):
            return "Sin datos (falt√≥ ENTRY)"
        if x > 0:
            return "Compra (Long)"
        if x < 0:
            return "Venta (Short)"
        return "Sin datos (dir=0)"

    if "dir" in t.columns:
        t["lado"] = t["dir"].apply(side_label)
    else:
        t["lado"] = "Sin datos (falt√≥ ENTRY)"

    # ============================================================
    # M√©tricas tuning: Riesgo estimado, Ganancia/Riesgo, Captura/Devoluci√≥n
    # ============================================================
    if "tickSize" in t.columns and "pointValue" in t.columns:
        t["tick_value"] = t["tickSize"] * t["pointValue"]
    else:
        t["tick_value"] = np.nan

    if "qtyTP1" in t.columns or "qtyRunner" in t.columns:
        q1 = t["qtyTP1"] if "qtyTP1" in t.columns else 0
        qr = t["qtyRunner"] if "qtyRunner" in t.columns else 0
        t["qty_total"] = pd.to_numeric(q1, errors="coerce").fillna(0) + pd.to_numeric(qr, errors="coerce").fillna(0)
    else:
        t["qty_total"] = np.nan

    if "slTicks" in t.columns and "tick_value" in t.columns and "qty_total" in t.columns:
        t["risk_$"] = t["slTicks"] * t["tick_value"] * t["qty_total"]
        t.loc[t["risk_$"] <= 0, "risk_$"] = np.nan
    else:
        t["risk_$"] = np.nan

    if "tradeRealized" in t.columns:
        t["rr"] = t["tradeRealized"] / t["risk_$"]
    else:
        t["rr"] = np.nan

    if "tradeRealized" in t.columns and "maxUnreal" in t.columns:
        winners = t["tradeRealized"] > 0
        t["captura_pct"] = np.where(winners & (t["maxUnreal"] > 0), t["tradeRealized"] / t["maxUnreal"], np.nan)
        t["devolucion_pct"] = np.where(winners & (t["maxUnreal"] > 0),
                                       (t["maxUnreal"] - t["tradeRealized"]) / t["maxUnreal"], np.nan)
    else:
        t["captura_pct"] = np.nan
        t["devolucion_pct"] = np.nan

    # Presi√≥n/Actividad pre-entrada (si hay arrays)
    t = add_pressure_activity_features(t)

    return t


def summarize(t: pd.DataFrame) -> dict:
    if t.empty:
        return {}
    n = len(t)
    wins = int((t["tradeRealized"] > 0).sum())
    losses = int((t["tradeRealized"] < 0).sum())
    win_rate = (wins / n * 100) if n else np.nan

    pf = profit_factor(t)
    expectancy = float(t["tradeRealized"].mean()) if n else np.nan

    max_dd, dd_peak_time, dd_trough_time = drawdown_details(t)

    max_win = float(t["tradeRealized"].max())
    max_loss = float(t["tradeRealized"].min())

    outcomes = pd.Series(np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS"))
    wlen, _, _ = max_streak(outcomes, "WIN")
    llen, _, _ = max_streak(outcomes, "LOSS")

    return {
        "n": n, "wins": wins, "losses": losses, "win_rate": win_rate,
        "pnl_total": float(t["tradeRealized"].sum()),
        "pf": pf, "expectancy": expectancy,
        "max_dd": max_dd, "dd_peak_time": dd_peak_time, "dd_trough_time": dd_trough_time,
        "max_win": max_win, "max_loss": max_loss,
        "best_win_streak": wlen, "best_loss_streak": llen,
    }


# ============================================================
# Grouping / bins
# ============================================================
def make_bins_quantiles(df: pd.DataFrame, col: str, q: int):
    s = df[col].dropna()
    if len(s) < q * 10:
        return None
    try:
        return pd.qcut(df[col], q=q, duplicates="drop")
    except Exception:
        return None



def group_metrics(df: pd.DataFrame, group_col: str, min_trades: int, recommended_trades: int = None):
    """M√©tricas por grupo con control de muestra.
    - NO oculta grupos peque√±os: los marca como üü¢/üü°/üî¥.
    - 'WinRate (ajustado)' evita que 2/2 (=100%) gane contra 30 trades.
    """
    if recommended_trades is None:
        recommended_trades = max(60, min_trades)

    rows = []
    for g, sub in df.groupby(group_col):
        n = int(len(sub))
        if n == 0:
            continue

        tr = pd.to_numeric(sub.get("tradeRealized"), errors="coerce")
        wins = int((tr > 0).sum()) if tr is not None else 0
        wr = wins / n * 100 if n else np.nan
        wr_adj = (wins + 1) / (n + 2) * 100  # suavizado

        pf = profit_factor(sub) if "tradeRealized" in sub.columns else np.nan
        exp = float(tr.mean()) if tr is not None else np.nan
        pnl = float(tr.sum()) if tr is not None else np.nan

        score = exp * np.log1p(n) if exp == exp else np.nan

        if n >= recommended_trades:
            estado = "üü¢ Suficiente"
        elif n >= min_trades:
            estado = "üü° Muestra peque√±a"
        else:
            estado = "üî¥ No concluyente"

        rows.append({
            "Grupo": str(g),
            "Trades": n,
            "Estado": estado,
            "WinRate %": wr,
            "WinRate (ajustado) %": wr_adj,
            "Profit Factor": pf,
            "Promedio por trade": exp,
            "PnL Total": pnl,
            "Score (ponderado)": score,
        })

    out = pd.DataFrame(rows)
    if not out.empty:
        out = out.sort_values(["Score (ponderado)", "Trades"], ascending=[False, False], na_position="last").reset_index(drop=True)
    return out


# ============================================================
# Advice engines (NEXT LEVEL)
# ============================================================
def advice_from_table(tbl: pd.DataFrame, title: str, min_trades: int):
    if tbl is None or tbl.empty:
        st.info(f"En **{title}** no hay suficiente muestra (m√≠nimo {min_trades} trades por grupo).")
        return

    best = tbl.iloc[0]
    worst = tbl.iloc[-1]

    st.markdown("**‚úÖ Consejos r√°pidos (tabla):**")
    st.write(
        f"üèÜ Mejor: **{best['Grupo']}** | Trades={int(best['Trades'])} | PF={fmt(best['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(best['Promedio por trade'],1)} | PnL={fmt(best['PnL Total'],0)}"
    )
    st.write(
        f"üß® Peor: **{worst['Grupo']}** | Trades={int(worst['Trades'])} | PF={fmt(worst['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(worst['Promedio por trade'],1)} | PnL={fmt(worst['PnL Total'],0)}"
    )

    # warnings
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è El mejor grupo tiene muestra peque√±a. Ideal confirmar con m√°s meses de logs.")
    if not np.isnan(best["Profit Factor"]) and best["Profit Factor"] < 1.0:
        st.error("üö® Incluso el mejor grupo tiene PF < 1 ‚Üí este filtro no est√° salvando el sistema en estos datos.")
    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning("üëâ Hay grupos con PF < 1 ‚Üí candidatos a filtrar/evitar.")

    st.caption("Nota: WinRate Ajustado + Score ponderado evitan que 2 trades al 100% ‚Äúganen‚Äù contra 30 trades.")


def pnl_shape_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].dropna()
    if pnl.empty:
        return []

    med = float(pnl.median())
    p25 = float(pnl.quantile(0.25))
    p75 = float(pnl.quantile(0.75))
    p10 = float(pnl.quantile(0.10))
    p90 = float(pnl.quantile(0.90))

    max_win = float(pnl.max())
    max_loss = float(pnl.min())
    avg_win = float(pnl[pnl > 0].mean()) if (pnl > 0).any() else np.nan
    avg_loss = float(pnl[pnl < 0].mean()) if (pnl < 0).any() else np.nan

    insights = []
    insights.append(f"üìå Mediana PnL: **{med:.1f}** | IQR (25‚Äì75%): **[{p25:.1f}, {p75:.1f}]**")

    if not np.isnan(avg_win) and not np.isnan(avg_loss) and avg_loss != 0:
        ratio = abs(avg_win / avg_loss)
        if ratio < 0.8:
            insights.append("‚ö†Ô∏è P√©rdidas promedio > ganancias promedio ‚Üí revisa SL, entradas tard√≠as, o horarios peligrosos.")
        elif ratio < 1.2:
            insights.append("üü° Ganancia y p√©rdida promedio similares ‚Üí el edge depende m√°s del winrate + filtros.")
        else:
            insights.append("üü¢ Ganancias promedio > p√©rdidas promedio ‚Üí buena relaci√≥n base si el winrate acompa√±a.")

    if max_win != 0:
        bomb = abs(max_loss) / abs(max_win)
        if bomb >= 1.5:
            insights.append("üö® P√©rdidas gigantes vs la mayor ganancia. Revisa stops, slippage, noticias, o ‚Äúchasing‚Äù.")
        elif bomb >= 1.0:
            insights.append("‚ö†Ô∏è La peor p√©rdida compite con la mejor ganancia. Controla los outliers.")

    insights.append(f"üß≠ Zona t√≠pica (10‚Äì90%): **[{p10:.1f}, {p90:.1f}]**. Fuera de esto son outliers.")
    return insights


def equity_recovery_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].fillna(0)
    exp = float(pnl.mean()) if len(pnl) else np.nan
    std = float(pnl.std()) if len(pnl) > 2 else np.nan

    max_dd, peak_t, trough_t = drawdown_details(t)

    insights = []
    if peak_t is not None and trough_t is not None:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}** (desde {peak_t} hasta {trough_t})")
    else:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}**")

    if exp < 0:
        insights.append("üö® Promedio por trade negativo: necesitas filtros fuertes o cambiar l√≥gica antes de ‚Äútunear fino‚Äù.")
    else:
        insights.append(f"‚úÖ Promedio por trade: **{exp:.1f}** ({traffic_exp(exp)})")

    if not np.isnan(std) and std > 0 and not np.isnan(exp):
        cv = abs(std / exp) if exp != 0 else np.inf
        if exp > 0 and cv > 6:
            insights.append("‚ö†Ô∏è PnL muy vol√°til vs el promedio ‚Üí sube muestra o filtra momentos de alta variabilidad.")
        elif exp > 0 and cv > 3:
            insights.append("üü° Variabilidad moderada-alta ‚Üí usa guardias diarias conservadoras.")
        elif exp > 0:
            insights.append("üü¢ PnL relativamente estable vs el promedio.")

    if exp > 0 and not np.isnan(max_dd):
        dd_trades_equiv = abs(max_dd / exp)
        if dd_trades_equiv > 80:
            insights.append("üö® Drawdown enorme relativo al promedio ‚Üí recuperaci√≥n puede tardar mucho.")
        elif dd_trades_equiv > 40:
            insights.append("‚ö†Ô∏è Drawdown alto relativo al promedio ‚Üí requiere disciplina (guardia diaria / filtros).")
        else:
            insights.append("üü¢ Drawdown razonable relativo al promedio.")

    return insights


def factor_danger_zone_insights(df_known: pd.DataFrame, xcol: str, q: int, min_trades: int, title: str):
    bins = make_bins_quantiles(df_known, xcol, q)
    if bins is None:
        return ["‚ÑπÔ∏è No hay suficiente data para detectar zonas por rangos."]

    tmp = df_known.copy()
    tmp["_bin"] = bins.astype(str)
    tbl = group_metrics(tmp, "_bin", min_trades=min_trades)

    if tbl.empty:
        return [f"‚ÑπÔ∏è No hay rangos con ‚â• {min_trades} trades para {title}."]

    # zonas malas
    bad = tbl[(tbl["Promedio por trade"] < 0) & (tbl["Profit Factor"] < 1.0)].copy()
    good = tbl[(tbl["Promedio por trade"] > 0) & (tbl["Profit Factor"] >= 1.2)].copy()

    insights = []
    if not bad.empty:
        b = bad.sort_values("Score (ponderado)").iloc[0]
        insights.append(f"üö´ Zona peligrosa: **{b['Grupo']}** ‚Üí promedio<0 y PF<1 (candidato a EVITAR).")
    else:
        insights.append("‚úÖ No se detectan rangos claramente peligrosos (con muestra suficiente).")

    if not good.empty:
        g = good.sort_values("Score (ponderado)", ascending=False).iloc[0]
        insights.append(f"‚úÖ Zona fuerte: **{g['Grupo']}** ‚Üí PF‚â•1.2 y promedio>0 (candidato a priorizar).")

    spread = float(tbl["Promedio por trade"].max() - tbl["Promedio por trade"].min())
    if spread < 5:
        insights.append("‚ÑπÔ∏è Este factor casi no separa rendimiento (spread peque√±o) ‚Üí filtro d√©bil por s√≠ solo.")
    else:
        insights.append("üìå Este factor S√ç separa rendimiento ‚Üí √∫til para tunear rangos.")
    return insights


# ============================================================
# Charts
# ============================================================
def plot_equity_drawdown(t: pd.DataFrame):
    fig1 = px.line(t, x="exit_time", y="equity", title="Equity (curva de capital acumulada)")
    fig1.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))

    fig2 = px.line(t, x="exit_time", y="drawdown", title="Drawdown (ca√≠da desde el m√°ximo de equity)")
    fig2.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))
    fig2.add_hline(y=0, line_width=1, line_dash="dash")
    return fig1, fig2


def plot_pnl_hist(t: pd.DataFrame):
    """Histograma de PnL realizado (dinero). tradeRealized est√° en la moneda de la cuenta (normalmente $)."""
    tmp = t.copy()
    tr = pd.to_numeric(tmp.get("tradeRealized"), errors="coerce")
    tmp["Resultado"] = np.where(tr >= 0, "Ganancia", "P√©rdida")

    fig = px.histogram(
        tmp,
        x="tradeRealized",
        color="Resultado",
        nbins=40,
        barmode="overlay",
        title="Distribuci√≥n de PnL ($) por operaci√≥n",
        labels={"tradeRealized": "PnL ($)"},
    )
    fig.update_traces(opacity=0.75)
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    fig.add_vline(x=0, line_width=1, line_dash="dash")
    return fig


def plot_scatter_advanced(df_known: pd.DataFrame, xcol: str, title: str):
    cols = [c for c in [xcol, "tradeRealized", "exit_time", "lado", "exitReason"] if c in df_known.columns]
    tmp = df_known[cols].dropna(subset=[xcol, "tradeRealized"]).copy()
    if tmp.empty:
        st.info("No hay suficiente data para el scatter.")
        return

    tmp["Resultado"] = np.where(tmp["tradeRealized"] >= 0, "Ganancia", "P√©rdida")

    fig = px.scatter(
        tmp,
        x=xcol,
        y="tradeRealized",
        color="Resultado",
        hover_data=[c for c in ["exit_time", "lado", "exitReason", "tradeRealized"] if c in tmp.columns],
        title=title
    )
    fig.update_traces(marker=dict(size=7, opacity=0.60))
    fig.add_hline(y=0, line_width=1, line_dash="dash")
    fig.update_layout(height=440, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.caption("Lectura: verde = PnL ‚â• 0, rojo = PnL < 0. Con muestra peque√±a, √∫salo como idea, no como regla.")




def plot_factor_bins(df_known: pd.DataFrame, col: str, q: int, min_trades: int, recommended_trades: int, title: str,
                     show_scatter: bool, scatter_df: pd.DataFrame):
    """
    Panel por rangos (cuantiles) para un factor (OR/ATR/EWO/etc).
    - Colores consistentes: verde = mejor, rojo = peor.
    - Sin 'bins' en UI: todo se llama 'rangos'.
    - Etiquetas humanas para rangos (ej: 60‚Äì94).
    """
    def nice_range_label(s: str) -> str:
        if not isinstance(s, str):
            return str(s)
        s2 = s.strip()
        # Formatos t√≠picos: "(60.0, 94.0]" o "[14.5, 60.0)"
        if ("," in s2) and (s2[0] in "([") and (s2[-1] in "])"):
            inner = s2[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    a = float(parts[0])
                    b = float(parts[1])
                    # Redondeo ‚Äúhumano‚Äù
                    if abs(a) >= 100 or abs(b) >= 100:
                        return f"{a:.0f}‚Äì{b:.0f}"
                    if abs(a) >= 10 or abs(b) >= 10:
                        return f"{a:.1f}‚Äì{b:.1f}"
                    return f"{a:.2f}‚Äì{b:.2f}"
                except Exception:
                    return s2
        return s2

    bins = make_bins_quantiles(df_known, col, q)
    if bins is None:
        st.info(f"No hay suficiente data para crear rangos en **{title}**.")
        return

    tmp = df_known.copy()
    tmp["_range"] = bins.astype(str)

    tbl = group_metrics(tmp, "_range", min_trades=min_trades, recommended_trades=recommended_trades)
    if tbl.empty:
        st.info(f"En **{title}** no hay data para agrupar.")
        return

    # Etiquetas humanas (m√°s f√°ciles de leer)
    _orig = tbl["Grupo"].astype(str).tolist()
    _nice = [nice_range_label(x) for x in _orig]

    def _parse_left(rg: str):
        rg = str(rg).strip()
        if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
            inner = rg[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    return float(parts[0])
                except Exception:
                    return np.nan
        return np.nan

    lefts = [(_parse_left(o), i) for i, o in enumerate(_orig)]
    order = [i for _, i in sorted(lefts, key=lambda x: (np.nan_to_num(x[0], nan=1e18), x[1]))]

    k = len(_nice)
    if k == 3:
        names = ["Bajo", "Medio", "Alto"]
    elif k == 4:
        names = ["Bajo", "Medio-bajo", "Medio-alto", "Alto"]
    elif k == 5:
        names = ["Muy bajo", "Bajo", "Medio", "Alto", "Muy alto"]
    else:
        names = [f"R{i+1}" for i in range(k)]

    label_map = {}
    for rank, idx in enumerate(order):
        base = names[rank] if rank < len(names) else f"R{rank+1}"
        label_map[_orig[idx]] = f"{base} ({_nice[idx]})"

    tbl["Grupo"] = tbl["Grupo"].astype(str).map(label_map).fillna(tbl["Grupo"].astype(str))

    # Leyenda de muestra
    n_ok = int((tbl["Estado"] == "üü¢ Suficiente").sum())
    n_small = int((tbl["Estado"] == "üü° Muestra peque√±a").sum())
    n_bad = int((tbl["Estado"] == "üî¥ No concluyente").sum())
    st.caption(
        f"Muestra por rango: üü¢{n_ok} üü°{n_small} üî¥{n_bad}  | "
        f"M√≠nimo para mirar: {min_trades}  | Recomendado para decidir: {recommended_trades}"
    )

    # Para gr√°ficos: solo rangos con muestra m√≠nima
    tbl_chart = tbl[tbl["Trades"] >= min_trades].copy()

    if not tbl_chart.empty:
        # Promedio por trade: verde = mejor, rojo = peor. Centramos en 0 (negativos quedan rojos).
        fig_exp = px.bar(
            tbl_chart,
            x="Grupo",
            y="Promedio por trade",
            color="Promedio por trade",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=0,
            title=f"{title} ‚Üí Promedio por trade (rangos)",
            text="Promedio por trade",
        )
        fig_exp.update_traces(texttemplate="%{text:.0f}", textposition="inside")
        fig_exp.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="Promedio",
        )
        fig_exp.add_hline(y=0, line_width=1, line_dash="dash")

        # Profit Factor: verde = alto (mejor), rojo = bajo (peor). Punto neutro en 1.0.
        fig_pf = px.bar(
            tbl_chart,
            x="Grupo",
            y="Profit Factor",
            color="Profit Factor",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=1.0,
            title=f"{title} ‚Üí Profit Factor (rangos)",
            text="Profit Factor",
        )
        fig_pf.update_traces(texttemplate="%{text:.2f}", textposition="inside")
        fig_pf.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="PF",
        )
        fig_pf.add_hline(y=1.0, line_width=1, line_dash="dash")

        st.plotly_chart(fig_exp, use_container_width=True)
        st.plotly_chart(fig_pf, use_container_width=True)

        st.caption("Profit Factor (PF) = Ganancias totales / P√©rdidas totales. PF>1 indica que el conjunto gana. "
                   "PF>1.5 suele ser s√≥lido si la muestra es suficiente (üü¢).")

        advice_from_table(tbl_chart, title, min_trades=min_trades)
    else:
        st.info("‚ö†Ô∏è Con el m√≠nimo actual, todos los rangos quedan con poca muestra. √ösalo como idea, no como regla.")

    st.dataframe(tbl, use_container_width=True)

    if show_scatter:
        st.markdown("**Scatter (solo para ver dispersi√≥n / outliers)**")
        if col in scatter_df.columns and scatter_df[col].notna().sum() >= max(20, min_trades):
            plot_scatter_advanced(scatter_df, col, title=f"{title} ‚Üí Scatter")
        else:
            st.info("No hay suficiente data para scatter en este factor.")

def plot_hour_analysis(t: pd.DataFrame, min_trades: int):
    tbl = group_metrics(t, "exit_hour_label", min_trades=min_trades)
    if tbl.empty:
        st.info(f"No hay suficientes trades por hora para min_trades={min_trades}.")
        return None

    fig = px.bar(tbl, x="Grupo", y="Score (ponderado)",
                 title="Horas m√°s prometedoras (Score ponderado por tama√±o de muestra)")
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.dataframe(tbl, use_container_width=True)
    advice_from_table(tbl, title="Hora", min_trades=min_trades)
    return tbl



def plot_heatmap_weekday_hour(t: pd.DataFrame, min_trades: int):
    tmp = t.copy()

    if "exit_time" not in tmp.columns or tmp["exit_time"].isna().all():
        st.info("No hay exit_time v√°lido para generar el heatmap.")
        return

    tmp = tmp.dropna(subset=["exit_time"]).copy()
    tmp["weekday"] = tmp["exit_time"].dt.day_name()
    if "exit_hour" not in tmp.columns or tmp["exit_hour"].isna().all():
        tmp["exit_hour"] = tmp["exit_time"].dt.hour

    weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    tmp["weekday_order"] = pd.Categorical(tmp["weekday"], categories=weekday_order, ordered=True)

    agg = tmp.groupby(["weekday_order", "exit_hour"]).agg(
        Trades=("tradeRealized", "size"),
        Promedio=("tradeRealized", "mean"),
    ).reset_index()

    agg.loc[agg["Trades"] < min_trades, "Promedio"] = np.nan
    pivot = agg.pivot(index="weekday_order", columns="exit_hour", values="Promedio")

    # Si con el m√≠nimo actual no queda nada visible, avisamos y no dibujamos un heatmap vac√≠o.
    if pivot.count().sum() == 0:
        st.info(
            f"No hay celdas con ‚â• {min_trades} trades para el heatmap. "
            "Baja el m√≠nimo o usa el panel por hora (arriba), que requiere menos muestra."
        )
        return

    # Escala azul‚Üírojo (negativo‚Üípositivo). Centramos en 0 para lectura r√°pida.
    vals = pivot.values.astype(float)
    max_abs = np.nanmax(np.abs(vals)) if np.isfinite(vals).any() else None
    zmin = -max_abs if max_abs else None
    zmax = max_abs if max_abs else None

    # Compatibilidad: algunas versiones de Plotly no soportan text_auto en imshow.
    try:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
            text_auto=True,
        )
    except TypeError:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
        )
        # A√±adimos etiquetas manuales (valores)
        for yi, day in enumerate(pivot.index.astype(str).tolist()):
            for xi, hour in enumerate(pivot.columns.tolist()):
                v = pivot.loc[pivot.index[yi], hour]
                if pd.notna(v):
                    fig.add_annotation(
                        x=hour,
                        y=day,
                        text=f"{v:.0f}",
                        showarrow=False,
                        font=dict(size=11, color="black"),
                    )

    fig.update_layout(height=460, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)
    st.caption("Azul = promedio negativo, rojo = promedio positivo. Si casi todo queda vac√≠o, baja el m√≠nimo (muestra peque√±a).")

# ============================================================
# UI
# ============================================================
st.title("üìä WIC_WLF2 Analizador")

uploaded = st.file_uploader(
    "üì§ Sube uno o varios archivos .jsonl (meses)",
    type=["jsonl"],
    accept_multiple_files=True
)
if not uploaded:
    st.stop()

all_records, bad_total = [], 0
for uf in uploaded:
    recs, bad = parse_jsonl_bytes(uf.getvalue())
    bad_total += bad
    all_records.extend(recs)

if not all_records:
    st.error("No se pudo leer ning√∫n registro JSON v√°lido.")
    st.stop()

df = pd.DataFrame(all_records)
df = normalize_columns(df)
t = pair_trades(df)

if bad_total > 0:
    st.caption(f"‚ÑπÔ∏è L√≠neas inv√°lidas ignoradas al parsear: **{bad_total}**")

missing_entry = int((~t["has_entry"]).sum())
if missing_entry > 0:
    st.warning(
        f"‚ö†Ô∏è **{missing_entry} operaciones no tienen ENTRY** en los archivos cargados. "
        "En esas, no se puede saber Compra/Venta ni ORSize/ATR/EWO/DeltaRatio. "
        "Se muestran como: ‚ÄúSin datos (falt√≥ ENTRY)‚Äù."
    )

# Sidebar controls
st.sidebar.subheader("‚öôÔ∏è Ajustes")
min_trades = st.sidebar.slider("M√≠nimo trades por grupo (para mirar)", 5, 120, 30, 5)
recommended_trades = st.sidebar.slider("Trades recomendados por grupo (para decidir)", 20, 300, 80, 10)
q_bins = st.sidebar.slider("N√∫mero de rangos (cuantiles)", 3, 12, 5, 1)

show_adv_scatter = st.sidebar.checkbox("Mostrar scatter (√∫til para ver outliers)", value=False)
last_n_scatter = st.sidebar.slider("Scatter: √∫ltimos N trades (0=todo)", 0, 3000, 800, 100)

summary = summarize(t)

# ============================================================
# Summary
# ============================================================
st.subheader("‚úÖ Resumen r√°pido (lo m√°s importante)")

c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric("Operaciones", f"{summary['n']}")
c2.metric("Ganadas", f"{summary['wins']}")
c3.metric("Perdidas", f"{summary['losses']}")
c4.metric("% Acierto", f"{summary['win_rate']:.1f}%")
c5.metric("PnL Total", f"{summary['pnl_total']:.0f}")
c6.metric("Profit Factor", f"{summary['pf']:.2f}" if not np.isnan(summary["pf"]) else "N/A")

c7, c8, c9, c10, c11, c12 = st.columns(6)
c7.metric("Promedio por trade (Expectancia)", f"{summary['expectancy']:.1f}")
c8.metric("Max Drawdown", f"{summary['max_dd']:.0f}")
c9.metric("Racha wins seguidos", f"{summary['best_win_streak']}")
c10.metric("Racha losses seguidos", f"{summary['best_loss_streak']}")
c11.metric("Mayor win", f"{summary['max_win']:.1f}")
c12.metric("Mayor loss", f"{summary['max_loss']:.1f}")

with st.expander("üìå C√≥mo leer estas m√©tricas (simple)"):
    st.write("**Promedio por trade (Expectancia)**: lo que ganas/pierdes en promedio por operaci√≥n. Si es positivo, bien.")
    st.write("**Profit Factor**: ganancias totales / p√©rdidas totales. PF > 1.0 indica ventaja. PF > 1.2 suele ser m√°s s√≥lido.")
    st.write("**Drawdown**: la peor ca√≠da desde el m√°ximo de tu equity; representa el ‚Äúdolor m√°ximo‚Äù del sistema.")
    st.write("**Rachas**: cu√°ntas operaciones ganadas/perdidas seguidas (√∫til para guardias diarias y sizing).")

st.markdown("### ‚öôÔ∏è Avisos seg√∫n tus ajustes")
total_n = int(summary.get("n", 0))
if total_n < 60:
    st.info("Muestra peque√±a (menos de 60 trades). √ösalo para orientar el tuning, pero evita cambiar reglas por 3 trades.")

# Si el usuario pide demasiados rangos o m√≠nimos para la muestra, casi todo quedar√° vac√≠o.
if q_bins * max(1, min_trades) > max(1, total_n):
    st.warning(
        "‚ö†Ô∏è Con estos ajustes vas a ver muchos paneles vac√≠os: est√°s pidiendo demasiados rangos o un m√≠nimo demasiado alto para tu muestra. "
        "Sugerencia con esta cantidad de trades: 3‚Äì5 rangos y m√≠nimo 10‚Äì20 trades por grupo."
    )
if min_trades > max(10, total_n // 2):
    st.warning("‚ö†Ô∏è M√≠nimo por grupo muy alto vs tu total de trades. Baja el m√≠nimo si quieres ver m√°s comparaciones (con cuidado).")
if recommended_trades > total_n:
    st.info("Recomendaci√≥n: tu 'trades recomendados para decidir' es mayor que tu muestra actual, as√≠ que todas las conclusiones son provisionales.")

# ============================================================
# Main charts
# ============================================================
st.subheader("üìà Gr√°ficos principales (claros + consejos)")

fig_eq, fig_dd = plot_equity_drawdown(t)
colA, colB = st.columns(2)
with colA:
    st.plotly_chart(fig_eq, use_container_width=True)
with colB:
    st.plotly_chart(fig_dd, use_container_width=True)

st.markdown("### üß† Consejos autom√°ticos (Equity / Drawdown)")
for s in equity_recovery_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.success(s)

st.plotly_chart(plot_pnl_hist(t), use_container_width=True)
st.caption("PnL ($) = dinero realizado por trade (tradeRealized). Si quieres verlo en ticks/points, se puede derivar con tickSize/pointValue, pero aqu√≠ mostramos la realidad de la cuenta.")

st.markdown("### üß† Consejos autom√°ticos (Distribuci√≥n de PnL)")
for s in pnl_shape_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.info(s)


# ============================================================
# Ganancia vs Riesgo (RR) + Captura / Devoluci√≥n
# ============================================================
st.subheader("üéØ Ganancia vs Riesgo (RR) y manejo de la operaci√≥n")

if "rr" not in t.columns or t["rr"].dropna().empty:
    st.info(
        "No hay datos suficientes para calcular RR. Para esto necesitas en el log (ENTRY o EXIT): "
        "tickSize, pointValue, slTicks y cantidades (qtyTP1/qtyRunner)."
    )
else:
    rr_df = t[t["rr"].notna()].copy()

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("RR mediana", f"{rr_df['rr'].median():.2f}")
    c2.metric("RR promedio", f"{rr_df['rr'].mean():.2f}")
    c3.metric("% RR ‚â• 1", f"{(rr_df['rr'] >= 1).mean()*100:.1f}%")
    c4.metric("% RR ‚â• 2", f"{(rr_df['rr'] >= 2).mean()*100:.1f}%")
    c5.metric("Trades con RR", f"{len(rr_df)}")

    # M√©tricas extra (m√°s f√°ciles de leer con muestras peque√±as)
    rr_wins = rr_df.loc[rr_df["rr"] > 0, "rr"]
    rr_losses = rr_df.loc[rr_df["rr"] < 0, "rr"]
    small_losses = rr_df[(rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)]

    c6, c7, c8 = st.columns(3)
    c6.metric("RR promedio (ganadores)", f"{rr_wins.mean():.2f}" if not rr_wins.empty else "N/A")
    c7.metric("RR promedio (perdedores)", f"{rr_losses.mean():.2f}" if not rr_losses.empty else "N/A")
    c8.metric("% p√©rdidas peque√±as (-0.5R a 0)", f"{len(small_losses)/len(rr_df)*100:.1f}%" if len(rr_df) else "N/A")

    rr_tmp = rr_df.copy()
    rr_tmp["Resultado"] = np.where(rr_tmp["rr"] >= 0, "Ganancia", "P√©rdida")
    fig_rr = px.histogram(
        rr_tmp,
        x="rr",
        color="Resultado",
        nbins=30,
        barmode="overlay",
        title="Distribuci√≥n de RR (Ganancia/Riesgo)",
        labels={"rr": "RR"},
    )
    fig_rr.update_traces(opacity=0.75)
    fig_rr.add_vline(x=0, line_width=1, line_dash="dash")
    fig_rr.add_vline(x=1, line_width=1, line_dash="dash")
    fig_rr.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig_rr, use_container_width=True)

    st.markdown("**C√≥mo leer RR (r√°pido)**")
    rr_med = rr_df["rr"].median()
    rr_mean = rr_df["rr"].mean()
    if rr_mean > 0 and rr_med < 0:
        st.info("Promedio > 0 y mediana < 0: el resultado depende de pocos trades grandes; la mayor√≠a pierde.")
    elif rr_mean > 0 and rr_med > 0:
        st.info("Promedio > 0 y mediana > 0: la mayor√≠a de trades aporta; comportamiento m√°s estable.")
    elif rr_mean < 0:
        st.info("Promedio < 0: el sistema est√° perdiendo (tuning o filtros urgentes).")
    st.caption("Con pocas operaciones, confirma con m√°s trades antes de cambiar reglas.")

    st.markdown("### üß† Pistas r√°pidas (RR)")
    pct_rr1 = (rr_df["rr"] >= 1).mean()
    pct_stop = (rr_df["rr"] <= -1).mean()
    pct_small_loss = ((rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)).mean()

    if pct_rr1 < 0.35:
        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if pct_stop > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if pct_small_loss < 0.05 and pct_stop > 0.15:
        st.info("üü° Casi no hay p√©rdidas peque√±as: cuando pierdes, sueles perder ~1R completo. Eso suele indicar 'stop-out' frecuente (poco margen para salir antes). Buen candidato: mejorar filtros de entrada/horario o invalidaci√≥n temprana.")

    if rr_df["rr"].median() > 0.3 and pct_rr1 > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if (rr_df["rr"] <= -1).mean() > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if rr_df["rr"].median() > 0.3 and (rr_df["rr"] >= 1).mean() > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

    # Captura / Devoluci√≥n (solo ganadores)
    if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
        wincap = t["captura_pct"].dropna()
        wingb = t["devolucion_pct"].dropna()

        c6, c7, c8 = st.columns(3)
        c6.metric("Captura mediana", f"{wincap.median()*100:.0f}%")
        c7.metric("Devoluci√≥n mediana", f"{wingb.median()*100:.0f}%")
        c8.metric("Ganadores con datos", f"{len(wincap)}")

        # Mostrar en % (0‚Äì100). Si ves valores >100%, suele ser inconsistencia de log (maxUnreal no captur√≥ el pico real).
        raw_cap = t["captura_pct"].dropna()
        n_weird = int((raw_cap > 1.05).sum())
        if n_weird > 0:
            st.warning("‚ö†Ô∏è Veo algunos valores de 'captura' > 100%. Eso suele pasar cuando maxUnreal no captur√≥ el pico real (o por parciales). "
                       "Para no confundir, el gr√°fico se limita a 0‚Äì100%.")

        cap_plot = (raw_cap.clip(0, 1) * 100.0)
        cap_df = pd.DataFrame({"Captura (%)": cap_plot})

        fig_cap = px.histogram(
            cap_df,
            x="Captura (%)",
            nbins=20,
            title="Qu√© tan cerca del pico cierras (solo ganadores)",
        )
        fig_cap.add_vline(x=50, line_width=1, line_dash="dash")
        fig_cap.update_layout(height=300, margin=dict(l=10, r=10, t=50, b=10))
        st.plotly_chart(fig_cap, use_container_width=True)

        st.markdown("**Qu√© significa esto (en simple)**")
        st.write(
            "Solo se calcula en trades **ganadores**. "
            "La idea es responder: **¬øcerr√© cerca del mejor punto, o dej√© devolver mucho?**"
        )
        st.write(
            "- **Pico del trade** = el mejor PnL flotante que tuvo antes de cerrar (*maxUnreal*).\n"
            "- **Te quedas (captura)** = qu√© % de ese pico terminaste cobrando al cerrar.\n"
            "- **Devolviste (devoluci√≥n)** = qu√© % retrocedi√≥ desde el pico hasta el cierre."
        )
        st.write(
            "Ejemplo: el trade lleg√≥ a **+$500** (pico) y cerr√≥ en **+$475** ‚Üí "
            "Te quedas ‚âà **95%** y devolviste ‚âà **5%**."
        )

        st.markdown("**üß† Consejos autom√°ticos (salidas / trailing)**")
        cap_med = wincap.median() if not wincap.empty else np.nan
        gb_med = wingb.median() if not wingb.empty else np.nan

        if cap_med == cap_med and cap_med < 0.35:
            st.warning("‚ö†Ô∏è Captura mediana baja (<35%). Est√°s cerrando muy lejos del mejor punto: revisa trailing, TP, o reglas de salida temprana.")
        elif cap_med == cap_med and cap_med > 0.60:
            st.success("‚úÖ Captura mediana alta (>60%). Buen manejo de salida (en esta muestra).")
        else:
            st.info("üü° Captura mediana intermedia. Puede estar bien; valida con m√°s trades.")

        if gb_med == gb_med and gb_med > 0.60:
            st.warning("‚ö†Ô∏è Devoluci√≥n mediana alta (>60%). Est√°s devolviendo mucho: prueba trailing m√°s agresivo o TP parcial mejor definido.")
        elif gb_med == gb_med and gb_med < 0.35:
            st.success("‚úÖ Devoluci√≥n mediana baja (<35%). Sueles proteger ganancias a tiempo.")
        else:
            st.info("üü° Devoluci√≥n mediana intermedia. Ajusta solo si ves que afecta RR/expectancia.")

        st.caption("Interpretaci√≥n r√°pida: Captura alta suele indicar salidas eficientes; Devoluci√≥n alta suele indicar trailing/TP tarde o dejar correr sin proteger.")

    # RR por plantilla / tipo de orden
    split_cols = []
    # Evitamos 'trigger' porque suele ser demasiado gen√©rico y confunde a usuarios finales.
    for c in ["template", "orderType", "exitReason", "lado"]:
        if c in rr_df.columns and rr_df[c].notna().sum() > 0:
            split_cols.append(c)

    if split_cols:
        pick = st.selectbox("Comparar RR por:", split_cols, index=0)
        rr_tbl = group_metrics(rr_df, pick, min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.dataframe(rr_tbl, use_container_width=True)
        st.caption("Tip: usa 'Estado' üü¢/üü°/üî¥ para no enamorarte de grupos con 3 trades.")

# ============================================================
# Motivos de salida
# ============================================================
st.subheader("üö™ Motivos de salida (qu√© est√° cerrando tus trades)")

colA, colB = st.columns(2)

with colA:
    if "exitReason" in t.columns and t["exitReason"].notna().sum() > 0:
        tbl_exit = group_metrics(t, "exitReason", min_trades=min_trades, recommended_trades=recommended_trades)
        st.markdown("**ExitReason**")
        st.dataframe(tbl_exit, use_container_width=True)

        # Pistas
        if not tbl_exit.empty:
            worst = tbl_exit.sort_values("Promedio por trade").iloc[0]
            if float(worst["Promedio por trade"]) < 0 and int(worst["Trades"]) >= min_trades:
                st.warning(f"‚ö†Ô∏è Peor motivo (por promedio): **{worst['Grupo']}**. Revisa ese flujo/condici√≥n.")
    else:
        st.info("No hay exitReason en los logs.")

with colB:
    if "forcedCloseReason" in t.columns and t["forcedCloseReason"].notna().sum() > 0:
        tbl_fc = group_metrics(t, "forcedCloseReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.markdown("**ForcedCloseReason**")
        st.dataframe(tbl_fc, use_container_width=True)

        if not tbl_fc.empty:
            hot = tbl_fc.sort_values("Trades", ascending=False).iloc[0]
            if int(hot["Trades"]) >= min_trades and float(hot["Promedio por trade"]) < 0:
                st.warning(f"üö® Forced close frecuente y negativo: **{hot['Grupo']}**. Esto suele ser 'regla' o 'protecci√≥n' mal calibrada.")
    else:
        st.info("No hay forcedCloseReason en los logs.")

st.caption("OJO: el motivo de salida es diagn√≥stico, no filtro m√°gico. √ösalo para detectar patrones (stops, daily halt, cierre forzado, etc.).")


# ============================================================
# Long vs Short
# ============================================================
st.subheader("üß≠ Compra vs Venta (solo donde hay ENTRY)")

col1, col2, col3 = st.columns(3)
col1.metric("Compras (Long)", int((t["lado"] == "Compra (Long)").sum()))
col2.metric("Ventas (Short)", int((t["lado"] == "Venta (Short)").sum()))
col3.metric("Sin datos (falt√≥ ENTRY)", int((t["lado"].str.startswith("Sin datos")).sum()))

known = t[t["lado"].isin(["Compra (Long)", "Venta (Short)"])].copy()
if known.empty:
    st.info("No hay suficientes trades con ENTRY para separar Compra/Venta.")
else:
    side_tbl = group_metrics(known, "lado", min_trades=max(5, min_trades // 2))
    st.dataframe(side_tbl, use_container_width=True)
    advice_from_table(side_tbl, title="Compra/Venta", min_trades=max(5, min_trades // 2))

# ============================================================
# Tuning factors
# ============================================================
st.subheader("üõ†Ô∏è Ajuste de filtros (tunear settings con datos reales)")

if known.empty:
    st.info("Estos an√°lisis necesitan ENTRY (para tener ORSize/ATR/EWO/DeltaRatio por trade).")
else:
    df_known = known.copy()
    df_scatter = df_known.sort_values("exit_time")
    if last_n_scatter and last_n_scatter > 0:
        df_scatter = df_scatter.tail(last_n_scatter)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["OR Size", "ATR", "EWO", "Balance C/V", "Presi√≥n y Actividad"])

    with tab1:
        with st.expander("üìå OR Size: qu√© significa y c√≥mo usarlo"):
            st.write("OR Size = tama√±o del rango inicial (Opening Range).")
            st.write("- OR grande ‚Üí mercado m√°s 'movido'. Si tu PF cae aqu√≠, suele ser por whipsaws y entradas tard√≠as.")
            st.write("- OR peque√±o ‚Üí mercado m√°s 'apretado'. Si tu PF cae aqu√≠, suele ser por falta de recorrido.")
            st.write("Consejo: busca rangos con **PF>1**, **promedio > 0** y muestra üü¢ antes de convertirlo en filtro.")
        if "orSize" in df_known.columns and df_known["orSize"].notna().sum() > 30:
            plot_factor_bins(df_known, "orSize", q_bins, min_trades, recommended_trades, "OR Size (tama√±o del rango)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de OR Size en los logs.")

    with tab2:
        with st.expander("üìå ATR: qu√© significa y c√≥mo usarlo"):
            st.write("ATR = volatilidad (cu√°nto se mueve el precio en promedio).")
            st.write("- ATR alto ‚Üí movimientos amplios: necesitas stops/targets coherentes o te saca el ruido.")
            st.write("- ATR bajo ‚Üí poco recorrido: si tu TP es fijo, puede que no llegue.")
            st.write("Consejo: si tu estrategia tiene ATR engine, aqu√≠ ver√°s si te est√° ayudando o empeorando.")
        if "atr" in df_known.columns and df_known["atr"].notna().sum() > 30:
            plot_factor_bins(df_known, "atr", q_bins, min_trades, recommended_trades, "ATR (volatilidad)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de ATR en los logs.")

    with tab3:
        with st.expander("üìå EWO: qu√© significa y c√≥mo usarlo"):
            st.write("EWO (aqu√≠ usamos |EWO|) = fuerza de tendencia. M√°s alto suele implicar tendencia m√°s marcada.")
            st.write("- |EWO| alto ‚Üí tendencia: suele favorecer continuaciones/breakouts.")
            st.write("- |EWO| bajo ‚Üí chop/rango: suele castigar entradas por impulso.")
            st.write("Consejo: si ves PF<1 en |EWO| bajo, es un buen candidato a filtro de 'no-trade'.")
        if "ewo" in df_known.columns and df_known["ewo"].notna().sum() > 30:
            df_known2 = df_known.copy()
            df_known2["ewo_abs"] = df_known2["ewo"].abs()

            df_scatter2 = df_scatter.copy()
            df_scatter2["ewo_abs"] = df_scatter2["ewo"].abs()

            plot_factor_bins(df_known2, "ewo_abs", q_bins, min_trades, recommended_trades, "EWO (fuerza de tendencia)", show_adv_scatter, df_scatter2)
        else:
            st.info("No hay suficientes valores de EWO en los logs.")

    with tab4:
        with st.expander("üìå Balance comprador-vendedor: qu√© significa y c√≥mo usarlo"):
            st.write("Balance C/V = delta/vol (intensidad neta de compras vs ventas).")
            st.write("- Valores altos (en magnitud) ‚Üí desequilibrio fuerte (posible impulso).")
            st.write("- Cerca de 0 ‚Üí poca ventaja de flujo (m√°s f√°cil que el precio se 'devuelva').")
            st.write("Consejo: √∫salo para evitar entradas cuando no hay participaci√≥n real.")
        if "deltaRatio" in df_known.columns and df_known["deltaRatio"].notna().sum() > 30:
            plot_factor_bins(df_known, "deltaRatio", q_bins, min_trades, recommended_trades, "Balance comprador-vendedor (delta/vol)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de Balance C/V en los logs.")

    with tab5:
        st.markdown("### Qu√© es esto (en simple)")
        st.write(
            "Usamos los arrays pre-entrada (delta/volumen y OHLC de los √∫ltimos N segundos) para medir "
            "**actividad** y **presi√≥n** antes de entrar. Esto ayuda a detectar entradas 'con gasolina' "
            "vs entradas 'sin apoyo' o con **absorci√≥n**."
        )
        st.caption(
            "‚ö†Ô∏è OJO: con 40 trades esto es exploratorio. √ösalo para generar hip√≥tesis y valida con m√°s muestra."
        )

        needed_any = any(c in df_known.columns for c in ["pre_absorcion", "pre_actividad_rel", "pre_presion_por_vol", "pre_presion_sum"])
        if not needed_any:
            st.info("No veo arrays pre-entrada en tus logs (deltaLastN/volLastN/OHLC). Si est√°n, revisa que se est√©n logueando en ENTRY.")
        else:
            # Ajuste de bins m√°s conservador cuando la muestra es peque√±a
            q_small = min(q_bins, 6)

            colA, colB = st.columns(2)
            with colA:
                if "pre_absorcion" in df_known.columns and df_known["pre_absorcion"].notna().sum() > 20:
                    st.markdown("#### 1) Absorci√≥n (presi√≥n fuerte, avance peque√±o)")
                    plot_factor_bins(df_known, "pre_absorcion", q_small, min_trades, recommended_trades,
                                     "Absorci√≥n (presi√≥n fuerte + avance peque√±o)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Absorci√≥n'.")

            with colB:
                if "pre_actividad_rel" in df_known.columns and df_known["pre_actividad_rel"].notna().sum() > 20:
                    st.markdown("#### 2) Actividad (volumen relativo antes de entrar)")
                    plot_factor_bins(df_known, "pre_actividad_rel", q_small, min_trades, recommended_trades,
                                     "Actividad relativa (volumen hasta entrada vs mediana reciente)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Actividad relativa'.")

            st.markdown("#### 3) Se√±ales sin apoyo (precio avanza, presi√≥n va en contra)")
            if "pre_sin_apoyo" in df_known.columns:
                tmp = df_known.copy()
                tmp["Sin apoyo"] = np.where(tmp["pre_sin_apoyo"] == True, "S√≠", "No")
                tbl = group_metrics(tmp, "Sin apoyo", min_trades=min_trades, recommended_trades=recommended_trades)
                st.dataframe(tbl, use_container_width=True)

                # Consejos r√°pidos
                if not tbl.empty and "Grupo" in tbl.columns:
                    row_si = tbl[tbl["Grupo"] == "S√≠"]
                    row_no = tbl[tbl["Grupo"] == "No"]
                    if not row_si.empty and not row_no.empty:
                        exp_si = float(row_si.iloc[0]["Promedio por trade"])
                        exp_no = float(row_no.iloc[0]["Promedio por trade"])
                        if exp_si < exp_no:
                            st.warning("‚ö†Ô∏è Tus trades marcados como 'Sin apoyo = S√≠' rinden peor en promedio. Buen candidato para FILTRAR.")
                        else:
                            st.info("üü° Por ahora 'Sin apoyo' no empeora rendimiento, pero confirma con m√°s muestra.")
            else:
                st.info("No se detecta la bandera 'pre_sin_apoyo' (requiere arrays + dir).")

            st.markdown("### Pistas pr√°cticas (tuning)")
            st.write("‚úÖ Si **Actividad alta** + buen PF ‚Üí suele indicar entradas con participaci√≥n real.")
            st.write("üö´ Si **Absorci√≥n muy alta** + PF<1 ‚Üí suele ser 'lucha' / absorci√≥n antes del giro (candidato a evitar).")
            st.write("‚ö†Ô∏è Si 'Sin apoyo = S√≠' aparece mucho en p√©rdidas ‚Üí evita perseguir precio cuando el delta no acompa√±a.")


# ============================================================
# Hours
# ============================================================
st.subheader("‚è∞ Horarios (justo y confiable)")

hour_tbl = plot_hour_analysis(t, min_trades=min_trades)
plot_heatmap_weekday_hour(t, min_trades=min_trades)

st.markdown("### üß† Consejos autom√°ticos (Horarios)")
if hour_tbl is None or hour_tbl.empty:
    st.info("No hay datos suficientes por hora con el m√≠nimo configurado.")
else:
    best = hour_tbl.iloc[0]
    worst = hour_tbl.iloc[-1]

    st.info(
        f"üèÜ Hora recomendada: **{best['Grupo']}** | Trades={int(best['Trades'])} | "
        f"{traffic_pf(best['Profit Factor'])} | {traffic_exp(best['Promedio por trade'])}"
    )
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è La mejor hora a√∫n tiene muestra peque√±a. Confirma con m√°s logs.")

    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning(f"üö´ Hora candidata a evitar: **{worst['Grupo']}** (PF < 1 y promedio bajo).")

    st.caption("Regla de oro: prefiere horas con buen Score ponderado + buen PF + buena muestra, no solo winrate.")

# ============================================================
# ============================================================
# Entradas por d√≠a y orden del trade (tuning realista)
# ============================================================
st.subheader("üìÖ Entradas por d√≠a y orden del trade")
st.caption("Aqu√≠ miramos **cu√°ntas entradas haces por d√≠a** y si el **trade #1 / #2 / #3...** suele ser mejor o peor. "
           "Sirve para decisiones realistas como **MaxSetupsPerSession**, evitar el 'revenge trade' y cortar d√≠as malos.")

if "entry_time" in t.columns and t["entry_time"].notna().any():
    te = t.copy()
    te = te[te["entry_time"].notna()].copy()
    te = te.sort_values("entry_time").reset_index(drop=True)
    te["entry_date"] = te["entry_time"].dt.date
    te["entry_hour"] = te["entry_time"].dt.hour

    # Trades por d√≠a
    per_day = (te.groupby("entry_date", as_index=False)
                 .agg(trades=("tradeRealized","size"),
                      pnl=("tradeRealized","sum"),
                      winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    colA, colB, colC, colD = st.columns(4)
    colA.metric("Promedio trades / d√≠a", f"{per_day['trades'].mean():.2f}" if len(per_day) else "N/A")
    colB.metric("M√°ximo trades en un d√≠a", f"{int(per_day['trades'].max())}" if len(per_day) else "N/A")
    colC.metric("D√≠as con 3+ trades", f"{int((per_day['trades']>=3).sum())}" if len(per_day) else "0")
    colD.metric("D√≠as totales", f"{len(per_day)}")

    c1, c2 = st.columns([1,1])
    n_days = len(per_day)
    with c1:
        if n_days > 90:
            dist = per_day.groupby("trades", as_index=False).size().rename(columns={"size":"dias"})
            fig = px.bar(dist, x="trades", y="dias", title="Distribuci√≥n: # trades por d√≠a")
            fig.update_layout(xaxis_title="# trades en el d√≠a", yaxis_title="D√≠as")
            st.plotly_chart(fig, use_container_width=True)
            st.caption("Con muchos d√≠as, esta distribuci√≥n suele ser m√°s √∫til que una barra por fecha.")
        else:
            fig = px.bar(per_day, x="entry_date", y="trades", title="Trades por d√≠a")
            fig.update_layout(xaxis_title="D√≠a", yaxis_title="Trades")
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        fig = px.scatter(per_day, x="trades", y="pnl",
                         title="¬øM√°s trades = mejor d√≠a? (PnL d√≠a vs # trades)",
                         hover_data=["entry_date","winrate"])
        fig.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="PnL del d√≠a ($)")
        st.plotly_chart(fig, use_container_width=True)

        by_n = (per_day.groupby("trades", as_index=False)
                    .agg(dias=("entry_date","size"),
                         pnl_prom=("pnl","mean"),
                         pnl_med=("pnl","median")))
        fig2 = px.bar(by_n, x="trades", y="pnl_prom", color="pnl_prom",
                      color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                      title="Promedio PnL del d√≠a por # trades")
        fig2.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="Promedio PnL del d√≠a ($)")
        st.plotly_chart(fig2, use_container_width=True)

        try:
            mean_12 = by_n[by_n["trades"].isin([1,2])]["pnl_prom"].mean()
            mean_3p = by_n[by_n["trades"]>=3]["pnl_prom"].mean()
            n_3p_days = int(by_n[by_n["trades"]>=3]["dias"].sum()) if len(by_n[by_n["trades"]>=3]) else 0
            if pd.notna(mean_12) and pd.notna(mean_3p) and n_3p_days >= 5 and mean_3p < mean_12:
                st.warning("‚ö†Ô∏è En esta muestra, los d√≠as con **3+ trades** rinden peor en promedio. "
                           "Prueba en el Lab **M√°x trades/d√≠a = 2** o **MaxSetupsPerSession=2**.")
        except Exception:
            pass

    # Orden del trade dentro del d√≠a
    te["trade_num_day"] = te.groupby("entry_date").cumcount() + 1
    te["orden_trade"] = te["trade_num_day"].apply(lambda n: "1¬∫" if n==1 else ("2¬∫" if n==2 else ("3¬∫" if n==3 else "4¬∫+")))

    # Resumen por orden
    def _pf(sub):
        return profit_factor(sub) if len(sub) else np.nan

    by_order = (te.groupby("orden_trade", as_index=False)
                  .agg(trades=("tradeRealized","size"),
                       pnl_prom=("tradeRealized","mean"),
                       pnl_med=("tradeRealized","median"),
                       winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    # PF por orden
    pf_map = {k:_pf(v) for k,v in te.groupby("orden_trade")}
    by_order["pf"] = by_order["orden_trade"].map(pf_map)

    # Orden de presentaci√≥n
    orden_cat = ["1¬∫","2¬∫","3¬∫","4¬∫+"]
    by_order["orden_trade"] = pd.Categorical(by_order["orden_trade"], categories=orden_cat, ordered=True)
    by_order = by_order.sort_values("orden_trade")

    st.markdown("### üîé ¬øCu√°l trade del d√≠a suele ser el peor?")
    st.write("Si ves que **#3 o #4+** baja fuerte (PF<1 o promedio<0), suele ser se√±al de **sobre-trading**.")
    st.dataframe(by_order, use_container_width=True, hide_index=True)

    # Consejos r√°pidos por orden (con muestra m√≠nima)
    try:
        bo = by_order.copy()
        bo["orden_trade"] = bo["orden_trade"].astype(str)
        # Elegimos "peor" por promedio (y PF si existe)
        bo_sort = bo.sort_values(["pnl_prom"], ascending=True)
        worst_row = bo_sort.iloc[0] if len(bo_sort) else None
        if worst_row is not None and int(worst_row["trades"]) >= max(5, min_trades):
            if float(worst_row["pnl_prom"]) < 0:
                st.warning(f"‚ö†Ô∏è El **{worst_row['orden_trade']} trade** es el m√°s flojo en esta muestra "
                           f"(prom={float(worst_row['pnl_prom']):.0f}$, PF={float(worst_row['pf']):.2f}). "
                           "Candidato a **limitar setups** o a subir confirmaci√≥n despu√©s de 1‚Äì2 trades.")
        # Si 4¬∫+ existe y es negativo con algo de muestra
        row4 = bo[bo["orden_trade"]=="4¬∫+"]
        if len(row4) and int(row4.iloc[0]["trades"]) >= max(5, min_trades) and float(row4.iloc[0]["pnl_prom"]) < 0:
            st.warning("üö´ Los trades **4¬∫+** salen negativos en promedio con muestra suficiente: "
                       "muy t√≠pico de **sobre-trading**. Prueba **MaxSetupsPerSession=2** o **M√°x trades/d√≠a=2** en el Lab.")
    except Exception:
        pass

    fig = px.bar(by_order, x="orden_trade", y="pnl_prom", color="pnl_prom",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                 title="Promedio por trade seg√∫n orden en el d√≠a")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Promedio PnL por trade ($)")
    st.plotly_chart(fig, use_container_width=True)

    fig = px.bar(by_order, x="orden_trade", y="pf", color="pf",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=1.0,
                 title="Profit Factor seg√∫n orden en el d√≠a")
    fig.add_hline(y=1.0, line_dash="dash")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Profit Factor")
    st.plotly_chart(fig, use_container_width=True)

    # Heatmap: hora vs orden (promedio y conteo)
    st.markdown("### üïí Hora de entrada vs orden del trade")
    st.write("√ötil para detectar cosas tipo: **'el 2¬∫ trade despu√©s de cierta hora es malo'**.")
    tmp = te.copy()
    tmp["h"] = tmp["entry_hour"].astype("Int64")
    tmp["ord"] = tmp["orden_trade"].astype(str)
    pivot_mean = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="mean")
    pivot_n = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="size")

    # Solo mostramos si hay algo
    if pivot_mean.notna().sum().sum() > 0:
        # Formatear horas como HH:00 para que el eje sea legible (y no salga 9.5, 10.5, etc.)
        pivot_mean = pivot_mean.sort_index(axis=1)
        pivot_n = pivot_n.reindex(columns=pivot_mean.columns)

        hour_labels = [f"{int(h):02d}:00" for h in pivot_mean.columns]
        pivot_mean.columns = hour_labels
        pivot_n.columns = hour_labels

        # Texto dentro de cada celda: "promedio (n=..)"
        text = pivot_mean.copy()
        for r in text.index:
            for c in text.columns:
                a = pivot_mean.loc[r, c]
                n = pivot_n.loc[r, c]
                if pd.isna(a) or pd.isna(n) or n == 0:
                    text.loc[r, c] = ""
                else:
                    text.loc[r, c] = f"{a:.0f} (n={int(n)})"

        try:
            fig = px.imshow(
                pivot_mean,
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                aspect="auto",
            )
            fig.update_traces(
                text=text,
                texttemplate="%{text}",
                customdata=pivot_n.values,
                hovertemplate="Hora: %{x}<br>Orden: %{y}<br>Promedio: %{z:.0f}$<br>n=%{customdata}<extra></extra>",
            )
            fig.update_layout(
                title="Heatmap (promedio PnL $) ‚Äî muestra por celda",
                xaxis_title="Hora (entrada)",
                yaxis_title="Orden del trade",
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.info("Tu versi√≥n de Plotly no soporta este heatmap con texto. (No afecta el an√°lisis.)")
    else:
        st.info("No hay suficientes datos con hora de entrada para el heatmap.")
else:
    st.info("No hay entry_time en los datos (faltan logs ENTRY). Esta secci√≥n necesita ENTRY.")

# ============================================================
# üß™ Lab: Simulador de reglas diarias y filtros (tuning realista)
# ============================================================
st.subheader("üß™ Lab: Simulador de reglas diarias y filtros")
st.caption("Simula reglas reales: **MaxLoss/MaxProfit por d√≠a**, **m√°ximo trades por d√≠a**, **racha de p√©rdidas**, y filtros (OR/EWO/ATR/Absorci√≥n/Actividad). "
           "La simulaci√≥n es 'what-if': te dice c√≥mo habr√≠a cambiado tu curva con esas reglas.")
def _hour_label(h: int) -> str:
    """Etiqueta humana para una hora completa (ej: 9:00‚Äì9:59 AM)."""
    h = int(h)
    ampm = "AM" if h < 12 else "PM"
    h12 = h % 12
    if h12 == 0:
        h12 = 12
    return f"{h12}:00‚Äì{h12}:59 {ampm}"

def _finite_minmax(s: pd.Series):
    s2 = pd.to_numeric(s, errors="coerce")
    s2 = s2[np.isfinite(s2)]
    if s2.empty:
        return None, None
    return float(s2.min()), float(s2.max())



def _lab_quick_suggestions(t: pd.DataFrame, min_bucket: int = 5) -> dict:
    """Heur√≠sticas r√°pidas basadas en tu historial REAL (no simulado).
    Devuelve un dict con llaves opcionales:
      - max_intraday_loss, max_intraday_profit (en $) para que NO corte nada
      - best_hour, worst_hour (int 0..23) por promedio PnL/trade (con muestra >= min_bucket)
      - rec_max_trades (int) sugerencia de m√°ximo trades/d√≠a (si se ve deterioro)
      - rec_max_consec_losses (int) p75 de racha de p√©rdidas por d√≠a
      - dir_stats (df) resumen Long/Short
    Nunca debe lanzar excepci√≥n; si falta data, devuelve {}.
    """
    out = {}
    try:
        if t is None or t.empty:
            return out

        df = t.copy()

        # PnL por trade
        if "tradeRealized" not in df.columns:
            return out
        df["tradeRealized"] = pd.to_numeric(df["tradeRealized"], errors="coerce")

        # Timestamp por trade (ENTRY preferido; si falta, EXIT como respaldo)
        ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
        ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)
        ts = ts_entry.fillna(ts_exit)

        df["_ts"] = ts
        df = df[df["_ts"].notna() & df["tradeRealized"].notna()].copy()
        if df.empty:
            return out

        df["day"] = df["_ts"].dt.date
        df["hour"] = df["_ts"].dt.hour

        # Baseline de reglas para NO cortar nada (por pnl diario total)
        per_day = df.groupby("day", as_index=False)["tradeRealized"].sum().rename(columns={"tradeRealized": "pnl_day"})
        if not per_day.empty:
            min_day = float(per_day["pnl_day"].min())
            max_day = float(per_day["pnl_day"].max())
            out["max_intraday_loss"] = abs(min_day) if min_day < 0 else 0.0
            out["max_intraday_profit"] = max_day if max_day > 0 else 0.0

        # Mejor / peor hora por promedio (si hay muestra)
        by_h = (df.groupby("hour")["tradeRealized"]
                  .agg(["size", "mean"])
                  .rename(columns={"size": "n", "mean": "mean_pnl"}))
        by_h = by_h[by_h["n"] >= int(min_bucket)]
        if len(by_h) >= 2:
            out["best_hour"] = int(by_h["mean_pnl"].idxmax())
            out["worst_hour"] = int(by_h["mean_pnl"].idxmin())

        # ¬øSe deteriora por trade # dentro del d√≠a?
        df = df.sort_values(["day", "_ts"])
        df["trade_num_day"] = df.groupby("day").cumcount() + 1
        by_k = (df.groupby("trade_num_day")["tradeRealized"]
                  .agg(["size", "mean"])
                  .rename(columns={"size": "n", "mean": "mean_pnl"}))
        # buscamos el primer k (>=2) con media negativa y muestra suficiente
        cand = by_k[(by_k.index >= 2) & (by_k["n"] >= int(min_bucket)) & (by_k["mean_pnl"] < 0)]
        if not cand.empty:
            k = int(cand.index.min())
            out["rec_max_trades"] = max(1, k - 1)

        # Racha de p√©rdidas seguidas por d√≠a (p75 de max racha diaria)
        def _max_streak_losses(s: pd.Series) -> int:
            x = (s < 0).astype(int).values
            best = cur = 0
            for v in x:
                if v == 1:
                    cur += 1
                    best = max(best, cur)
                else:
                    cur = 0
            return int(best)

        streaks = df.groupby("day")["tradeRealized"].apply(_max_streak_losses)
        if len(streaks) > 0:
            p75 = float(np.nanpercentile(streaks.values, 75))
            out["rec_max_consec_losses"] = int(max(1, round(p75)))

        # Long / Short stats si existe dir
        if "dir" in t.columns:
            d2 = t.copy()
            d2["tradeRealized"] = pd.to_numeric(d2["tradeRealized"], errors="coerce")
            d2 = d2[d2["tradeRealized"].notna()]
            d2["side"] = d2["dir"].apply(lambda v: "Long" if str(v).strip() in ("1", "Long", "LONG") else ("Short" if str(v).strip() in ("-1", "Short", "SHORT") else "Unknown"))
            ds = d2[d2["side"].isin(["Long", "Short"])].groupby("side")["tradeRealized"].agg(["size", "mean", "median"])
            if not ds.empty:
                out["dir_stats"] = ds
    except Exception:
        return {}
    return out


def _apply_filters(df_in: pd.DataFrame):
    """
    Lab filters (opcional) aplicados ANTES de simular reglas diarias.
    Devuelve: (df_filtrado, notas:list[str])
    """
    df = df_in.copy()
    notes: list[str] = []

    # --- toggle: incluir trades con datos faltantes (NaN) ---
    include_missing = bool(st.session_state.get("lab_include_missing", True))

    # --- timestamp por fila para filtrar horas (ENTRY preferido, si no EXIT) ---
    ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
    ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)

    df["_lab_ts"] = ts_entry
    # fallback a EXIT solo para filas sin ENTRY
    df.loc[df["_lab_ts"].isna(), "_lab_ts"] = ts_exit[df["_lab_ts"].isna()]
    df["_lab_hour"] = pd.to_datetime(df["_lab_ts"], errors="coerce").dt.hour

    # horas disponibles seg√∫n dataset (si no hay nada, 0..23)
    avail_hours = sorted([int(x) for x in df["_lab_hour"].dropna().unique().tolist()])
    if len(avail_hours) == 0:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours] if "_hour_label" in globals() else [f"{h:02d}:00‚Äì{h:02d}:59" for h in avail_hours]
    label_to_hour = {lab: h for lab, h in zip(hour_labels, avail_hours)}

    # --- helper UI: slider rango basado en min/max del dataset ---
    def _range_slider_for(col: str, key: str, title: str, unit_hint: str = ""):
        if col not in df.columns:
            return None

        lo0, hi0 = (None, None)
        if "_finite_minmax" in globals():
            lo0, hi0 = _finite_minmax(df[col])

        if lo0 is None or hi0 is None:
            return None

        lo0 = float(lo0)
        hi0 = float(hi0)
        if (not np.isfinite(lo0)) or (not np.isfinite(hi0)):
            return None

        if lo0 > hi0:
            lo0, hi0 = hi0, lo0
        if lo0 == hi0:
            hi0 = lo0 + 1e-9  # avoid Streamlit edge-case

        def _norm(val):
            try:
                if isinstance(val, (list, tuple)) and len(val) == 2:
                    a = float(val[0])
                    b = float(val[1])
                else:
                    return (lo0, hi0)
                if (not np.isfinite(a)) or (not np.isfinite(b)):
                    return (lo0, hi0)
                a = max(lo0, min(hi0, a))
                b = max(lo0, min(hi0, b))
                if a > b:
                    a, b = b, a
                return (a, b)
            except Exception:
                return (lo0, hi0)

        # If a previous run stored a weird value, fix it BEFORE creating the slider.
        if key in st.session_state:
            st.session_state[key] = _norm(st.session_state.get(key))

        default = _norm(st.session_state.get(key, (lo0, hi0)))

        span = hi0 - lo0
        step = span / 50.0 if span > 0 else 1.0
        if (not np.isfinite(step)) or step <= 0:
            step = 1.0

        label = f"{title} {unit_hint}".strip()
        rng = st.slider(label, lo0, hi0, default, step=step, key=key)
        return rng

    # --- helper: aplicar rango inclusivo (con opci√≥n de incluir NaN) ---
    def _apply_range_mask(dfx: pd.DataFrame, col: str, rng):
        if col not in dfx.columns or rng is None:
            return dfx
        lo, hi = rng
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = (s >= float(lo)) & (s <= float(hi))
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- helper: threshold m√≠nimo (>=) ---
    def _apply_min_mask(dfx: pd.DataFrame, col: str, thr):
        if col not in dfx.columns or thr is None:
            return dfx
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = s >= float(thr)
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- UI ---
    with st.container():
        st.markdown("### Filtros (opcional)")
        st.caption("Estos filtros afectan **solo** la simulaci√≥n. En Reset no deber√≠an eliminar nada.")

        include_missing = st.checkbox(
            "Incluir trades con datos faltantes (NaN) en filtros (recomendado)",
            value=include_missing,
            key="lab_include_missing",
            help="Si un trade no tiene ENTRY (o alg√∫n indicador), aparecer√° como 'Sin datos'. Activado = no se excluye por defecto."
        )

        # Direcci√≥n (Compra/Venta)
        dir_col = None
        for c in ["dir", "tradeDirection", "direction"]:
            if c in df.columns:
                dir_col = c
                break

        if dir_col:
            dnum = pd.to_numeric(df[dir_col], errors="coerce")
        else:
            dnum = pd.Series(np.nan, index=df.index)

        is_long = dnum > 0
        is_short = dnum < 0
        is_unknown = dnum.isna() | (dnum == 0)

        dir_opts = ["Venta", "Compra", "No definida"]
        # Sanear defaults guardados de versiones anteriores
        _dir_raw = st.session_state.get("lab_dirs_allowed", dir_opts)
        if not isinstance(_dir_raw, (list, tuple)):
            _dir_raw = dir_opts
        _map_dir = {
            "Largos": "Compra",
            "Long": "Compra",
            "Longs": "Compra",
            "Cortos": "Venta",
            "Short": "Venta",
            "Shorts": "Venta",
            "Sin datos": "No definida",
            "Sin datos (falt√≥ ENTRY)": "No definida",
            "Sin datos (falt√≥ Entry)": "No definida",
            "Sin datos (falt√≥ entry)": "No definida",
            "No definida": "No definida",
            "Compra": "Compra",
            "Venta": "Venta",
        }
        _dir_sane = []
        for v in _dir_raw:
            v2 = _map_dir.get(str(v), None)
            if v2 in dir_opts and v2 not in _dir_sane:
                _dir_sane.append(v2)
        if not _dir_sane:
            _dir_sane = dir_opts.copy()
        st.session_state["lab_dirs_allowed"] = _dir_sane
        sel_dirs = st.multiselect("Direcci√≥n permitida", dir_opts, default=_dir_sane, key="lab_dirs_allowed")        # Horas (entry preferido)
        _h_raw = st.session_state.get("lab_hours_allowed", hour_labels)
        if not isinstance(_h_raw, (list, tuple)):
            _h_raw = hour_labels
        _h_sane = [h for h in _h_raw if h in hour_labels]
        if not _h_sane:
            _h_sane = hour_labels.copy()
        st.session_state["lab_hours_allowed"] = _h_sane
        sel_hour_labels = st.multiselect(
            "Horas permitidas (entrada)",
            options=hour_labels,
            default=_h_sane,
            key="lab_hours_allowed",
            help="Cada hora representa el bloque completo HH:00‚ÄìHH:59. Si falta ENTRY, se usa EXIT como respaldo."
        )
        sel_hours = [label_to_hour[x] for x in sel_hour_labels if x in label_to_hour]

        # Rangos (si existen columnas)
        or_rng = _range_slider_for("orSize", "lab_or_rng", "OR Size permitido", unit_hint="(seg√∫n tu log)")
        atr_rng = _range_slider_for("atr", "lab_atr_rng", "ATR permitido", unit_hint="(seg√∫n tu log)")

    # --- aplicar filtros ---
    # Direcci√≥n
    dir_mask = pd.Series(False, index=df.index)
    if "Compra" in sel_dirs:
        dir_mask |= is_long
    if "Venta" in sel_dirs:
        dir_mask |= is_short
    if "No definida" in sel_dirs:
        dir_mask |= is_unknown
    if dir_mask.any():
        df = df[dir_mask].copy()
    else:
        notes.append("‚ö†Ô∏è No seleccionaste ninguna direcci√≥n; se ignora el filtro de direcci√≥n.")

    # Horas
    if len(sel_hours) > 0 and "_lab_hour" in df.columns:
        h = pd.to_numeric(df["_lab_hour"], errors="coerce")
        hmask = h.isin(sel_hours)
        if include_missing:
            hmask = hmask | h.isna()
        df = df[hmask].copy()

    # Rangos
    df = _apply_range_mask(df, "orSize", or_rng)
    df = _apply_range_mask(df, "atr", atr_rng)

    return df, notes


def _simulate_daily_rules(df_in: pd.DataFrame,
                          max_loss: float = 0.0,
                          max_profit: float = 0.0,
                          max_trades: int = 0,
                          max_consec_losses: int = 0,
                          stop_big_loss: bool = False,
                          stop_big_win: bool = False):
    """
    Simula reglas tipo 'Daily Guard' sobre un dataframe ya filtrado.

    - max_loss: corta el d√≠a cuando el PnL acumulado <= -max_loss (0 = sin l√≠mite)
    - max_profit: corta el d√≠a cuando el PnL acumulado >= max_profit (0 = sin l√≠mite)
    - max_trades: corta el d√≠a tras N trades ejecutados (0 = sin l√≠mite)
    - max_consec_losses: corta el d√≠a tras N p√©rdidas seguidas (0 = sin l√≠mite)
    - stop_big_loss: corta el d√≠a despu√©s de un trade con RR <= -1
    - stop_big_win: corta el d√≠a despu√©s de un trade con RR >= 2

    Devuelve:
      sim_kept: trades que ‚Äúquedar√≠an‚Äù tras aplicar reglas (incluye el trade que gatilla el corte)
      stops_df: una fila por d√≠a cortado con m√©tricas b√°sicas (para explicar impacto)
    """
    if df_in is None or df_in.empty:
        return (pd.DataFrame() if df_in is None else df_in.copy()), pd.DataFrame()

    df = df_in.copy()

    # Columna de tiempo para ordenar (ENTRY preferido; fallback EXIT)
    ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
    ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)

    df["_sim_ts"] = ts_entry
    df.loc[df["_sim_ts"].isna(), "_sim_ts"] = ts_exit[df["_sim_ts"].isna()]

    # Trades sin timestamp: no se pueden agrupar por d√≠a -> se conservan tal cual
    df_valid = df[df["_sim_ts"].notna()].copy()
    df_other = df[df["_sim_ts"].isna()].copy()

    if df_valid.empty:
        sim_kept = df_other.copy()
        sim_kept.drop(columns=["_sim_ts"], errors="ignore", inplace=True)
        return sim_kept, pd.DataFrame()

    df_valid = df_valid.sort_values("_sim_ts").copy()
    df_valid["day"] = df_valid["_sim_ts"].dt.date

    # Normaliza n√∫meros
    if "tradeRealized" in df_valid.columns:
        df_valid["tradeRealized"] = pd.to_numeric(df_valid["tradeRealized"], errors="coerce").fillna(0.0).astype(float)
    else:
        df_valid["tradeRealized"] = 0.0

    rr_series = pd.to_numeric(df_valid["rr"], errors="coerce") if "rr" in df_valid.columns else pd.Series(np.nan, index=df_valid.index)

    kept_idx = []
    stop_rows = []

    max_loss = float(max_loss or 0.0)
    max_profit = float(max_profit or 0.0)
    max_trades = int(max_trades or 0)
    max_consec_losses = int(max_consec_losses or 0)

    for d, sub in df_valid.groupby("day", sort=True):
        sub = sub.sort_values("_sim_ts")
        total = int(len(sub))
        cum = 0.0
        consec = 0
        taken = 0
        cut_reason = None

        for i, (idx, row) in enumerate(sub.iterrows(), start=1):
            pnl = float(row.get("tradeRealized", 0.0) or 0.0)
            rr  = rr_series.loc[idx] if idx in rr_series.index else np.nan

            taken += 1
            cum += pnl
            if pnl < 0:
                consec += 1
            else:
                consec = 0

            kept_idx.append(idx)

            # Si ya no hay m√°s trades, no tiene sentido marcar corte
            has_more = taken < total

            if has_more and cut_reason is None:
                if max_trades > 0 and taken >= max_trades:
                    cut_reason = "M√°x trades/d√≠a"
                elif max_loss > 0 and cum <= -abs(max_loss):
                    cut_reason = "M√°x p√©rdida/d√≠a"
                elif max_profit > 0 and cum >= abs(max_profit):
                    cut_reason = "M√°x ganancia/d√≠a"
                elif max_consec_losses > 0 and consec >= max_consec_losses:
                    cut_reason = f"{max_consec_losses} p√©rdidas seguidas"
                elif bool(stop_big_loss) and np.isfinite(rr) and float(rr) <= -1.0:
                    cut_reason = "Stop‚Äëout fuerte (‚â§ -1R)"
                elif bool(stop_big_win) and np.isfinite(rr) and float(rr) >= 2.0:
                    cut_reason = "Ganador grande (‚â• 2R)"

            if cut_reason is not None:
                # Registramos el corte (el trade que gatilla el corte est√° incluido)
                stop_rows.append({
                    "fecha": d,
                    "day": d,
                    "motivo": cut_reason,
                    "trades_totales_dia": total,
                    "trades_ejecutados": taken,
                    "trades_filtrados_por_stop": int(total - taken),
                    "pnl_hasta_stop": float(cum),
                })
                break  # cortar el resto del d√≠a

    sim_kept_valid = df_valid.loc[kept_idx].copy() if kept_idx else df_valid.iloc[0:0].copy()
    sim_kept = pd.concat([sim_kept_valid, df_other], axis=0, ignore_index=False)

    # Limpieza auxiliares
    sim_kept.drop(columns=["_sim_ts"], errors="ignore", inplace=True)

    stops_df = pd.DataFrame(stop_rows)
    return sim_kept, stops_df


def _reset_lab_state(base_df: pd.DataFrame):
    """Resetea el Lab para que arranque 1:1 con el Resumen r√°pido (REAL vs SIMULADO sin cortes)."""
    if base_df is None:
        base_df = pd.DataFrame()

    # -------------------- Reglas (0 = sin l√≠mite) --------------------
    st.session_state["lab_max_loss"] = 0.0
    st.session_state["lab_max_profit"] = 0.0
    st.session_state["lab_max_trades"] = 0
    st.session_state["lab_max_consec_losses"] = 0
    st.session_state["lab_stop_big_loss"] = False
    st.session_state["lab_stop_big_win"] = False

    # -------------------- Helpers --------------------
    def _minmax(col: str, default=(0.0, 1.0)):
        if col in base_df.columns:
            mn, mx = _finite_minmax(base_df[col])
            if mn is None or mx is None:
                return default
            if mn == mx:
                # Evita sliders degenerados (mismo min/max)
                eps = 1e-9 if mn == 0 else abs(mn) * 1e-6
                return float(mn - eps), float(mx + eps)
            return float(mn), float(mx)
        return default

    def _min_abs(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            s = s.abs()
            return float(s.min())
        return default

    def _min_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.min())
        return default

    def _max_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.max())
        return default

    # -------------------- Filtros (opcionales) --------------------
        # Horas disponibles desde tu dataset (ENTRY preferido, si falta usa EXIT)
    ts_entry = pd.to_datetime(base_df["entry_time"], errors="coerce") if "entry_time" in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_exit  = pd.to_datetime(base_df["exit_time"],  errors="coerce") if "exit_time"  in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_lab   = ts_entry.fillna(ts_exit)

    if ts_lab.notna().any():
        avail_hours = sorted([int(h) for h in ts_lab.dt.hour.dropna().unique().tolist()])
    else:
        avail_hours = list(range(24))
    if not avail_hours:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours]
    st.session_state["lab_hours_allowed"] = hour_labels[:]
    st.session_state["lab_dirs_allowed"] = ["Venta", "Compra", "No definida"]
    st.session_state["lab_include_missing"] = True


    # Rangos num√©ricos -> por defecto NO filtra (rango completo / umbral m√≠nimo)
    st.session_state["lab_or_rng"] = _minmax("orSize")
    st.session_state["lab_atr_rng"] = _minmax("atr")



reset_col, reset_info = st.columns([1, 3])
with reset_col:
    if st.button("üîÑ Reset experimento", help="Resetea TODO (reglas sin l√≠mite + sin filtros) para que el Lab coincida 1:1 con el Resumen r√°pido."):
        _reset_lab_state(t)
with reset_info:
    st.caption("Idea: el Lab **empieza igual que el Resumen r√°pido**. Luego ajustas reglas/filtros para ver el impacto (what‚Äëif).")

lab_left, lab_right = st.columns([1, 1])

with lab_left:
    st.markdown("**Reglas diarias**")
    max_loss = st.number_input(
        "Max p√©rdida por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_loss", 0.0)), step=50.0,
        key="lab_max_loss",
        help="0 = sin l√≠mite. Si el d√≠a llega a -MaxLoss, se corta el trading del d√≠a."
    )
    max_profit = st.number_input(
        "Max ganancia por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_profit", 0.0)), step=100.0,
        key="lab_max_profit",
        help="0 = sin l√≠mite. Si el d√≠a llega a +MaxProfit, se corta el trading del d√≠a."
    )
    max_trades = st.slider("M√°x trades por d√≠a (0 = sin l√≠mite)", min_value=0, max_value=10,
                           value=int(st.session_state.get("lab_max_trades", 0)), key="lab_max_trades")
    max_consec_losses = st.slider("M√°x p√©rdidas seguidas (0 = sin l√≠mite)", min_value=0, max_value=10,
                                  value=int(st.session_state.get("lab_max_consec_losses", 0)), key="lab_max_consec_losses")
    stop_big_loss = st.checkbox("Cortar el d√≠a tras un stop-out fuerte (RR ‚â§ -1)", value=bool(st.session_state.get("lab_stop_big_loss", False)),
                                key="lab_stop_big_loss")
    stop_big_win = st.checkbox("Cortar el d√≠a tras un ganador grande (RR ‚â• 2)", value=bool(st.session_state.get("lab_stop_big_win", False)),
                               key="lab_stop_big_win")


    st.markdown("---")
    st.markdown("**üß≠ Sugerencias r√°pidas (seg√∫n tu historial real)**")
    sugg = _lab_quick_suggestions(t)
    if not sugg:
        st.info("No hay suficientes datos para sugerir reglas (o faltan timestamps/PnL).")
    else:
        # Valores "sin recortar" (sirven como baseline 1:1 aunque actives la regla)
        if ("max_intraday_loss" in sugg) or ("max_intraday_profit" in sugg):
            loss0 = sugg.get("max_intraday_loss", 0.0)
            prof0 = sugg.get("max_intraday_profit", 0.0)
            st.caption(f"Baseline 1:1: para que las reglas NO corten nada, usa Max p√©rdida/d√≠a ‚âà **{loss0:,.0f}** y Max ganancia/d√≠a ‚âà **{prof0:,.0f}** (o deja 0 = sin l√≠mite).")

        best_h = sugg.get("best_hour", None)
        worst_h = sugg.get("worst_hour", None)
        if best_h is not None and worst_h is not None:
            st.write(f"üïí Mejor hora promedio: **{_hour_label(best_h)}** | Peor: **{_hour_label(worst_h)}** (con muestra ‚â• {5}).")

        rec_mt = sugg.get("rec_max_trades", None)
        if rec_mt is not None and rec_mt >= 1:
            st.warning(f"üìâ A partir del trade #{rec_mt+1} el promedio suele volverse negativo. Prueba **M√°x trades/d√≠a = {rec_mt}**.", icon="‚ö†Ô∏è")
        else:
            st.write("üìå No se ve un deterioro claro por # de trade (con la muestra actual).")

        rec_streak = sugg.get("rec_max_consec_losses", None)
        if rec_streak is not None:
            rec_streak = max(1, int(rec_streak))
            st.write(f"üîÅ Racha t√≠pica (p75) de p√©rdidas seguidas por d√≠a: **{rec_streak}** ‚Üí prueba M√°x p√©rdidas seguidas = {rec_streak}.")

        if "dir_stats" in sugg and not sugg["dir_stats"].empty:
            ds = sugg["dir_stats"]
            try:
                long_mean = float(ds.loc["Long","mean"]) if "Long" in ds.index else np.nan
                short_mean = float(ds.loc["Short","mean"]) if "Short" in ds.index else np.nan
                st.write(f"üìä Long avg: **{long_mean:,.0f}** | Short avg: **{short_mean:,.0f}** (por trade).")
                if np.isfinite(long_mean) and np.isfinite(short_mean):
                    if long_mean > 0 and short_mean < 0:
                        st.warning("‚û°Ô∏è Considera filtrar **solo Long** en el Lab y ver el impacto.", icon="‚ö†Ô∏è")
                    elif short_mean > 0 and long_mean < 0:
                        st.warning("‚¨ÖÔ∏è Considera filtrar **solo Short** en el Lab y ver el impacto.", icon="‚ö†Ô∏è")
            except Exception:
                pass

        # RR-based suggestions
        if "after_stopout" in sugg:
            med, n = sugg["after_stopout"]
            if n >= 5 and np.isfinite(med) and med < 0:
                st.warning(f"üßØ Tras un stop-out fuerte (RR‚â§-1), el resto del d√≠a tiende a ser negativo (mediana {med:,.0f}, n={n}). Prueba activar esa regla.", icon="‚ö†Ô∏è")
        if "after_bigwin" in sugg:
            med, n = sugg["after_bigwin"]
            if n >= 5 and np.isfinite(med) and med < 0:
                st.warning(f"üèÜ Tras un ganador grande (RR‚â•2), suele haber devoluci√≥n (mediana resto {med:,.0f}, n={n}). Prueba activar esa regla.", icon="‚ö†Ô∏è")


with lab_right:
    st.markdown("**Filtros (opcional)**")
    base_for_lab = t.copy()  # mismo universo que el Resumen r√°pido

    # Aviso si faltan ENTRY (solo afecta a filtros que dependan de ENTRY/OR/ATR)
    missing_entry = int(base_for_lab["entry_time"].isna().sum()) if ("entry_time" in base_for_lab.columns) else 0
    if missing_entry > 0:
        st.warning(
            f"{missing_entry} operaciones no tienen ENTRY. En esas no se conoce Compra/Venta ni OR/ATR; "
            "solo se podr√°n filtrar por hora usando EXIT como respaldo.",
            icon="‚ö†Ô∏è"
        )

    filtered, filter_notes = _apply_filters(base_for_lab)

    st.write(f"Trades tras filtros: **{len(filtered)}** (de {len(base_for_lab)})")
    if filter_notes:
        st.caption("Notas de filtros: " + ", ".join(filter_notes))
    else:
        st.caption("Filtros activos: ninguno (equivale al Resumen r√°pido).")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üöÄ Turbo Presets (A): lista de presets aplicables con 1 click
# Objetivo: sugerir combinaciones simples (filtros + reglas) y permitir aplicarlas.
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
with st.expander("üöÄ Turbo Presets (A) ‚Äî aplicar con 1 click", expanded=False):
    st.caption("Se calculan presets r√°pidos y se ordenan por un puntaje balanceado (ŒîPnL + mejora DD). "
               "Cada preset ajusta filtros y/o reglas. Al aplicar, ver√°s el resultado en 'Resultados del Lab'.")

    # --- Helpers (sin widgets) ---
    def _dd_mag_from_pnl(pnl_series: pd.Series) -> float:
        try:
            s = pd.to_numeric(pnl_series, errors="coerce").fillna(0.0)
            if s.empty:
                return 0.0
            eq = s.cumsum()
            peak = eq.cummax()
            dd = eq - peak
            return float((-dd.min()) if len(dd) else 0.0)
        except Exception:
            return 0.0

    def _infer_col(df_: pd.DataFrame, candidates):
        for c in candidates:
            if c in df_.columns:
                return c
        return None

    def _lab_filter_df_params(df_: pd.DataFrame, params: dict) -> pd.DataFrame:
        d = df_.copy()

        include_missing = bool(params.get("lab_include_missing", True))

        # Direcci√≥n
        dir_col = _infer_col(d, ["dir_label", "dir", "direction", "tradeDirection"])
        allowed_dirs = params.get("lab_dirs_allowed", ["Compra", "Venta", "No definida"])
        if dir_col is not None and allowed_dirs:
            if include_missing:
                d = d[d[dir_col].isin(allowed_dirs) | d[dir_col].isna()]
            else:
                d = d[d[dir_col].isin(allowed_dirs)]

        # Horas (entrada) ‚Äî usa entry_hour si existe; si no, intenta derivar de entry_ts
        hour_col = _infer_col(d, ["entry_hour", "hour", "entryHour"])
        if hour_col is None:
            ts_col = _infer_col(d, ["entry_ts", "entryTime", "entry_time", "ts_entry"])
            if ts_col is not None:
                d["_tmp_entry_hour"] = pd.to_datetime(d[ts_col], errors="coerce").dt.hour
                hour_col = "_tmp_entry_hour"
        if hour_col is not None:
            # labels -> horas int
            sel_labels = params.get("lab_hours_allowed", None)
            if sel_labels:
                # construir mapa label->hour para horas presentes
                hours_present = sorted([int(h) for h in pd.Series(d[hour_col]).dropna().unique().tolist() if str(h).isdigit()])
                label_map = { _hour_block_label(int(h)) : int(h) for h in hours_present }
                sel_hours = [label_map.get(x) for x in sel_labels if x in label_map]
                sel_hours = [h for h in sel_hours if h is not None]
                if sel_hours:
                    if include_missing:
                        d = d[d[hour_col].isin(sel_hours) | d[hour_col].isna()]
                    else:
                        d = d[d[hour_col].isin(sel_hours)]

        # Rango OR
        or_col = _infer_col(d, ["orSize", "or_size", "or", "orPoints"])
        or_rng = params.get("lab_or_rng", None)
        if or_col is not None and or_rng and len(or_rng)==2:
            lo, hi = or_rng
            x = pd.to_numeric(d[or_col], errors="coerce")
            if include_missing:
                d = d[(x.between(lo, hi, inclusive="both")) | x.isna()]
            else:
                d = d[x.between(lo, hi, inclusive="both")]

        # Rango ATR
        atr_col = _infer_col(d, ["atr", "ATR", "atrPoints"])
        atr_rng = params.get("lab_atr_rng", None)
        if atr_col is not None and atr_rng and len(atr_rng)==2:
            lo, hi = atr_rng
            x = pd.to_numeric(d[atr_col], errors="coerce")
            if include_missing:
                d = d[(x.between(lo, hi, inclusive="both")) | x.isna()]
            else:
                d = d[x.between(lo, hi, inclusive="both")]

        # Evitar 'sin apoyo'
        if bool(params.get("lab_avoid_no_support", False)) and "support_flag" in d.columns:
            if include_missing:
                d = d[(d["support_flag"] != "Sin datos") | d["support_flag"].isna()]
            else:
                d = d[d["support_flag"] != "Sin datos"]

        # limpieza tmp
        if "_tmp_entry_hour" in d.columns:
            d.drop(columns=["_tmp_entry_hour"], inplace=True)

        return d

    def _pick_best_bin(df_: pd.DataFrame, col: str, q=4, min_n=25):
        if col not in df_.columns:
            return None
        x = pd.to_numeric(df_[col], errors="coerce")
        y = pd.to_numeric(df_.get("tradeRealized"), errors="coerce")
        ok = x.notna() & y.notna()
        if ok.sum() < max(min_n, q*min_n):
            return None
        try:
            bins = pd.qcut(x[ok], q=q, duplicates="drop")
        except Exception:
            return None
        tmp = pd.DataFrame({"bin": bins, "pnl": y[ok]})
        grp = tmp.groupby("bin")["pnl"]
        # Profit Factor aproximado por bin
        def _pf(s):
            w = s[s>0].sum()
            l = -s[s<0].sum()
            return float(w / l) if l > 0 else (float("inf") if w > 0 else np.nan)
        stats = grp.agg(n="count", mean="mean")
        stats["pf"] = grp.apply(_pf)
        stats = stats[stats["n"] >= min_n].sort_values(["pf","mean"], ascending=False)
        if stats.empty:
            return None
        best_bin = stats.index[0]
        # devuelve (lo, hi, pf, n)
        lo = float(best_bin.left)
        hi = float(best_bin.right)
        return (lo, hi, float(stats.loc[best_bin, "pf"]), int(stats.loc[best_bin, "n"]))

    def _best_hour(df_: pd.DataFrame, min_n=5):
        hour_col = _infer_col(df_, ["entry_hour", "hour", "entryHour"])
        if hour_col is None:
            return None
        y = pd.to_numeric(df_.get("tradeRealized"), errors="coerce")
        ok = y.notna() & pd.to_numeric(df_[hour_col], errors="coerce").notna()
        if ok.sum() < min_n*2:
            return None
        tmp = df_.loc[ok, [hour_col]].copy()
        tmp["pnl"] = y[ok].values
        g = tmp.groupby(hour_col)["pnl"].agg(["count","mean"])
        g = g[g["count"]>=min_n].sort_values("mean", ascending=False)
        if g.empty:
            return None
        h = int(g.index[0])
        return _hour_block_label(h)

    def _turbo_eval_preset(df_real: pd.DataFrame, params: dict) -> dict:
        # Filtrar (solo simulaci√≥n)
        filt = _lab_filter_df_params(df_real, params)
        # Simular reglas diarias
        max_loss = float(params.get("lab_max_loss", 0.0) or 0.0)
        max_profit = float(params.get("lab_max_profit", 0.0) or 0.0)
        max_trades = int(params.get("lab_max_trades", 0) or 0)
        max_consec_losses = int(params.get("lab_max_consec_losses", 0) or 0)
        stop_big_loss = bool(params.get("lab_stop_big_loss", False))
        stop_big_win  = bool(params.get("lab_stop_big_win", False))
        sim_kept, _stops = _simulate_daily_rules(filt, max_loss, max_profit, max_trades, max_consec_losses, stop_big_loss, stop_big_win)

        # M√©tricas
        pnl_real = float(pd.to_numeric(df_real.get("tradeRealized"), errors="coerce").fillna(0.0).sum()) if df_real is not None else 0.0
        pnl_sim  = float(pd.to_numeric(sim_kept.get("tradeRealized"), errors="coerce").fillna(0.0).sum()) if sim_kept is not None and not sim_kept.empty else 0.0
        dd_real  = _dd_mag_from_pnl(pd.to_numeric(df_real.get("tradeRealized"), errors="coerce").fillna(0.0)) if df_real is not None else 0.0
        dd_sim   = _dd_mag_from_pnl(pd.to_numeric(sim_kept.get("tradeRealized"), errors="coerce").fillna(0.0)) if sim_kept is not None and not sim_kept.empty else 0.0

        # PF
        pf_sim = profit_factor(sim_kept["tradeRealized"]) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else np.nan

        delta_pnl = pnl_sim - pnl_real
        mejora_dd = dd_real - dd_sim  # positivo = reduce drawdown
        score_bal = delta_pnl + mejora_dd

        return {
            "pnl_sim": pnl_sim,
            "dd_sim": dd_sim,
            "pf_sim": float(pf_sim) if (pf_sim is not None and not (isinstance(pf_sim,float) and np.isnan(pf_sim))) else np.nan,
            "trades_sim": int(len(sim_kept)) if sim_kept is not None else 0,
            "omitidos_filt": int(len(df_real) - len(filt)) if df_real is not None else 0,
            "delta_pnl": delta_pnl,
            "mejora_dd": mejora_dd,
            "score_bal": score_bal,
        }

    def _preset_summary(params: dict) -> str:
        parts=[]
        if params.get("lab_max_trades", 0):
            parts.append(f"max trades={params['lab_max_trades']}")
        if params.get("lab_max_loss", 0):
            parts.append(f"max p√©rdida/d√≠a={params['lab_max_loss']}")
        if params.get("lab_max_consec_losses", 0):
            parts.append(f"max p√©rdidas seguidas={params['lab_max_consec_losses']}")
        if params.get("lab_hours_allowed"):
            parts.append("horas=seleccionadas")
        if params.get("lab_or_rng"):
            parts.append("OR=rango")
        if params.get("lab_atr_rng"):
            parts.append("ATR=rango")
        if params.get("lab_dirs_allowed") and len(params["lab_dirs_allowed"])<3:
            parts.append("dir=filtrada")
        return " | ".join(parts) if parts else "sin cambios"

    
    # --- Turbo Optimus (presets auto) ---
    df_real = t.copy()

    st.markdown("### üöÄ Turbo Optimus (presets auto)")
    st.caption("Turbo **no aplica nada solo**. Primero calcula candidatos, te muestra una **previsualizaci√≥n** clara (PnL / DD / PF / Trades) y solo cambia el an√°lisis cuando presionas **Aplicar**.")

    # Nota UX: NO mostramos 'Base (sin filtros)'. La referencia √∫til es el **estado actual** (lo que tienes configurado ahora mismo).
    def _turbo_safe_num(s):
        return pd.to_numeric(s, errors="coerce")

    def _turbo_get_cols(df):
        pnl_col  = _infer_col(df, ["tradeRealized","realized","pnl","PnL","pnl_usd","pnl$","profit","pl"])
        hour_col = _infer_col(df, ["entry_hour","hour","Hour","trade_hour","entryHour"])
        atr_col  = _infer_col(df, ["atr","ATR","atr_points","atrPts","atr_pt"])
        or_col   = _infer_col(df, ["or_rng","or_range","OR","orPoints","or_pts","opening_range","or"])
        ts_col   = _infer_col(df, ["exit_ts","exitTs","ts","timestamp","time","ExitTime","exit_time","date"])
        return pnl_col, hour_col, atr_col, or_col, ts_col

    def _max_dd_from_pnl(df, pnl_col, ts_col):
        s = _turbo_safe_num(df[pnl_col]).fillna(0.0) if pnl_col in df.columns else pd.Series(dtype=float)
        if s.empty:
            return float("inf")
        if ts_col and ts_col in df.columns:
            try:
                dff = df[[ts_col]].copy()
                dff["_p"] = s.values
                dff[ts_col] = pd.to_datetime(dff[ts_col], errors="coerce")
                dff = dff.sort_values(ts_col)
                eq = dff["_p"].fillna(0.0).cumsum()
            except Exception:
                eq = s.cumsum()
        else:
            eq = s.cumsum()
        peak = eq.cummax()
        dd = (peak - eq).max()
        return float(dd) if dd is not None else float("inf")

    def _turbo_metrics(df, params):
        """M√©tricas usando la MISMA l√≥gica que 'Aplicar': filtros + simulaci√≥n de reglas diarias."""
        pnl_col, hour_col, atr_col, or_col, ts_col = _turbo_get_cols(df)
        if not pnl_col:
            return None

        # 1) filtros
        df_f = _lab_filter_df_params(df, params)
        if df_f is None or df_f.empty:
            return {"trades": 0, "pnl": 0.0, "dd": float("inf"), "pf": float("nan")}

        df_work = df_f.copy()
        df_work["tradeRealized"] = _turbo_safe_num(df_work[pnl_col]).fillna(0.0)

        # 2) reglas diarias (simulaci√≥n)
        max_loss = float(params.get("lab_max_loss", 0.0) or 0.0)
        max_profit = float(params.get("lab_max_profit", 0.0) or 0.0)
        max_trades = int(params.get("lab_max_trades", 0) or 0)
        max_consec_losses = int(params.get("lab_max_consec_losses", 0) or 0)
        stop_big_loss = bool(params.get("lab_stop_big_loss", False))
        stop_big_win  = bool(params.get("lab_stop_big_win", False))

        if bool(params.get("lab_use_rules", True)):
            df_sim, _ = _simulate_daily_rules(
                df_work,
                max_loss=max_loss,
                max_profit=max_profit,
                max_trades=max_trades,
                max_consec_losses=max_consec_losses,
                stop_big_loss=stop_big_loss,
                stop_big_win=stop_big_win,
            )
        else:
            df_sim = df_work

        if df_sim is None or df_sim.empty:
            return {"trades": 0, "pnl": 0.0, "dd": float("inf"), "pf": float("nan")}

        pnl = float(_turbo_safe_num(df_sim["tradeRealized"]).fillna(0.0).sum())
        dd  = _max_dd_from_pnl(df_sim, "tradeRealized", ts_col) if ts_col else _max_dd_from_pnl(df_sim, "tradeRealized", None)
        pf  = profit_factor(df_sim) if len(df_sim) else float("nan")
        return {"trades": int(len(df_sim)), "pnl": pnl, "dd": float(dd), "pf": pf}

    def _fmt_money(x):
        try:
            x = float(x)
        except Exception:
            return "‚Äî"
        sign = "+" if x > 0 else ""
        return f"{sign}{x:,.0f}"

    def _fmt_pf(x):
        try:
            x = float(x)
        except Exception:
            return "‚Äî"
        if np.isnan(x):
            return "‚Äî"
        return f"{x:.2f}"

    def _fmt_dd(x):
        if x is None:
            return "‚Äî"
        try:
            x = float(x)
        except Exception:
            return "‚Äî"
        if x == float("inf") or np.isnan(x):
            return "‚Äî"
        return f"{x:,.0f}"

    def _hours_best_sets(df, hour_col, pnl_col):
        if not hour_col or hour_col not in df.columns:
            return [("Todo el d√≠a", None)]
        h = pd.to_numeric(df[hour_col], errors="coerce")
        p = pd.to_numeric(df[pnl_col], errors="coerce").fillna(0.0)
        d = pd.DataFrame({"h": h, "p": p}).dropna(subset=["h"])
        if d.empty:
            return [("Todo el d√≠a", None)]
        g = d.groupby("h")["p"].sum().sort_values(ascending=False)
        top = [int(x) for x in g.index[:6] if pd.notna(x)]
        sets = [("Todo el d√≠a", None)]
        if len(top) >= 3:
            sets.append(("Top 3 horas", top[:3]))
        if len(top) >= 5:
            sets.append(("Top 5 horas", top[:5]))
        return sets

    def _hours_to_labels(hours_list):
        if not hours_list:
            return []
        return [f"{int(h):02d}:00" for h in hours_list]

    def _top_bins_for(df, x_col, pnl_col, top_k=2):
        if (not x_col) or (x_col not in df.columns) or (not pnl_col) or (pnl_col not in df.columns):
            return []
        x = pd.to_numeric(df[x_col], errors="coerce")
        p = pd.to_numeric(df[pnl_col], errors="coerce").fillna(0.0)
        dfb = pd.DataFrame({"x": x, "p": p}).dropna(subset=["x"])
        if dfb.empty:
            return []
        qs = dfb["x"].quantile([0.05, 0.25, 0.50, 0.75, 0.95]).values.tolist()
        qs = [float(q) for q in qs if pd.notna(q)]
        qs = sorted(set(qs))
        if len(qs) < 2:
            return []
        try:
            dfb["bin"] = pd.cut(dfb["x"], bins=qs, include_lowest=True)
        except Exception:
            return []
        g = dfb.groupby("bin")["p"].agg(["sum", "count", "mean"]).reset_index()
        g = g[g["count"] >= max(10, int(len(dfb) * 0.02))]
        if g.empty:
            return []
        g = g.sort_values(["sum", "mean"], ascending=False)
        out = []
        for _, r in g.head(int(top_k)).iterrows():
            b = r["bin"]
            if hasattr(b, "left"):
                out.append((float(b.left), float(b.right)))
        return out

    def _make_params(hours=None, or_rng=None, atr_rng=None, max_trades=0, max_loss=0, max_consec=0, dirs_allowed=None):
        # Nota clave: si NO pasamos 'lab_dirs_allowed', _lab_filter_df_params usa defaults
        # ("Compra/Venta/No definida") que suelen NO existir en datasets NT (LONG/SHORT/1/-1).
        # Resultado: Turbo filtra casi todo y "no encuentra presets".
        return {
            "lab_include_missing": True,
            "lab_dirs_allowed": list(dirs_allowed) if dirs_allowed is not None else None,
            "lab_use_hours_filter": bool(hours),
            "lab_hours_allowed": _hours_to_labels(hours) if hours else [],
            "lab_use_or_filter": bool(or_rng),
            "lab_or_rng": or_rng,
            "lab_use_atr_filter": bool(atr_rng),
            "lab_atr_rng": atr_rng,
            "lab_use_rules": True,
            "lab_max_trades": int(max_trades),
            "lab_max_loss": float(max_loss),
            "lab_max_consec_losses": int(max_consec),
        }

    def _friendly_details(params):
        if params.get("lab_use_hours_filter") and params.get("lab_hours_allowed"):
            horario = "Solo: " + ", ".join(params["lab_hours_allowed"])
        else:
            horario = "Todo el d√≠a"

        def _fmt_rng(rng):
            if not rng:
                return "sin filtro"
            try:
                a, b = float(rng[0]), float(rng[1])
                return f"{a:,.2f} ‚Äì {b:,.2f}"
            except Exception:
                return "sin filtro"

        or_txt  = _fmt_rng(params.get("lab_or_rng")) if params.get("lab_use_or_filter") else "sin filtro"
        atr_txt = _fmt_rng(params.get("lab_atr_rng")) if params.get("lab_use_atr_filter") else "sin filtro"

        mt = int(params.get("lab_max_trades", 0) or 0)
        ml = float(params.get("lab_max_loss", 0.0) or 0.0)
        mc = int(params.get("lab_max_consec_losses", 0) or 0)

        reglas = {
            "M√°x trades/d√≠a": ("sin l√≠mite" if mt == 0 else str(mt)),
            "M√°x p√©rdida/d√≠a": ("sin l√≠mite" if ml == 0 else f"{ml:,.0f}"),
            "M√°x p√©rdidas seguidas": ("sin l√≠mite" if mc == 0 else str(mc)),
        }
        filtros = {"Horario": horario, "OR": or_txt, "ATR": atr_txt}
        return filtros, reglas

    def _apply_preset(params: dict):
        st.session_state["_turbo_pending_apply"] = dict(params or {})
        st.session_state["_turbo_applied_flash"] = True
        st.rerun()

    if df_real is None or df_real.empty:
        st.info("Turbo necesita datos cargados (trades) para proponer presets.")
    else:
        pnl_col, hour_col, atr_col, or_col, ts_col = _turbo_get_cols(df_real)
        st.caption(f"Universo Turbo: **{len(df_real)}** trades (seg√∫n la carga/selecci√≥n actual).")

        # Direcci√≥n: por defecto Turbo NO debe filtrar por direcci√≥n (evita defaults Compra/Venta).
        # Si el Lab tiene un selector de direcciones, lo respetamos; si no, dejamos None.
        turbo_dirs_allowed = st.session_state.get("lab_dirs_allowed", None)

        current_params = {
            "lab_include_missing": True,
            "lab_dirs_allowed": turbo_dirs_allowed,
            "lab_use_hours_filter": st.session_state.get("lab_use_hours_filter", False),
            "lab_hours_allowed": st.session_state.get("lab_hours_allowed", []),
            "lab_use_or_filter": st.session_state.get("lab_use_or_filter", False),
            "lab_or_rng": st.session_state.get("lab_or_rng", None),
            "lab_use_atr_filter": st.session_state.get("lab_use_atr_filter", False),
            "lab_atr_rng": st.session_state.get("lab_atr_rng", None),
            "lab_use_rules": st.session_state.get("lab_use_rules", True),
            "lab_max_trades": st.session_state.get("lab_max_trades", 0),
            "lab_max_loss": st.session_state.get("lab_max_loss", 0.0),
            "lab_max_consec_losses": st.session_state.get("lab_max_consec_losses", 0),
        }
        cur_m = _turbo_metrics(df_real, current_params) or {"pnl": 0.0, "dd": float("inf"), "pf": float("nan"), "trades": 0}
        # Si cambias filtros/reglas del Lab, invalida la cach√© de Turbo (evita deltas inconsistentes)
        def _turbo_params_sig(p):
            try:
                import json as _json
                return _json.dumps(p, sort_keys=True, default=str)
            except Exception:
                return str(p)

        _cur_sig = _turbo_params_sig(current_params)
        if st.session_state.get("turbo_cur_sig") != _cur_sig:
            st.session_state["turbo_cur_sig"] = _cur_sig
            st.session_state.pop("turbo_ranked_df", None)
            st.session_state.pop("turbo_rank_label", None)
            st.session_state.pop("turbo_rank_icon", None)


        colA, colB, colC = st.columns([1.1, 1.0, 1.9])
        with colA:
            min_mode = st.selectbox(
                "M√≠n trades (anti-ruido)",
                ["Absoluto", "% del dataset"],
                index=0,
                key="turbo_min_mode",
                help="Evita recomendaciones con muy poca muestra."
            )
            if min_mode == "% del dataset":
                pct = st.slider("Porcentaje m√≠nimo", min_value=1, max_value=100, value=10, step=1, key="turbo_min_pct")
                min_trades = max(5, int(round(len(df_real) * (pct / 100.0))))
                st.caption(f"‚Üí m√≠nimo calculado: **{min_trades}** trades")
            else:
                min_trades = st.number_input("M√≠nimo absoluto", min_value=5, max_value=500, value=30, step=5, key="turbo_min_trades")
        with colB:
            top_bins = st.number_input(
                "Top rangos (OR/ATR)",
                min_value=1, max_value=5, value=2, step=1,
                key="turbo_top_bins",
                help="Cu√°ntos rangos candidatos (intervalos) intentar√° probar para OR y ATR."
            )
        with colC:
            st.markdown(
                f"**Estado actual** ‚Üí PnL: `{_fmt_money(cur_m['pnl'])}` ¬∑ DD: `{_fmt_dd(cur_m['dd'])}` ¬∑ PF: `{_fmt_pf(cur_m['pf'])}` ¬∑ Trades: `{cur_m['trades']}`"
            )

        st.markdown("#### üéØ Elige tu objetivo (solo 1):")
        st.radio(
            "",
            ["üöÄ Rocket (m√°ximo PnL)", "üõü Submarine (m√≠nimo DD)", "üéõÔ∏è Tuned (balance)"],
            horizontal=True,
            key="turbo_obj",
        )

        if st.button("üß™ Generar presets", key="turbo_generate_btn"):
            if not pnl_col:
                st.error("Turbo no encuentra una columna de PnL (tradeRealized/pnl/etc).")
            else:
                with st.spinner("Calculando presets (Turbo)..."):
                    hour_sets = _hours_best_sets(df_real, hour_col, pnl_col)

                    or_bins  = _top_bins_for(df_real, or_col, pnl_col, top_k=int(top_bins)) if or_col else []
                    atr_bins = _top_bins_for(df_real, atr_col, pnl_col, top_k=int(top_bins)) if atr_col else []

                    max_trades_opts = [0, 2, 3, 4]
                    max_loss_opts   = [0, 400, 600, 800]
                    max_consec_opts = [0, 2, 3]

                    or_opts  = [None] + or_bins
                    atr_opts = [None] + atr_bins

                    cap = 500
                    rows = []
                    for hs_name, hs in hour_sets:
                        for or_rng in or_opts:
                            for atr_rng in atr_opts:
                                for mt in max_trades_opts:
                                    for ml in max_loss_opts:
                                        for mc in max_consec_opts:
                                            params = _make_params(hours=hs, or_rng=or_rng, atr_rng=atr_rng, max_trades=mt, max_loss=ml, max_consec=mc, dirs_allowed=turbo_dirs_allowed)
                                            m = _turbo_metrics(df_real, params)
                                            if not m:
                                                continue
                                            if int(m.get("trades", 0)) < int(min_trades):
                                                continue
                                            pnl = float(m.get("pnl", 0.0))
                                            dd  = float(m.get("dd", float("inf")))
                                            pf  = float(m.get("pf", float("nan")))
                                            d_pnl = pnl - float(cur_m.get("pnl", 0.0))
                                            d_dd  = float(cur_m.get("dd", float("inf"))) - dd
                                            rows.append({
                                                "params": params,
                                                "pnl": pnl, "dd": dd, "pf": pf, "trades": int(m.get("trades", 0)),
                                                "d_pnl": d_pnl, "d_dd": d_dd,
                                            })
                                            if len(rows) >= cap:
                                                break
                                        if len(rows) >= cap:
                                            break
                                    if len(rows) >= cap:
                                        break
                                if len(rows) >= cap:
                                    break
                            if len(rows) >= cap:
                                break
                        if len(rows) >= cap:
                            break

                    if not rows:
                        st.warning("Turbo no encontr√≥ presets v√°lidos con la muestra m√≠nima. Baja 'M√≠n trades' o revisa columnas OR/ATR/hora.")
                    else:
                        df_rows = pd.DataFrame(rows)

                        # Diagn√≥stico r√°pido: si no hay bins/horas, muchos presets terminan siendo equivalentes
                        if (len(hour_sets) <= 1) and (not or_bins) and (not atr_bins):
                            st.info("Turbo no detect√≥ variaci√≥n suficiente en **horas/OR/ATR** (o no existen esas columnas). "
                                    "En este caso, Turbo solo puede variar reglas diarias y es normal ver pocos presets distintos.")

                        df_rows["_psig"] = df_rows["params"].apply(_turbo_params_sig)

                        base_pnl = float(cur_m.get("pnl", 0.0))
                        base_dd  = float(cur_m.get("dd", float("inf")))
                        df_rows["d_pnl"] = df_rows["pnl"] - base_pnl
                        df_rows["d_dd"]  = base_dd - df_rows["dd"]

                        obj = st.session_state.get("turbo_obj", "üöÄ Rocket (m√°ximo PnL)")
                        if obj.startswith("üöÄ"):
                            df_rows["_score"] = df_rows["d_pnl"]
                            df_rank = df_rows.sort_values(["_score", "pnl", "dd", "trades"], ascending=[False, False, True, False])
                            icon = "üöÄ"
                            label = "Cohete"
                        elif obj.startswith("üõü"):
                            df_rows["_score"] = df_rows["d_dd"]
                            df_rank = df_rows.sort_values(["_score", "dd", "pnl", "trades"], ascending=[False, True, False, False])
                            icon = "üõü"
                            label = "Submarino"
                        else:
                            df_rows["_score"] = df_rows.apply(lambda r: (r["pnl"] / (r["dd"] + 1.0)) if (r["dd"] not in [0.0, float("inf")] and not np.isnan(r["dd"])) else -1e18, axis=1)
                            df_rank = df_rows.sort_values(["_score", "d_pnl", "dd", "trades"], ascending=[False, False, True, False])
                            icon = "üéõÔ∏è"
                            label = "Balance"

                        # Selecci√≥n diversa: evita colapsar a 1 solo preset cuando las m√©tricas se repiten
                        picked = []
                        seen = set()
                        for _, r in df_rank.iterrows():
                            sig = r["_psig"]
                            if sig in seen:
                                continue
                            seen.add(sig)
                            picked.append(r)
                            if len(picked) >= 10:
                                break
                        df_rank = pd.DataFrame(picked).reset_index(drop=True)

                        st.session_state["turbo_ranked_df"] = df_rank
                        st.session_state["turbo_rank_label"] = label
                        st.session_state["turbo_rank_icon"] = icon

        ranked_df = st.session_state.get("turbo_ranked_df")
        if isinstance(ranked_df, pd.DataFrame) and not ranked_df.empty:
            icon = st.session_state.get("turbo_rank_icon", "üöÄ")
            label = st.session_state.get("turbo_rank_label", "Opci√≥n")

            def _rules_hint(p: dict) -> str:
                mt = int(p.get("lab_max_trades", 0) or 0)
                ml = float(p.get("lab_max_loss", 0.0) or 0.0)
                mc = int(p.get("lab_max_consec_losses", 0) or 0)
                parts = []
                if mt:
                    parts.append(f"m√°x {mt}/d√≠a")
                if ml:
                    parts.append(f"p√©rdida {ml:,.0f}/d√≠a")
                if mc:
                    parts.append(f"racha {mc}")
                return "sin l√≠mite" if not parts else ", ".join(parts)

            def _opt_label(i, row):
                pnl = float(row["pnl"]); dd = float(row["dd"]); pf = float(row["pf"]); tr = int(row["trades"])
                # Delta siempre contra el estado actual (cur_m) para evitar inconsistencias visuales
                d_pnl = pnl - float(cur_m.get("pnl", 0.0))
                d_dd  = float(cur_m.get("dd", float("inf"))) - dd

                if icon == "üöÄ":
                    delta = f"ŒîPnL {_fmt_money(d_pnl)}"
                elif icon == "üõü":
                    sign = "+" if d_dd > 0 else ""
                    delta = f"ŒîDD {sign}{d_dd:,.0f}"
                else:
                    delta = f"Score {row['_score']:.3f}"

                hint = _rules_hint(row.get("params", {}))
                return f"{icon} {label} #{i+1} ¬∑ {delta} ¬∑ PnL {_fmt_money(pnl)} ¬∑ DD {_fmt_dd(dd)} ¬∑ PF {_fmt_pf(pf)} ¬∑ Trades {tr} ¬∑ Reglas: {hint}"

            options = [ _opt_label(i, ranked_df.iloc[i]) for i in range(len(ranked_df)) ]
            sel = st.selectbox("‚úÖ Elige un preset (Turbo recomienda seg√∫n tu objetivo):", options, index=0, key="turbo_sel")

            sel_idx = options.index(sel)
            chosen = ranked_df.iloc[sel_idx].to_dict()
            params = chosen["params"]

            prev_m = {"pnl": float(chosen["pnl"]), "dd": float(chosen["dd"]), "pf": float(chosen["pf"]), "trades": int(chosen["trades"])}

            a1, a2, a3, a4 = st.columns(4)
            a1.metric("PnL (preview)", f"{_fmt_money(prev_m['pnl'])}", delta=f"{_fmt_money(prev_m['pnl']-cur_m['pnl'])}")
            a2.metric("MaxDD (preview)", f"{_fmt_dd(prev_m['dd'])}", delta=f"{(cur_m['dd']-prev_m['dd']):,.0f}" if (cur_m['dd'] not in [float('inf')] and prev_m['dd'] not in [float('inf')]) else None)
            a3.metric("Trades (preview)", f"{prev_m['trades']}", delta=f"{prev_m['trades']-cur_m['trades']}")
            a4.metric("PF (preview)", f"{_fmt_pf(prev_m['pf'])}")

            obj = st.session_state.get("turbo_obj", "üöÄ Rocket (m√°ximo PnL)")
            if obj.startswith("üöÄ"):
                st.success("üöÄ **Objetivo Cohete:** maximiza la mejora de PnL vs tu estado actual.")
            elif obj.startswith("üõü"):
                st.success("üõü **Objetivo Submarino:** reduce DD vs tu estado actual.")
            else:
                st.success("üéõÔ∏è **Objetivo Balance:** busca el mejor equilibrio PnL/DD.")

            filtros, reglas = _friendly_details(params)
            cL, cR = st.columns(2)
            with cL:
                st.markdown("**Filtros**")
                for k, v in filtros.items():
                    st.write(f"‚Ä¢ {k}: {v}")
            with cR:
                st.markdown("**Reglas diarias**")
                for k, v in reglas.items():
                    st.write(f"‚Ä¢ {k}: {v}")

            if (ranked_df["d_pnl"].abs().max() < 1e-9) and (ranked_df["d_dd"].abs().max() < 1e-9):
                st.warning("Turbo no ve diferencias entre presets. Suele pasar si OR/ATR no tienen datos √∫tiles o si el universo es muy constante.")

            if st.button("üéõÔ∏è Aplicar este preset", key="turbo_apply_btn"):
                _apply_preset(params)
    # ------------------------------------------------------------
    # Comparativa principal: REAL (universo) vs CANDIDATO (tras filtros) vs SIM (tras reglas)
    # Nota: los filtros se definen en la columna derecha (lab_right) via _apply_filters().
    # ------------------------------------------------------------
    real_df = base_for_lab.copy() if ("base_for_lab" in locals() and base_for_lab is not None) else (t.copy() if (t is not None) else pd.DataFrame())
    cand_df = filtered.copy() if ("filtered" in locals() and filtered is not None) else real_df.copy()

    if cand_df is None or cand_df.empty:
        sim_df = pd.DataFrame()
        stops_df = pd.DataFrame()
    else:
        sim_kept, stops_df = _simulate_daily_rules(
            cand_df,
            max_loss=float(max_loss or 0.0),
            max_profit=float(max_profit or 0.0),
            max_trades=int(max_trades or 0),
            max_consec_losses=int(max_consec_losses or 0),
            stop_big_loss=bool(stop_big_loss),
            stop_big_win=bool(stop_big_win),
        )
        sim_df = sim_kept

    n_real = int(len(real_df)) if real_df is not None else 0
    n_cand = int(len(cand_df)) if cand_df is not None else 0
    n_sim  = int(len(sim_df))  if sim_df  is not None else 0

    omit_filtros = max(0, n_real - n_cand)
    omit_reglas  = max(0, n_cand - n_sim)

    pnl_real = float(pd.to_numeric(real_df.get("tradeRealized"), errors="coerce").fillna(0.0).sum()) if (real_df is not None and not real_df.empty) else 0.0
    pnl_sim  = float(pd.to_numeric(sim_df.get("tradeRealized"), errors="coerce").fillna(0.0).sum())  if (sim_df  is not None and not sim_df.empty)  else 0.0

    pf_real = profit_factor(real_df) if (real_df is not None and not real_df.empty) else np.nan
    pf_sim  = profit_factor(sim_df)  if (sim_df  is not None and not sim_df.empty)  else np.nan

    st.markdown("### üìä Resultados del Lab (real vs simulado)")
    # Defaults defensivos (evita NameError si no se calculan a√∫n)
    dd_base_f = np.nan
    dd_sim_mag = np.nan

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("Trades reales", f"{n_real}")
    c2.metric("Trades simulados", f"{n_sim}", delta=f"{n_sim - n_real}")
    c3.metric("PnL real ($)", f"{pnl_real:.0f}")
    c4.metric("PnL simulado ($)", f"{pnl_sim:.0f}", delta=f"{(pnl_sim - pnl_real):.0f}")
    c5.metric("PF real / sim", f"{fmt(pf_real,2)} / {fmt(pf_sim,2)}")


    # Guard: stops_df puede no existir si la simulaci√≥n no gener√≥ tabla de d√≠as cortados
    if "stops_df" not in locals():
        stops_df = pd.DataFrame()

    d1, d2, d3 = st.columns(3)
    d1.metric("Omitidos por filtros", f"{omit_filtros}")
    d2.metric("Omitidos por reglas", f"{omit_reglas}")
    dias_cortados = int(stops_df["fecha"].nunique()) if (stops_df is not None and not stops_df.empty and "fecha" in stops_df.columns) else 0
    d3.metric("D√≠as 'cortados' (reglas)", f"{dias_cortados}")

    # Drawdown (aprox) por curva de equity
    def _equity_df(df_):
        z = df_.copy()
        z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
        z["equity"] = z["tradeRealized"].fillna(0).cumsum()
        z["equity_peak"] = z["equity"].cummax()
        z["drawdown"] = z["equity"] - z["equity_peak"]
        return z

    real_eq = _equity_df(real_df) if len(real_df) else pd.DataFrame()
    sim_eq  = _equity_df(sim_df)  if len(sim_df)  else pd.DataFrame()

    dd_real = float(real_eq["drawdown"].min()) if len(real_eq) else np.nan
    dd_sim  = float(sim_eq["drawdown"].min())  if len(sim_eq)  else np.nan

    colx, coly = st.columns(2)
    colx.metric("M√°x ca√≠da real ($)", f"{abs(dd_real):.0f}" if not np.isnan(dd_real) else "‚Äî")
    coly.metric("M√°x ca√≠da sim ($)",  f"{abs(dd_sim):.0f}"  if not np.isnan(dd_sim)  else "‚Äî",
                delta=f"{(abs(dd_real) - abs(dd_sim)):.0f}" if (not np.isnan(dd_real) and not np.isnan(dd_sim)) else None)

    st.caption("Nota: el **simulado** aplica tus filtros (selectividad) y luego reglas diarias (corte). "
               "Por eso puede tener menos trades que lo real. Para que coincida 1:1, deja filtros en 'todo' y reglas en 0.")

    # Equity curve
    st.markdown("#### Curva de equity (real vs simulado)")
    if len(real_eq) and len(sim_eq) and ("exit_time" in real_eq.columns) and ("exit_time" in sim_eq.columns):
        real_plot = real_eq[["exit_time","equity"]].rename(columns={"equity":"Equity real"})
        sim_plot  = sim_eq[["exit_time","equity"]].rename(columns={"equity":"Equity sim"})
        plot_df = pd.merge_asof(real_plot.sort_values("exit_time"),
                                sim_plot.sort_values("exit_time"),
                                on="exit_time", direction="nearest", tolerance=pd.Timedelta("1D"))
        plot_df = plot_df.sort_values("exit_time")
        fig = px.line(plot_df, x="exit_time", y=["Equity real","Equity sim"], title="Equity ($)")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No hay datos suficientes para comparar curvas de equity.")
# Impacto de las reglas (en vez de solo frecuencia)
    if stops_df is not None and not stops_df.empty:
        st.markdown("#### ¬øQu√© regla detuvo el d√≠a y qu√© impacto tuvo?")

        # Construimos, por d√≠a, la secuencia de PnL en el orden real de entrada
        _lab_base = filtered.copy()
        _time_col = "entry_time" if "entry_time" in _lab_base.columns else "exit_time"
        _lab_base = _lab_base[_lab_base[_time_col].notna()].copy()
        _lab_base = _lab_base.sort_values(_time_col)
        _lab_base["lab_day"] = _lab_base[_time_col].dt.date

        def _day_dd_mag(pnls):
            if pnls is None or len(pnls) == 0:
                return 0.0
            c = np.cumsum(pnls)
            peak = np.maximum.accumulate(c)
            dd = c - peak
            return float(abs(np.min(dd))) if len(dd) else 0.0

        day_to_pnls = {}
        for d, subd in _lab_base.groupby("lab_day"):
            pnls = subd["tradeRealized"].fillna(0).astype(float).tolist()
            day_to_pnls[d] = pnls

        enriched = stops_df.copy()

        # Enriquecemos con "qu√© PnL qued√≥ fuera" y "mejora de DD intrad√≠a" (aprox)
        pnl_total_base = []
        pnl_omitido = []
        delta_pnl = []
        dd_day_base = []
        dd_day_sim = []
        delta_dd = []
        stop_ahorra = []

        for _, r in enriched.iterrows():
            d = r["fecha"]
            taken = int(r.get("trades_ejecutados", 0) or 0)
            pnls = day_to_pnls.get(d, [])
            base_total = float(np.sum(pnls)) if pnls else 0.0
            kept_total = float(np.sum(pnls[:taken])) if pnls else 0.0
            skipped = base_total - kept_total              # lo que "se pierde" por cortar
            d_pnl = kept_total - base_total                # impacto vs base (positivo = mejora)

            dd_b = _day_dd_mag(pnls)
            dd_s = _day_dd_mag(pnls[:taken])
            d_dd = dd_b - dd_s                             # positivo = reduce ca√≠da intrad√≠a

            pnl_total_base.append(base_total)
            pnl_omitido.append(skipped)
            delta_pnl.append(d_pnl)
            dd_day_base.append(dd_b)
            dd_day_sim.append(dd_s)
            delta_dd.append(d_dd)
            stop_ahorra.append(skipped < 0)                # si lo omitido era negativo, el corte evit√≥ p√©rdidas

        enriched["pnl_total_dia_base"] = pnl_total_base
        enriched["pnl_omitido_por_corte"] = pnl_omitido
        enriched["delta_pnl_vs_base"] = delta_pnl
        enriched["dd_dia_base"] = dd_day_base
        enriched["dd_dia_sim"] = dd_day_sim
        enriched["mejora_dd_dia"] = delta_dd
        enriched["evito_perdidas"] = stop_ahorra

        # Resumen por motivo (lo realmente √∫til)
        impact = (
            enriched.groupby("motivo", as_index=False)
            .agg(
                dias=("fecha", "count"),
                trades_omitidos=("trades_filtrados_por_stop", "sum"),
                delta_pnl_total=("delta_pnl_vs_base", "sum"),
                delta_pnl_prom=("delta_pnl_vs_base", "mean"),
                mejora_dd_total=("mejora_dd_dia", "sum"),
                mejora_dd_prom=("mejora_dd_dia", "mean"),
                pct_evito_perdidas=("evito_perdidas", "mean"),
            )
        )
        impact["pct_evito_perdidas"] = (impact["pct_evito_perdidas"] * 100).round(0)

        # Gr√°ficos de impacto (PnL y DD) ‚Äî mucho m√°s interpretables que "frecuencia"
        leftg, rightg = st.columns(2)

        with leftg:
            st.markdown("**Impacto en PnL al cortar el d√≠a**")
            figp = px.bar(
                impact.sort_values("delta_pnl_total"),
                x="motivo",
                y="delta_pnl_total",
                color="delta_pnl_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("delta_pnl_total")["delta_pnl_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="ŒîPnL total vs base ($) ‚Äî positivo = mejora",
            )
            figp.update_layout(xaxis_title="Regla", yaxis_title="ŒîPnL ($)")
            st.plotly_chart(figp, use_container_width=True)

        with rightg:
            st.markdown("**Impacto en Drawdown intrad√≠a (aprox.)**")
            figd = px.bar(
                impact.sort_values("mejora_dd_total"),
                x="motivo",
                y="mejora_dd_total",
                color="mejora_dd_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("mejora_dd_total")["mejora_dd_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="Mejora DD total ($) ‚Äî positivo = reduce ca√≠das",
            )
            figd.update_layout(xaxis_title="Regla", yaxis_title="Mejora DD ($)")
            
            st.plotly_chart(figd, use_container_width=True)

        # Relaci√≥n entre reglas: trade-off PnL vs reducci√≥n de drawdown (visi√≥n de cuadrantes)
        if len(impact) >= 1:
            impact_sc = impact.copy()
            def _quad(row):
                dp = float(row.get("delta_pnl_total", 0) or 0)
                dd = float(row.get("mejora_dd_total", 0) or 0)
                if dp >= 0 and dd >= 0:
                    return "Mejora PnL y reduce DD"
                if dp < 0 and dd >= 0:
                    return "Reduce DD pero cuesta PnL"
                if dp >= 0 and dd < 0:
                    return "Mejora PnL pero empeora DD"
                return "Empeora ambos"
            impact_sc["cuadrante"] = impact_sc.apply(_quad, axis=1)

            st.markdown("**Mapa PnL vs Drawdown por regla (trade‚Äëoff)**")
            figs = px.scatter(
                impact_sc,
                x="delta_pnl_total",
                y="mejora_dd_total",
                size="dias" if "dias" in impact_sc.columns else None,
                color="cuadrante",
                hover_name="motivo",
                hover_data={
                    "dias": True,
                    "trades_omitidos": True,
                    "pct_evito_perdidas": True,
                    "delta_pnl_total": ":.0f",
                    "mejora_dd_total": ":.0f",
                },
                labels={
                    "delta_pnl_total": "ŒîPnL vs base ($)",
                    "mejora_dd_total": "Mejora DD total ($)",
                    "dias": "D√≠as activada",
                },
                title="Cada punto = una regla. Derecha/arriba = mejor. Tama√±o = d√≠as activada.",
            )
            figs.add_vline(x=0, line_dash="dash", opacity=0.4)
            figs.add_hline(y=0, line_dash="dash", opacity=0.4)
            figs.update_layout(xaxis_title="ŒîPnL ($)  (positivo = mejora)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figs, use_container_width=True)

            if len(impact_sc) >= 3:
                try:
                    r = float(np.corrcoef(impact_sc["delta_pnl_total"], impact_sc["mejora_dd_total"])[0,1])
                    st.caption(f"Correlaci√≥n entre ŒîPnL y Mejora DD (entre reglas): r = {r:.2f}. "
                               "Con pocas reglas, √∫salo solo como referencia visual.")
                except Exception:
                    pass

        st.caption(

            "Interpretaci√≥n: **ŒîPnL** positivo significa que cortar evit√≥ m√°s p√©rdidas de las que dej√≥ pasar. "
            "**Mejora DD** positiva significa menor ca√≠da intrad√≠a en los d√≠as donde se activ√≥ esa regla. "
            "Esto es una aproximaci√≥n por d√≠a (no reemplaza el DD global)."
        )

        # Tabla detallada (para quien quiera auditar)
        
        # ------------------------------------------------------------
        # Extra: "What-if" por regla (una regla a la vez)
        # Esto evita confusi√≥n cuando varias reglas est√°n activas a la vez.
        # ------------------------------------------------------------
        st.markdown("#### üß© What‚Äëif por regla (una regla a la vez)")
        st.caption("Aqu√≠ se simula **cada regla por separado** (manteniendo los filtros) y se compara contra los **candidatos tras filtros**. "
                   "Sirve para ver el **trade‚Äëoff PnL vs Drawdown** sin mezclar reglas.")

        def _dd_mag_from_df(df_):
            if df_ is None or df_.empty:
                return 0.0
            z = df_.copy()
            z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
            eq = z["tradeRealized"].fillna(0).astype(float).cumsum()
            peak = eq.cummax()
            dd = eq - peak
            return float(abs(dd.min())) if len(dd) else 0.0

        pnl_base_f = float(filtered["tradeRealized"].fillna(0).astype(float).sum()) if (filtered is not None and not filtered.empty) else 0.0
        dd_base_f  = _dd_mag_from_df(filtered)
        pf_base_f  = profit_factor(filtered) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else np.nan

        # Construye escenarios individuales en funci√≥n de lo que el usuario activ√≥
        scenarios = []
        if max_loss > 0:
            scenarios.append(("Max p√©rdida/d√≠a", dict(max_loss=max_loss, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_profit > 0:
            scenarios.append(("Max ganancia/d√≠a", dict(max_loss=0.0, max_profit=max_profit, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_trades > 0:
            scenarios.append(("M√°x trades/d√≠a", dict(max_loss=0.0, max_profit=0.0, max_trades=max_trades, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_consec_losses > 0:
            scenarios.append((f"{max_consec_losses} p√©rdidas seguidas", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=max_consec_losses, stop_big_loss=False, stop_big_win=False)))
        if stop_big_loss:
            scenarios.append(("Stop‚Äëout fuerte (‚â§ -1R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=True, stop_big_win=False)))
        if stop_big_win:
            scenarios.append(("Cierre tras ganador grande (‚â• 2R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=True)))

        rows = []
        for name, params in scenarios:
            sim_one, stops_one = _simulate_daily_rules(filtered, **params)
            pnl_sim_one = float(sim_one["tradeRealized"].fillna(0).astype(float).sum()) if (sim_one is not None and not sim_one.empty) else 0.0
            dd_sim_one  = _dd_mag_from_df(sim_one)
            pf_sim_one  = profit_factor(sim_one) if (sim_one is not None and not sim_one.empty and "tradeRealized" in sim_one.columns) else np.nan

            rows.append({
                "regla": name,
                "trades_sim": int(len(sim_one)) if sim_one is not None else 0,
                "dias_cortados": int(len(stops_one)) if stops_one is not None else 0,
                "delta_pnl": pnl_sim_one - pnl_base_f,
                "mejora_dd": dd_base_f - dd_sim_one,
                "pf_sim": pf_sim_one,
            })

        # Punto "Combinado" (todas las reglas activas) si hay m√°s de 1 regla
        if len(scenarios) >= 2:
            pnl_base_comb = float(filtered["tradeRealized"].sum()) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else 0.0
            pnl_sim_comb  = float(sim_kept["tradeRealized"].sum()) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else 0.0
            dd_sim_mag = _dd_mag_from_df(sim_kept) if (sim_kept is not None and not sim_kept.empty) else 0.0
            cut_days_total = int(stops_df["day"].nunique()) if (stops_df is not None and not stops_df.empty and "day" in stops_df.columns) else 0
            rows.append({
                "regla": "Combinado (todas)",
                "trades_sim": int(len(sim_kept)) if sim_kept is not None else 0,
                "dias_cortados": cut_days_total,
                "delta_pnl": pnl_sim_comb - pnl_base_comb,
                "mejora_dd": dd_base_f - dd_sim_mag,
                "pf_sim": profit_factor(sim_kept) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else np.nan,
            })


        if rows:
            wf = pd.DataFrame(rows)
            def _quad2(r):
                dp = float(r["delta_pnl"])
                ddm = float(r["mejora_dd"])
                if dp >= 0 and ddm >= 0: return "‚úÖ Mejora PnL y DD"
                if dp < 0 and ddm >= 0:  return "üü° Reduce DD pero cuesta PnL"
                if dp >= 0 and ddm < 0:  return "üü† Mejora PnL pero empeora DD"
                return "‚ùå Empeora ambos"
            wf["cuadrante"] = wf.apply(_quad2, axis=1)

            # Gr√°fico trade-off (m√°s estable con muchas reglas)
            figwf = px.scatter(
                wf,
                x="delta_pnl",
                y="mejora_dd",
                size="dias_cortados",
                color="cuadrante",
                hover_name="regla",
                hover_data={"trades_sim": True, "dias_cortados": True, "pf_sim": True},
                title="Mapa (what‚Äëif) por regla ‚Äî ŒîPnL vs mejora DD (cada regla por separado)",
            )
            figwf.add_vline(x=0, line_dash="dash", opacity=0.4)
            figwf.add_hline(y=0, line_dash="dash", opacity=0.4)

            # Asegura que el 0 siempre sea visible (evita ejes ‚Äúpegados‚Äù a un lado)
            try:
                xmin = float(wf["delta_pnl"].min()); xmax = float(wf["delta_pnl"].max())
                ymin = float(wf["mejora_dd"].min()); ymax = float(wf["mejora_dd"].max())
                padx = max(100.0, (xmax - xmin) * 0.15)
                pady = max(100.0, (ymax - ymin) * 0.15)
                figwf.update_xaxes(range=[min(xmin, 0.0) - padx, max(xmax, 0.0) + padx])
                figwf.update_yaxes(range=[min(ymin, 0.0) - pady, max(ymax, 0.0) + pady])
            except Exception:
                pass

            figwf.update_layout(xaxis_title="ŒîPnL vs base ($)  (positivo = mejor)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figwf, use_container_width=True)

            with st.expander("Ver tabla (what‚Äëif por regla)"):
                wf2 = wf.sort_values(["cuadrante","mejora_dd","delta_pnl"], ascending=[True, False, False]).copy()
                wf2["delta_pnl"] = wf2["delta_pnl"].round(0).astype(int)
                wf2["mejora_dd"] = wf2["mejora_dd"].round(0).astype(int)
                st.dataframe(wf2[["regla","delta_pnl","mejora_dd","dias_cortados","trades_sim","pf_sim","cuadrante"]], use_container_width=True, hide_index=True)

            # Consejo r√°pido autom√°tico
            best = wf[wf["regla"] != "Combinado (todas)"].copy()
            if not best.empty and (best["dias_cortados"].sum() > 0):
                cand = best.sort_values(["mejora_dd","delta_pnl"], ascending=False).iloc[0]
                st.success(f"‚úÖ Regla con mejor equilibrio (en esta muestra): **{cand['regla']}** "
                           f"(ŒîPnL {cand['delta_pnl']:.0f}$, mejora DD {cand['mejora_dd']:.0f}$). "
                           "Ojo: valida con m√°s trades y no optimices 5 cosas a la vez.")
        else:
            st.info("Activa al menos una regla diaria para ver el 'what‚Äëif por regla'.")

        with st.expander("Ver detalle por d√≠a (qu√© se omiti√≥ al cortar)"):
            show_cols = [
                "fecha", "motivo",
                "trades_ejecutados", "trades_totales_dia", "trades_filtrados_por_stop",
                "pnl_total_dia_base", "pnl_hasta_stop", "pnl_omitido_por_corte", "delta_pnl_vs_base",
                "dd_dia_base", "dd_dia_sim", "mejora_dd_dia",
            ]
            cols_present = [c for c in show_cols if c in enriched.columns]
            cols_missing = [c for c in show_cols if c not in enriched.columns]
            if cols_missing:
                st.caption('Columnas no disponibles en este dataset: ' + ', '.join(cols_missing))
            st.dataframe(
                enriched[cols_present].sort_values(['fecha']) if cols_present else enriched.sort_values(['fecha']),
                use_container_width=True,
                hide_index=True,
            )
    else:
        st.info("Con estas reglas, no se activ√≥ ning√∫n 'corte del d√≠a'.")
    # Consejos autom√°ticos del Lab
    st.markdown("### üí° Consejos autom√°ticos (Lab)")
    if len(filtered) < 30:
        st.warning("Muestra peque√±a tras filtros: toma estas conclusiones como hip√≥tesis, no como regla.")
    if len(sim_kept) < max(10, int(0.25*len(filtered))):
        st.warning("La simulaci√≥n est√° eliminando demasiados trades. Revisa si est√°s filtrando/cortando en exceso.")

    # OJO: dd_base/dd_sim son negativos (ca√≠da desde el pico). Para comparar "mejor/peor" usamos magnitudes.
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.success("‚úÖ Menor drawdown con reglas: buen candidato para un 'Daily Guard' realista.")
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.warning("‚ö†Ô∏è El drawdown empeor√≥ en la simulaci√≥n: estas reglas podr√≠an estar cortando recuperaci√≥n o dejando p√©rdidas grandes.")

    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim > pf_real + 0.2 and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.info("Mejor√≥ PF pero empeor√≥ DD: t√≠pico cuando eliminas muchos trades peque√±os pero te quedas con p√©rdidas grandes. Revisa filtros/horarios.")
    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim < pf_real and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.info("Baj√≥ PF pero tambi√©n baj√≥ el DD: a veces vale la pena si tu objetivo es estabilidad (menos estr√©s / menos reset).")
# Resumen final (muy user-friendly)
# ============================================================
st.subheader("üßæ Resumen final y recomendaciones")

st.write(
    "Este bloque resume lo m√°s accionable. No es una verdad absoluta: con muestra peque√±a, √∫salo para orientar, no para 'sobre-optimizar'."
)

# 1) Salud general
pf_val = summary.get("pf", np.nan)
exp_val = summary.get("expectancy", np.nan)
if pf_val == pf_val and pf_val < 1.0:
    st.error("üö® Salud general: Profit Factor < 1 (pierde). Prioridad: filtrar condiciones malas antes de ajustar targets.")
elif exp_val == exp_val and exp_val < 0:
    st.warning("‚ö†Ô∏è Salud general: promedio por trade < 0. Revisa filtros (horario/volatilidad/tendencia) y disciplina de salida.")
else:
    st.success("‚úÖ Salud general: no se ve rojo inmediato (seg√∫n esta muestra). Ahora toca mejorar consistencia.")

# 2) RR y estructura
if "rr" in t.columns and t["rr"].notna().any():
    _rr = t[t["rr"].notna()]["rr"].astype(float)
    rr_median = float(_rr.median())
    rr_mean = float(_rr.mean())
    rr_ge2 = float((_rr >= 2).mean() * 100)
    rr_le_1 = float((_rr <= -1).mean() * 100)

    st.markdown("**Estructura RR**")
    st.write(f"- RR mediana: {rr_median:.2f} | RR promedio: {rr_mean:.2f} | %RR‚â•2: {rr_ge2:.1f}% | %RR‚â§-1: {rr_le_1:.1f}%")
    if rr_mean > 0 and rr_median < 0:
        st.info("Promedio > 0 y mediana < 0: dependes de pocos ganadores grandes. Enf√≥cate en reducir stop-outs feos sin matar tus runners.")
    if rr_le_1 > 15:
        st.warning("‚ö†Ô∏è %RR‚â§-1 alto: est√°s tomando muchas p√©rdidas completas. Buen objetivo: mejorar confirmaci√≥n/evitar chop/horas malas.")

# 3) Manejo de ganadores (captura/devoluci√≥n)
if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
    cap_med = float(t["captura_pct"].dropna().median())
    gb_med = float(t["devolucion_pct"].dropna().median()) if "devolucion_pct" in t.columns and t["devolucion_pct"].notna().any() else np.nan
    st.markdown("**Manejo de ganadores**")
    st.write(f"- Captura mediana: {cap_med*100:.0f}%" + (f" | Devoluci√≥n mediana: {gb_med*100:.0f}%" if gb_med == gb_med else ""))
    if cap_med < 0.35:
        st.warning("‚ö†Ô∏è Captura baja: est√°s dejando mucho en la mesa. Ajusta trailing/TP parcial o reglas de salida temprana.")
    if gb_med == gb_med and gb_med > 0.60:
        st.warning("‚ö†Ô∏è Devoluci√≥n alta: el trade va bien, pero no proteges a tiempo. Prueba trailing m√°s agresivo cuando ya est√©s en +1R.")

# 4) Motivos de salida (top problema)
if "exitReason" in t.columns and t["exitReason"].notna().any():
    _tbl = group_metrics(t, "exitReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
    if not _tbl.empty:
        worst = _tbl.sort_values("Promedio por trade").iloc[0]
        if float(worst["Promedio por trade"]) < 0:
            st.markdown("**Motivo de salida a vigilar**")
            st.write(f"- {worst['Grupo']}: promedio {float(worst['Promedio por trade']):.1f} con {int(worst['Trades'])} trades")

# 5) Horarios (si hay)
if hour_tbl is not None and not hour_tbl.empty:
    best = hour_tbl.iloc[0]
    st.markdown("**Horario con mejor Score (ponderado)**")
    st.write(f"- {best['Grupo']} | Trades={int(best['Trades'])} | PF={float(best['Profit Factor']):.2f} | Promedio={float(best['Promedio por trade']):.1f}")
    if int(best["Trades"]) < min_trades * 2:
        st.info("Nota: el mejor horario a√∫n tiene poca muestra. Confirma con m√°s meses antes de convertirlo en regla.")

recommend_settings_block(known, min_trades=min_trades, recommended_trades=recommended_trades)

st.markdown("**Siguientes pasos recomendados (orden)**")
st.write("1) Primero elimina lo rojo: horarios peores + condiciones con PF<1 (muestra üü¢).")
st.write("2) Luego ajusta manejo: reduce devoluciones grandes y evita stop-outs completos recurrentes.")
st.write("3) Al final optimiza targets/trailing: no mates los winners grandes si tu edge depende de ellos.")

# ============================================================
# Trades table
# ============================================================
with st.expander("üìÑ Tabla de trades (una fila por atmId)", expanded=False):
    cols_show = [c for c in [
        "exit_time", "entry_time", "lado", "outcome", "tradeRealized",
        "maxUnreal", "minUnreal", "exitReason", "forcedCloseReason",
        "orSize", "ewo", "atr", "deltaRatio", "atrSlMult", "tp1R", "tp2R",
        "duration_sec"
    ] if c in t.columns]
    st.dataframe(t[cols_show].sort_values("exit_time", ascending=False), use_container_width=True)

st.caption(
    "Tip: para eliminar ‚ÄúSin datos (falt√≥ ENTRY)‚Äù, aseg√∫rate de cargar meses que contengan los ENTRY y EXIT juntos. "
    "Si quieres 100% robustez, a√±ade `dir` tambi√©n en el EXIT (en NinjaScript) o guarda logs en bloques por trade."
)
