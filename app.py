import streamlit as st
import pandas as pd
import numpy as np
import json
import plotly.express as px

st.set_page_config(page_title="WIC_WLF2 Analizador", layout="wide")

def _best_group_for_categorical(df: pd.DataFrame, col: str, min_trades: int):
    if col not in df.columns:
        return None
    rows = []
    for g, sub in df.groupby(col):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        rows.append((g, n, exp, pf, score))
    if not rows:
        return None
    rows.sort(key=lambda x: (x[4], x[1]), reverse=True)
    g, n, exp, pf, score = rows[0]
    return {"grupo": g, "n": n, "exp": exp, "pf": pf, "score": score}


def _best_range_for_numeric(df: pd.DataFrame, col: str, q: int, min_trades: int):
    if col not in df.columns:
        return None
    s = pd.to_numeric(df[col], errors="coerce")
    if s.notna().sum() < max(15, min_trades * 2):
        return None
    try:
        cuts = pd.qcut(s, q=q, duplicates="drop")
    except Exception:
        return None

    tmp = df.copy()
    tmp["_r"] = cuts.astype(str)

    best = None
    for g, sub in tmp.groupby("_r"):
        n = int(len(sub))
        if n < min_trades:
            continue
        exp = float(sub["tradeRealized"].mean())
        pf = profit_factor(sub)
        score = exp * np.log1p(n)
        cand = {"rango": str(g), "n": n, "exp": exp, "pf": pf, "score": score}
        if (best is None) or (cand["score"] > best["score"]):
            best = cand
    if best is None:
        return None

    # Intentar extraer l√≠mites num√©ricos del rango "(a, b]"
    lo = hi = None
    rg = best["rango"].strip()
    if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
        inner = rg[1:-1]
        parts = inner.split(",")
        if len(parts) == 2:
            try:
                lo = float(parts[0])
                hi = float(parts[1])
            except Exception:
                lo = hi = None
    best["lo"] = lo
    best["hi"] = hi
    return best


def recommend_settings_block(known_df: pd.DataFrame, min_trades: int, recommended_trades: int):
    """
    Resume recomendaciones 'tipo NinjaTrader' basadas en lo que rinde mejor en ESTA muestra.
    No inventa campos: solo usa lo que existe en el JSON.
    """
    if known_df is None or known_df.empty:
        st.info("No hay suficientes trades con ENTRY para sugerir ajustes.")
        return

    n_total = int(len(known_df))
    st.subheader("üéØ Ajustes sugeridos (seg√∫n esta muestra)")
    st.caption("Esto NO es una optimizaci√≥n cient√≠fica; es una gu√≠a r√°pida. Con poca muestra, √∫salo como hip√≥tesis.")

    if n_total < recommended_trades:
        st.warning(f"Muestra peque√±a: {n_total} trades con ENTRY. Recomendado ‚â• {recommended_trades} para decisiones fuertes.")

    # 1) Entry: StopMarket vs Limit
    if "orderType" in known_df.columns:
        tmp = known_df.copy()
        ot = tmp["orderType"].astype(str).str.lower()
        tmp["EntryType"] = np.where(ot.str.contains("stop"), "StopMarket", np.where(ot.str.contains("limit"), "Limit", tmp["orderType"].astype(str)))
        best_entry = _best_group_for_categorical(tmp, "EntryType", min_trades=min_trades)
    else:
        best_entry = None

    # 2) UseAtrEngine (bool)
    best_atr_mode = _best_group_for_categorical(known_df, "useAtrEngine", min_trades=min_trades)

    # 3) Rangos num√©ricos clave (si existen)
    q_small = 3  # con 40 trades: rangos pocos, m√°s estables
    best_or = _best_range_for_numeric(known_df, "orSize", q=q_small, min_trades=min_trades)
    best_ewo = None
    if "ewo" in known_df.columns:
        tmp = known_df.copy()
        tmp["ewoAbs"] = pd.to_numeric(tmp["ewo"], errors="coerce").abs()
        best_ewo = _best_range_for_numeric(tmp, "ewoAbs", q=q_small, min_trades=min_trades)

    best_atr = _best_range_for_numeric(known_df, "atr", q=q_small, min_trades=min_trades)
    best_atr_sl = _best_range_for_numeric(known_df, "atrSlMult", q=q_small, min_trades=min_trades)
    best_tp1 = _best_range_for_numeric(known_df, "tp1R", q=q_small, min_trades=min_trades)
    best_tp2 = _best_range_for_numeric(known_df, "tp2R", q=q_small, min_trades=min_trades)
    best_ts = _best_range_for_numeric(known_df, "tsBehindTP1Atr", q=q_small, min_trades=min_trades)
    best_step = _best_range_for_numeric(known_df, "trailStepTicks", q=q_small, min_trades=min_trades)

    # 4) Render: salida tipo "par√°metro -> sugerencia"
    lines = []

    def add_line(name, suggestion, note=None):
        s = f"- **{name}**: {suggestion}"
        if note:
            s += f"  \n  {note}"
        lines.append(s)

    if best_entry:
        use_stop = "True" if str(best_entry["grupo"]).lower() == "stopmarket" else "False"
        add_line("UseStopMarketEntry", use_stop, f"(mejor grupo: {best_entry['grupo']} | n={best_entry['n']} | PF={best_entry['pf']:.2f} | prom={best_entry['exp']:.0f})")

    if best_atr_mode:
        add_line("UseAtrEngine", str(best_atr_mode["grupo"]), f"(n={best_atr_mode['n']} | PF={best_atr_mode['pf']:.2f} | prom={best_atr_mode['exp']:.0f})")

    if best_or and best_or.get("lo") is not None and best_or.get("hi") is not None:
        add_line("MinORSize / MaxORSize", f"{best_or['lo']:.2f}  ‚Üí  {best_or['hi']:.2f}",
                 f"(mejor rango ORSize | n={best_or['n']} | PF={best_or['pf']:.2f} | prom={best_or['exp']:.0f})")

    if best_ewo and best_ewo.get("lo") is not None:
        add_line("MinEWOMagnitude", f"‚âà {best_ewo['lo']:.3f} (o mayor)",
                 f"(basado en |EWO| | n={best_ewo['n']} | PF={best_ewo['pf']:.2f} | prom={best_ewo['exp']:.0f})")

    if best_atr_sl and best_atr_sl.get("lo") is not None and best_atr_sl.get("hi") is not None:
        mid = (best_atr_sl["lo"] + best_atr_sl["hi"]) / 2
        add_line("AtrSlMult", f"‚âà {mid:.2f} (rango {best_atr_sl['lo']:.2f}‚Äì{best_atr_sl['hi']:.2f})",
                 f"(n={best_atr_sl['n']} | PF={best_atr_sl['pf']:.2f} | prom={best_atr_sl['exp']:.0f})")

    if best_tp1 and best_tp1.get("lo") is not None and best_tp1.get("hi") is not None:
        mid = (best_tp1["lo"] + best_tp1["hi"]) / 2
        add_line("TP1_RMult", f"‚âà {mid:.2f} (rango {best_tp1['lo']:.2f}‚Äì{best_tp1['hi']:.2f})",
                 f"(n={best_tp1['n']} | PF={best_tp1['pf']:.2f} | prom={best_tp1['exp']:.0f})")

    if best_tp2 and best_tp2.get("lo") is not None and best_tp2.get("hi") is not None:
        mid = (best_tp2["lo"] + best_tp2["hi"]) / 2
        add_line("TP2_RMult", f"‚âà {mid:.2f} (rango {best_tp2['lo']:.2f}‚Äì{best_tp2['hi']:.2f})",
                 f"(n={best_tp2['n']} | PF={best_tp2['pf']:.2f} | prom={best_tp2['exp']:.0f})")

    if best_ts and best_ts.get("lo") is not None and best_ts.get("hi") is not None:
        mid = (best_ts["lo"] + best_ts["hi"]) / 2
        add_line("TSBehindTP1_ATR", f"‚âà {mid:.2f} (rango {best_ts['lo']:.2f}‚Äì{best_ts['hi']:.2f})",
                 f"(n={best_ts['n']} | PF={best_ts['pf']:.2f} | prom={best_ts['exp']:.0f})")

    if best_step and best_step.get("lo") is not None and best_step.get("hi") is not None:
        # ticks: mejor entero
        mid = int(round((best_step["lo"] + best_step["hi"]) / 2))
        add_line("TrailStepTicks", f"‚âà {mid} (rango {best_step['lo']:.0f}‚Äì{best_step['hi']:.0f})",
                 f"(n={best_step['n']} | PF={best_step['pf']:.2f} | prom={best_step['exp']:.0f})")

    if not lines:
        st.info("No hay suficientes campos/muestra para sugerir ajustes autom√°ticos.")
    else:
        st.markdown("\n".join(lines))

    st.caption("‚ö†Ô∏è Consejo: aplica 1 cambio a la vez y vuelve a medir. Evita optimizar 5 par√°metros con 40 trades.")


# ============================================================
# (Opcional) Password: define APP_PASSWORD en Streamlit Secrets
# ============================================================
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
if APP_PASSWORD:
    st.sidebar.subheader("üîê Acceso")
    pwd = st.sidebar.text_input("Contrase√±a", type="password")
    if pwd != APP_PASSWORD:
        st.sidebar.warning("Contrase√±a incorrecta.")
        st.stop()

# ============================================================
# Helpers parse/normalize
# ============================================================
def parse_jsonl_bytes(b: bytes):
    txt = b.decode("utf-8", errors="replace")
    recs, bad = [], 0
    for line in txt.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            recs.append(json.loads(line))
        except Exception:
            bad += 1
    return recs, bad


def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "ts" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["ts"], errors="coerce")
    elif "timestamp" in df.columns:
        df["ts_parsed"] = pd.to_datetime(df["timestamp"], errors="coerce")
    else:
        df["ts_parsed"] = pd.NaT

    if "type" not in df.columns:
        df["type"] = ""

    return df

# ============================================================
# Arrays (volumen/delta/OHLC) y m√©tricas pre-entrada
# ============================================================
def _as_list(x):
    """Convierte a lista si viene como list/tuple/np.array o string tipo '[...]'."""
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return []
    if isinstance(x, list):
        return x
    if isinstance(x, (tuple, np.ndarray)):
        return list(x)
    if isinstance(x, str):
        s = x.strip()
        if s.startswith("[") and s.endswith("]"):
            try:
                return json.loads(s)
            except Exception:
                return []
    return []


def add_pressure_activity_features(trades: pd.DataFrame) -> pd.DataFrame:
    """A√±ade m√©tricas de 'Presi√≥n y Actividad' usando arrays LastN (contexto pre-entrada).
    Si no existen arrays, devuelve el DF sin cambios.
    """
    if trades is None or trades.empty:
        return trades

    t = trades.copy()

    # Asegura num√©ricos base si existen
    for c in ["tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "volEntrySoFar", "deltaEntrySoFar", "dir"]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    def _row_feat(r):
        dl = _as_list(r.get("deltaLastN"))
        vl = _as_list(r.get("volLastN"))
        ol = _as_list(r.get("openLastN"))
        hl = _as_list(r.get("highLastN"))
        ll = _as_list(r.get("lowLastN"))
        cl = _as_list(r.get("closeLastN"))

        if not dl or not vl or not hl or not ll or not cl or not ol:
            return pd.Series({
                "pre_presion_sum": np.nan,
                "pre_presion_abs": np.nan,
                "pre_vol_sum": np.nan,
                "pre_precio_neto": np.nan,
                "pre_rango_precio": np.nan,
                "pre_mov_ticks": np.nan,
                "pre_absorcion": np.nan,
                "pre_actividad_rel": np.nan,
                "pre_presion_por_vol": np.nan,
                "pre_sin_apoyo": False,
            })

        presion_sum = float(np.nansum(dl))
        presion_abs = float(abs(presion_sum))
        vol_sum = float(np.nansum(vl))

        # Movimiento de precio pre-entrada
        try:
            precio_neto = float(cl[-1] - ol[0])
        except Exception:
            precio_neto = np.nan

        try:
            rango = float(np.nanmax(hl) - np.nanmin(ll))
        except Exception:
            rango = np.nan

        tick = r.get("tickSize")
        if tick is None or (isinstance(tick, float) and np.isnan(tick)) or tick == 0 or rango != rango:
            mov_ticks = np.nan
        else:
            mov_ticks = rango / float(tick)

        # Absorci√≥n: presi√≥n alta + avance bajo (normalizado por ticks movidos)
        absorcion = (presion_abs / max(mov_ticks, 1.0)) if mov_ticks == mov_ticks else np.nan

        # Actividad relativa: vol hasta entrada vs mediana del vol reciente
        med_vol = float(np.nanmedian(vl)) if len(vl) else np.nan
        vol_entry = r.get("volEntrySoFar")
        if med_vol == med_vol and med_vol > 0 and vol_entry == vol_entry:
            actividad_rel = float(vol_entry / med_vol)
        else:
            actividad_rel = np.nan

        # Presi√≥n por volumen (magnitud relativa)
        presion_por_vol = float(presion_abs / vol_sum) if vol_sum == vol_sum and vol_sum > 0 else np.nan

        # ‚ÄúSin apoyo‚Äù: precio avanza en una direcci√≥n pero la presi√≥n va al lado opuesto
        d = r.get("dir")
        sin_apoyo = False
        if d == d and precio_neto == precio_neto:
            if d > 0 and precio_neto > 0 and presion_sum < 0:
                sin_apoyo = True
            elif d < 0 and precio_neto < 0 and presion_sum > 0:
                sin_apoyo = True

        return pd.Series({
            "pre_presion_sum": presion_sum,
            "pre_presion_abs": presion_abs,
            "pre_vol_sum": vol_sum,
            "pre_precio_neto": precio_neto,
            "pre_rango_precio": rango,
            "pre_mov_ticks": mov_ticks,
            "pre_absorcion": absorcion,
            "pre_actividad_rel": actividad_rel,
            "pre_presion_por_vol": presion_por_vol,
            "pre_sin_apoyo": sin_apoyo,
        })

    feats = t.apply(_row_feat, axis=1)
    for c in feats.columns:
        t[c] = feats[c]

    return t


# ============================================================
# Formatting & traffic-light helpers
# ============================================================
def pct(x, d=1):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}%"

def fmt(x, d=2):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "N/A"
    return f"{x:.{d}f}"

def traffic_pf(pf: float):
    if pf is None or np.isnan(pf):
        return "‚ö™ PF N/A"
    if pf < 1.0:  return "üî¥ PF < 1 (pierde)"
    if pf < 1.2:  return "üü° PF 1.0‚Äì1.2 (d√©bil)"
    if pf < 1.5:  return "üü¢ PF 1.2‚Äì1.5 (bueno)"
    return "üü£ PF > 1.5 (muy bueno)"

def traffic_exp(exp: float):
    if exp is None or np.isnan(exp):
        return "‚ö™ Promedio N/A"
    if exp < 0:   return "üî¥ Promedio < 0"
    if exp < 10:  return "üü° Promedio bajo pero positivo"
    return "üü¢ Promedio s√≥lido"


# ============================================================
# Core metrics
# ============================================================
def profit_factor(trades) -> float:
    """Profit Factor = suma de ganancias / suma absoluta de p√©rdidas.

    Acepta:
      - DataFrame con columna 'tradeRealized'
      - Serie de PnL (tradeRealized)
    """
    if trades is None:
        return np.nan

    # Permite pasar directamente la Serie tradeRealized
    if isinstance(trades, pd.Series):
        s = trades.dropna()
    else:
        if not isinstance(trades, pd.DataFrame) or "tradeRealized" not in trades.columns:
            return np.nan
        s = trades["tradeRealized"].dropna()

    wins = float(s[s > 0].sum())
    losses = float(s[s < 0].sum())  # negativo

    loss_abs = abs(losses)
    if loss_abs <= 0:
        # Sin p√©rdidas: PF infinito si hay ganancias, sino NaN
        return float("inf") if wins > 0 else np.nan

    return wins / loss_abs


def max_streak(outcomes: pd.Series, target: str):
    best_len, cur = 0, 0
    best_end = None
    for i, o in enumerate(outcomes.tolist()):
        if o == target:
            cur += 1
            if cur > best_len:
                best_len = cur
                best_end = i
        else:
            cur = 0
    if best_len == 0:
        return 0, None, None
    start = best_end - best_len + 1
    return best_len, start, best_end


def drawdown_details(t: pd.DataFrame):
    if t.empty:
        return np.nan, None, None
    dd = t["drawdown"].fillna(0)
    trough_idx = int(dd.idxmin())
    trough_time = t.loc[trough_idx, "exit_time"]
    peak_idx = int(t.loc[:trough_idx, "equity"].idxmax())
    peak_time = t.loc[peak_idx, "exit_time"]
    return float(dd.min()), peak_time, trough_time


def hour_bucket_label(h):
    if pd.isna(h):
        return "Sin hora"
    h = int(h)
    return f"{h:02d}:00‚Äì{h:02d}:59"



def pair_trades(df: pd.DataFrame) -> pd.DataFrame:
    """
    1 fila por trade (atmId):
    - EXIT: √∫ltimo por atmId
    - ENTRY: primero por atmId
    Si falta ENTRY -> lado = "Sin datos (falt√≥ ENTRY)" (NO inventamos)
    """
    entries = df[df["type"] == "ENTRY"].copy()
    exits = df[df["type"] == "EXIT"].copy()

    entry_cols = [
        "atmId", "ts_parsed", "dir",
        "instrument", "tickSize", "pointValue",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar",
        "volEntrySoFar", "deltaEntrySoFar",
        "snapN", "snapIncludesEntryBar",
        "volLastN", "deltaLastN",
        "openLastN", "highLastN", "lowLastN", "closeLastN"
    ]
    entry_cols = [c for c in entry_cols if c in entries.columns]

    if len(entry_cols) == 0:
        e1 = pd.DataFrame(columns=["atmId", "entry_time"])
    else:
        e1 = (entries.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[entry_cols]
                    .first()
                    .rename(columns={"ts_parsed": "entry_time"}))

    exit_cols = [
        "atmId", "ts_parsed",
        "outcome", "exitReason", "tradeRealized", "dayRealized",
        "maxUnreal", "minUnreal", "forcedCloseReason", "dailyHalt",
        "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "cvd", "deltaBar", "deltaPrevBar"
    ]
    exit_cols = [c for c in exit_cols if c in exits.columns]

    if len(exit_cols) == 0:
        x1 = pd.DataFrame(columns=["atmId", "exit_time", "tradeRealized"])
    else:
        x1 = (exits.sort_values("ts_parsed")
                    .groupby("atmId", as_index=False)[exit_cols]
                    .last()
                    .rename(columns={"ts_parsed": "exit_time"}))

    t = pd.merge(x1, e1, on="atmId", how="left")

    # Unifica columnas duplicadas de EXIT/ENTRY (pandas crea sufijos _x/_y)
    def _coalesce(name: str):
        x = f"{name}_x"
        y = f"{name}_y"
        if name in t.columns:
            return
        if (x in t.columns) or (y in t.columns):
            base = t[y] if y in t.columns else pd.Series([np.nan]*len(t))
            if x in t.columns:
                base = base.where(base.notna(), t[x])
            t[name] = base
            drop_cols = [c for c in [x, y] if c in t.columns]
            if drop_cols:
                t.drop(columns=drop_cols, inplace=True)

    for nm in [
        "dir", "instrument", "tickSize", "pointValue",
        "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "template", "orderType", "trigger",
        "orHigh", "orLow", "orSize",
        "ewo", "atr", "useAtrEngine", "atrSlMult",
        "tp1R", "tp2R", "tp1Ticks", "tp2Ticks",
        "tsBehindTP1Atr", "trailStepTicks",
        "deltaRatio", "dailyPnL",
        "cvd", "deltaBar", "deltaPrevBar"
    ]:
        _coalesce(nm)

    t["has_entry"] = t.get("entry_time").notna() if "entry_time" in t.columns else False

    # Num√©ricos
    for c in [
        "tradeRealized", "dayRealized", "maxUnreal", "minUnreal",
        "orSize", "atr", "ewo", "deltaRatio", "dir",
        "atrSlMult", "tp1R", "tp2R", "trailStepTicks",
        "tickSize", "pointValue", "slTicks", "qtyTP1", "qtyRunner", "avgEntry",
        "volEntrySoFar", "deltaEntrySoFar"
    ]:
        if c in t.columns:
            t[c] = pd.to_numeric(t[c], errors="coerce")

    # outcome robusto si falta
    if "tradeRealized" in t.columns:
        calc_outcome = np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS")
        if "outcome" not in t.columns:
            t["outcome"] = calc_outcome
        else:
            t["outcome"] = t["outcome"].where(t["outcome"].notna(), calc_outcome)

    # Duraci√≥n
    if "entry_time" in t.columns and "exit_time" in t.columns:
        t["duration_sec"] = (t["exit_time"] - t["entry_time"]).dt.total_seconds()
    else:
        t["duration_sec"] = np.nan

    # Equity / drawdown
    t = t.sort_values("exit_time").reset_index(drop=True)
    t["equity"] = t["tradeRealized"].fillna(0).cumsum()
    t["equity_peak"] = t["equity"].cummax()
    t["drawdown"] = t["equity"] - t["equity_peak"]

    # Hora
    t["exit_hour"] = t["exit_time"].dt.hour
    t["exit_hour_label"] = t["exit_hour"].apply(hour_bucket_label)

    # Lado (Compra/Venta) solo si hay dir
    def side_label(x):
        if pd.isna(x):
            return "Sin datos (falt√≥ ENTRY)"
        if x > 0:
            return "Compra (Long)"
        if x < 0:
            return "Venta (Short)"
        return "Sin datos (dir=0)"

    if "dir" in t.columns:
        t["lado"] = t["dir"].apply(side_label)
    else:
        t["lado"] = "Sin datos (falt√≥ ENTRY)"

    # ============================================================
    # M√©tricas tuning: Riesgo estimado, Ganancia/Riesgo, Captura/Devoluci√≥n
    # ============================================================
    if "tickSize" in t.columns and "pointValue" in t.columns:
        t["tick_value"] = t["tickSize"] * t["pointValue"]
    else:
        t["tick_value"] = np.nan

    if "qtyTP1" in t.columns or "qtyRunner" in t.columns:
        q1 = t["qtyTP1"] if "qtyTP1" in t.columns else 0
        qr = t["qtyRunner"] if "qtyRunner" in t.columns else 0
        t["qty_total"] = pd.to_numeric(q1, errors="coerce").fillna(0) + pd.to_numeric(qr, errors="coerce").fillna(0)
    else:
        t["qty_total"] = np.nan

    if "slTicks" in t.columns and "tick_value" in t.columns and "qty_total" in t.columns:
        t["risk_$"] = t["slTicks"] * t["tick_value"] * t["qty_total"]
        t.loc[t["risk_$"] <= 0, "risk_$"] = np.nan
    else:
        t["risk_$"] = np.nan

    if "tradeRealized" in t.columns:
        t["rr"] = t["tradeRealized"] / t["risk_$"]
    else:
        t["rr"] = np.nan

    if "tradeRealized" in t.columns and "maxUnreal" in t.columns:
        winners = t["tradeRealized"] > 0
        t["captura_pct"] = np.where(winners & (t["maxUnreal"] > 0), t["tradeRealized"] / t["maxUnreal"], np.nan)
        t["devolucion_pct"] = np.where(winners & (t["maxUnreal"] > 0),
                                       (t["maxUnreal"] - t["tradeRealized"]) / t["maxUnreal"], np.nan)
    else:
        t["captura_pct"] = np.nan
        t["devolucion_pct"] = np.nan

    # Presi√≥n/Actividad pre-entrada (si hay arrays)
    t = add_pressure_activity_features(t)

    return t


def summarize(t: pd.DataFrame) -> dict:
    if t.empty:
        return {}
    n = len(t)
    wins = int((t["tradeRealized"] > 0).sum())
    losses = int((t["tradeRealized"] < 0).sum())
    win_rate = (wins / n * 100) if n else np.nan

    pf = profit_factor(t)
    expectancy = float(t["tradeRealized"].mean()) if n else np.nan

    max_dd, dd_peak_time, dd_trough_time = drawdown_details(t)

    max_win = float(t["tradeRealized"].max())
    max_loss = float(t["tradeRealized"].min())

    outcomes = pd.Series(np.where(t["tradeRealized"].fillna(0) >= 0, "WIN", "LOSS"))
    wlen, _, _ = max_streak(outcomes, "WIN")
    llen, _, _ = max_streak(outcomes, "LOSS")

    return {
        "n": n, "wins": wins, "losses": losses, "win_rate": win_rate,
        "pnl_total": float(t["tradeRealized"].sum()),
        "pf": pf, "expectancy": expectancy,
        "max_dd": max_dd, "dd_peak_time": dd_peak_time, "dd_trough_time": dd_trough_time,
        "max_win": max_win, "max_loss": max_loss,
        "best_win_streak": wlen, "best_loss_streak": llen,
    }


# ============================================================
# Grouping / bins
# ============================================================
def make_bins_quantiles(df: pd.DataFrame, col: str, q: int):
    s = df[col].dropna()
    if len(s) < q * 10:
        return None
    try:
        return pd.qcut(df[col], q=q, duplicates="drop")
    except Exception:
        return None



def group_metrics(df: pd.DataFrame, group_col: str, min_trades: int, recommended_trades: int = None):
    """M√©tricas por grupo con control de muestra.
    - NO oculta grupos peque√±os: los marca como üü¢/üü°/üî¥.
    - 'WinRate (ajustado)' evita que 2/2 (=100%) gane contra 30 trades.
    """
    if recommended_trades is None:
        recommended_trades = max(60, min_trades)

    rows = []
    for g, sub in df.groupby(group_col):
        n = int(len(sub))
        if n == 0:
            continue

        tr = pd.to_numeric(sub.get("tradeRealized"), errors="coerce")
        wins = int((tr > 0).sum()) if tr is not None else 0
        wr = wins / n * 100 if n else np.nan
        wr_adj = (wins + 1) / (n + 2) * 100  # suavizado

        pf = profit_factor(sub) if "tradeRealized" in sub.columns else np.nan
        exp = float(tr.mean()) if tr is not None else np.nan
        pnl = float(tr.sum()) if tr is not None else np.nan

        score = exp * np.log1p(n) if exp == exp else np.nan

        if n >= recommended_trades:
            estado = "üü¢ Suficiente"
        elif n >= min_trades:
            estado = "üü° Muestra peque√±a"
        else:
            estado = "üî¥ No concluyente"

        rows.append({
            "Grupo": str(g),
            "Trades": n,
            "Estado": estado,
            "WinRate %": wr,
            "WinRate (ajustado) %": wr_adj,
            "Profit Factor": pf,
            "Promedio por trade": exp,
            "PnL Total": pnl,
            "Score (ponderado)": score,
        })

    out = pd.DataFrame(rows)
    if not out.empty:
        out = out.sort_values(["Score (ponderado)", "Trades"], ascending=[False, False], na_position="last").reset_index(drop=True)
    return out


# ============================================================
# Advice engines (NEXT LEVEL)
# ============================================================
def advice_from_table(tbl: pd.DataFrame, title: str, min_trades: int):
    if tbl is None or tbl.empty:
        st.info(f"En **{title}** no hay suficiente muestra (m√≠nimo {min_trades} trades por grupo).")
        return

    best = tbl.iloc[0]
    worst = tbl.iloc[-1]

    st.markdown("**‚úÖ Consejos r√°pidos (tabla):**")
    st.write(
        f"üèÜ Mejor: **{best['Grupo']}** | Trades={int(best['Trades'])} | PF={fmt(best['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(best['Promedio por trade'],1)} | PnL={fmt(best['PnL Total'],0)}"
    )
    st.write(
        f"üß® Peor: **{worst['Grupo']}** | Trades={int(worst['Trades'])} | PF={fmt(worst['Profit Factor'],2)} | "
        f"Promedio/trade={fmt(worst['Promedio por trade'],1)} | PnL={fmt(worst['PnL Total'],0)}"
    )

    # warnings
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è El mejor grupo tiene muestra peque√±a. Ideal confirmar con m√°s meses de logs.")
    if not np.isnan(best["Profit Factor"]) and best["Profit Factor"] < 1.0:
        st.error("üö® Incluso el mejor grupo tiene PF < 1 ‚Üí este filtro no est√° salvando el sistema en estos datos.")
    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning("üëâ Hay grupos con PF < 1 ‚Üí candidatos a filtrar/evitar.")

    st.caption("Nota: WinRate Ajustado + Score ponderado evitan que 2 trades al 100% ‚Äúganen‚Äù contra 30 trades.")


def pnl_shape_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].dropna()
    if pnl.empty:
        return []

    med = float(pnl.median())
    p25 = float(pnl.quantile(0.25))
    p75 = float(pnl.quantile(0.75))
    p10 = float(pnl.quantile(0.10))
    p90 = float(pnl.quantile(0.90))

    max_win = float(pnl.max())
    max_loss = float(pnl.min())
    avg_win = float(pnl[pnl > 0].mean()) if (pnl > 0).any() else np.nan
    avg_loss = float(pnl[pnl < 0].mean()) if (pnl < 0).any() else np.nan

    insights = []
    insights.append(f"üìå Mediana PnL: **{med:.1f}** | IQR (25‚Äì75%): **[{p25:.1f}, {p75:.1f}]**")

    if not np.isnan(avg_win) and not np.isnan(avg_loss) and avg_loss != 0:
        ratio = abs(avg_win / avg_loss)
        if ratio < 0.8:
            insights.append("‚ö†Ô∏è P√©rdidas promedio > ganancias promedio ‚Üí revisa SL, entradas tard√≠as, o horarios peligrosos.")
        elif ratio < 1.2:
            insights.append("üü° Ganancia y p√©rdida promedio similares ‚Üí el edge depende m√°s del winrate + filtros.")
        else:
            insights.append("üü¢ Ganancias promedio > p√©rdidas promedio ‚Üí buena relaci√≥n base si el winrate acompa√±a.")

    if max_win != 0:
        bomb = abs(max_loss) / abs(max_win)
        if bomb >= 1.5:
            insights.append("üö® P√©rdidas gigantes vs la mayor ganancia. Revisa stops, slippage, noticias, o ‚Äúchasing‚Äù.")
        elif bomb >= 1.0:
            insights.append("‚ö†Ô∏è La peor p√©rdida compite con la mejor ganancia. Controla los outliers.")

    insights.append(f"üß≠ Zona t√≠pica (10‚Äì90%): **[{p10:.1f}, {p90:.1f}]**. Fuera de esto son outliers.")
    return insights


def equity_recovery_insights(t: pd.DataFrame):
    if t.empty:
        return []

    pnl = t["tradeRealized"].fillna(0)
    exp = float(pnl.mean()) if len(pnl) else np.nan
    std = float(pnl.std()) if len(pnl) > 2 else np.nan

    max_dd, peak_t, trough_t = drawdown_details(t)

    insights = []
    if peak_t is not None and trough_t is not None:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}** (desde {peak_t} hasta {trough_t})")
    else:
        insights.append(f"üìâ Max Drawdown: **{max_dd:.0f}**")

    if exp < 0:
        insights.append("üö® Promedio por trade negativo: necesitas filtros fuertes o cambiar l√≥gica antes de ‚Äútunear fino‚Äù.")
    else:
        insights.append(f"‚úÖ Promedio por trade: **{exp:.1f}** ({traffic_exp(exp)})")

    if not np.isnan(std) and std > 0 and not np.isnan(exp):
        cv = abs(std / exp) if exp != 0 else np.inf
        if exp > 0 and cv > 6:
            insights.append("‚ö†Ô∏è PnL muy vol√°til vs el promedio ‚Üí sube muestra o filtra momentos de alta variabilidad.")
        elif exp > 0 and cv > 3:
            insights.append("üü° Variabilidad moderada-alta ‚Üí usa guardias diarias conservadoras.")
        elif exp > 0:
            insights.append("üü¢ PnL relativamente estable vs el promedio.")

    if exp > 0 and not np.isnan(max_dd):
        dd_trades_equiv = abs(max_dd / exp)
        if dd_trades_equiv > 80:
            insights.append("üö® Drawdown enorme relativo al promedio ‚Üí recuperaci√≥n puede tardar mucho.")
        elif dd_trades_equiv > 40:
            insights.append("‚ö†Ô∏è Drawdown alto relativo al promedio ‚Üí requiere disciplina (guardia diaria / filtros).")
        else:
            insights.append("üü¢ Drawdown razonable relativo al promedio.")

    return insights


def factor_danger_zone_insights(df_known: pd.DataFrame, xcol: str, q: int, min_trades: int, title: str):
    bins = make_bins_quantiles(df_known, xcol, q)
    if bins is None:
        return ["‚ÑπÔ∏è No hay suficiente data para detectar zonas por rangos."]

    tmp = df_known.copy()
    tmp["_bin"] = bins.astype(str)
    tbl = group_metrics(tmp, "_bin", min_trades=min_trades)

    if tbl.empty:
        return [f"‚ÑπÔ∏è No hay rangos con ‚â• {min_trades} trades para {title}."]

    # zonas malas
    bad = tbl[(tbl["Promedio por trade"] < 0) & (tbl["Profit Factor"] < 1.0)].copy()
    good = tbl[(tbl["Promedio por trade"] > 0) & (tbl["Profit Factor"] >= 1.2)].copy()

    insights = []
    if not bad.empty:
        b = bad.sort_values("Score (ponderado)").iloc[0]
        insights.append(f"üö´ Zona peligrosa: **{b['Grupo']}** ‚Üí promedio<0 y PF<1 (candidato a EVITAR).")
    else:
        insights.append("‚úÖ No se detectan rangos claramente peligrosos (con muestra suficiente).")

    if not good.empty:
        g = good.sort_values("Score (ponderado)", ascending=False).iloc[0]
        insights.append(f"‚úÖ Zona fuerte: **{g['Grupo']}** ‚Üí PF‚â•1.2 y promedio>0 (candidato a priorizar).")

    spread = float(tbl["Promedio por trade"].max() - tbl["Promedio por trade"].min())
    if spread < 5:
        insights.append("‚ÑπÔ∏è Este factor casi no separa rendimiento (spread peque√±o) ‚Üí filtro d√©bil por s√≠ solo.")
    else:
        insights.append("üìå Este factor S√ç separa rendimiento ‚Üí √∫til para tunear rangos.")
    return insights


# ============================================================
# Charts
# ============================================================
def plot_equity_drawdown(t: pd.DataFrame):
    fig1 = px.line(t, x="exit_time", y="equity", title="Equity (curva de capital acumulada)")
    fig1.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))

    fig2 = px.line(t, x="exit_time", y="drawdown", title="Drawdown (ca√≠da desde el m√°ximo de equity)")
    fig2.update_layout(height=340, margin=dict(l=10, r=10, t=50, b=10))
    fig2.add_hline(y=0, line_width=1, line_dash="dash")
    return fig1, fig2


def plot_pnl_hist(t: pd.DataFrame):
    """Histograma de PnL realizado (dinero). tradeRealized est√° en la moneda de la cuenta (normalmente $)."""
    tmp = t.copy()
    tr = pd.to_numeric(tmp.get("tradeRealized"), errors="coerce")
    tmp["Resultado"] = np.where(tr >= 0, "Ganancia", "P√©rdida")

    fig = px.histogram(
        tmp,
        x="tradeRealized",
        color="Resultado",
        nbins=40,
        barmode="overlay",
        title="Distribuci√≥n de PnL ($) por operaci√≥n",
        labels={"tradeRealized": "PnL ($)"},
    )
    fig.update_traces(opacity=0.75)
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    fig.add_vline(x=0, line_width=1, line_dash="dash")
    return fig


def plot_scatter_advanced(df_known: pd.DataFrame, xcol: str, title: str):
    cols = [c for c in [xcol, "tradeRealized", "exit_time", "lado", "exitReason"] if c in df_known.columns]
    tmp = df_known[cols].dropna(subset=[xcol, "tradeRealized"]).copy()
    if tmp.empty:
        st.info("No hay suficiente data para el scatter.")
        return

    tmp["Resultado"] = np.where(tmp["tradeRealized"] >= 0, "Ganancia", "P√©rdida")

    fig = px.scatter(
        tmp,
        x=xcol,
        y="tradeRealized",
        color="Resultado",
        hover_data=[c for c in ["exit_time", "lado", "exitReason", "tradeRealized"] if c in tmp.columns],
        title=title
    )
    fig.update_traces(marker=dict(size=7, opacity=0.60))
    fig.add_hline(y=0, line_width=1, line_dash="dash")
    fig.update_layout(height=440, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.caption("Lectura: verde = PnL ‚â• 0, rojo = PnL < 0. Con muestra peque√±a, √∫salo como idea, no como regla.")




def plot_factor_bins(df_known: pd.DataFrame, col: str, q: int, min_trades: int, recommended_trades: int, title: str,
                     show_scatter: bool, scatter_df: pd.DataFrame):
    """
    Panel por rangos (cuantiles) para un factor (OR/ATR/EWO/etc).
    - Colores consistentes: verde = mejor, rojo = peor.
    - Sin 'bins' en UI: todo se llama 'rangos'.
    - Etiquetas humanas para rangos (ej: 60‚Äì94).
    """
    def nice_range_label(s: str) -> str:
        if not isinstance(s, str):
            return str(s)
        s2 = s.strip()
        # Formatos t√≠picos: "(60.0, 94.0]" o "[14.5, 60.0)"
        if ("," in s2) and (s2[0] in "([") and (s2[-1] in "])"):
            inner = s2[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    a = float(parts[0])
                    b = float(parts[1])
                    # Redondeo ‚Äúhumano‚Äù
                    if abs(a) >= 100 or abs(b) >= 100:
                        return f"{a:.0f}‚Äì{b:.0f}"
                    if abs(a) >= 10 or abs(b) >= 10:
                        return f"{a:.1f}‚Äì{b:.1f}"
                    return f"{a:.2f}‚Äì{b:.2f}"
                except Exception:
                    return s2
        return s2

    bins = make_bins_quantiles(df_known, col, q)
    if bins is None:
        st.info(f"No hay suficiente data para crear rangos en **{title}**.")
        return

    tmp = df_known.copy()
    tmp["_range"] = bins.astype(str)

    tbl = group_metrics(tmp, "_range", min_trades=min_trades, recommended_trades=recommended_trades)
    if tbl.empty:
        st.info(f"En **{title}** no hay data para agrupar.")
        return

    # Etiquetas humanas (m√°s f√°ciles de leer)
    _orig = tbl["Grupo"].astype(str).tolist()
    _nice = [nice_range_label(x) for x in _orig]

    def _parse_left(rg: str):
        rg = str(rg).strip()
        if ("," in rg) and (rg[0] in "([") and (rg[-1] in "])"):
            inner = rg[1:-1]
            parts = inner.split(",")
            if len(parts) == 2:
                try:
                    return float(parts[0])
                except Exception:
                    return np.nan
        return np.nan

    lefts = [(_parse_left(o), i) for i, o in enumerate(_orig)]
    order = [i for _, i in sorted(lefts, key=lambda x: (np.nan_to_num(x[0], nan=1e18), x[1]))]

    k = len(_nice)
    if k == 3:
        names = ["Bajo", "Medio", "Alto"]
    elif k == 4:
        names = ["Bajo", "Medio-bajo", "Medio-alto", "Alto"]
    elif k == 5:
        names = ["Muy bajo", "Bajo", "Medio", "Alto", "Muy alto"]
    else:
        names = [f"R{i+1}" for i in range(k)]

    label_map = {}
    for rank, idx in enumerate(order):
        base = names[rank] if rank < len(names) else f"R{rank+1}"
        label_map[_orig[idx]] = f"{base} ({_nice[idx]})"

    tbl["Grupo"] = tbl["Grupo"].astype(str).map(label_map).fillna(tbl["Grupo"].astype(str))

    # Leyenda de muestra
    n_ok = int((tbl["Estado"] == "üü¢ Suficiente").sum())
    n_small = int((tbl["Estado"] == "üü° Muestra peque√±a").sum())
    n_bad = int((tbl["Estado"] == "üî¥ No concluyente").sum())
    st.caption(
        f"Muestra por rango: üü¢{n_ok} üü°{n_small} üî¥{n_bad}  | "
        f"M√≠nimo para mirar: {min_trades}  | Recomendado para decidir: {recommended_trades}"
    )

    # Para gr√°ficos: solo rangos con muestra m√≠nima
    tbl_chart = tbl[tbl["Trades"] >= min_trades].copy()

    if not tbl_chart.empty:
        # Promedio por trade: verde = mejor, rojo = peor. Centramos en 0 (negativos quedan rojos).
        fig_exp = px.bar(
            tbl_chart,
            x="Grupo",
            y="Promedio por trade",
            color="Promedio por trade",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=0,
            title=f"{title} ‚Üí Promedio por trade (rangos)",
            text="Promedio por trade",
        )
        fig_exp.update_traces(texttemplate="%{text:.0f}", textposition="inside")
        fig_exp.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="Promedio",
        )
        fig_exp.add_hline(y=0, line_width=1, line_dash="dash")

        # Profit Factor: verde = alto (mejor), rojo = bajo (peor). Punto neutro en 1.0.
        fig_pf = px.bar(
            tbl_chart,
            x="Grupo",
            y="Profit Factor",
            color="Profit Factor",
            color_continuous_scale="RdYlGn",
            color_continuous_midpoint=1.0,
            title=f"{title} ‚Üí Profit Factor (rangos)",
            text="Profit Factor",
        )
        fig_pf.update_traces(texttemplate="%{text:.2f}", textposition="inside")
        fig_pf.update_layout(
            height=320,
            margin=dict(l=10, r=10, t=50, b=10),
            coloraxis_colorbar_title="PF",
        )
        fig_pf.add_hline(y=1.0, line_width=1, line_dash="dash")

        st.plotly_chart(fig_exp, use_container_width=True)
        st.plotly_chart(fig_pf, use_container_width=True)

        st.caption("Profit Factor (PF) = Ganancias totales / P√©rdidas totales. PF>1 indica que el conjunto gana. "
                   "PF>1.5 suele ser s√≥lido si la muestra es suficiente (üü¢).")

        advice_from_table(tbl_chart, title, min_trades=min_trades)
    else:
        st.info("‚ö†Ô∏è Con el m√≠nimo actual, todos los rangos quedan con poca muestra. √ösalo como idea, no como regla.")

    st.dataframe(tbl, use_container_width=True)

    if show_scatter:
        st.markdown("**Scatter (solo para ver dispersi√≥n / outliers)**")
        if col in scatter_df.columns and scatter_df[col].notna().sum() >= max(20, min_trades):
            plot_scatter_advanced(scatter_df, col, title=f"{title} ‚Üí Scatter")
        else:
            st.info("No hay suficiente data para scatter en este factor.")

def plot_hour_analysis(t: pd.DataFrame, min_trades: int):
    tbl = group_metrics(t, "exit_hour_label", min_trades=min_trades)
    if tbl.empty:
        st.info(f"No hay suficientes trades por hora para min_trades={min_trades}.")
        return None

    fig = px.bar(tbl, x="Grupo", y="Score (ponderado)",
                 title="Horas m√°s prometedoras (Score ponderado por tama√±o de muestra)")
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig, use_container_width=True)

    st.dataframe(tbl, use_container_width=True)
    advice_from_table(tbl, title="Hora", min_trades=min_trades)
    return tbl



def plot_heatmap_weekday_hour(t: pd.DataFrame, min_trades: int):
    tmp = t.copy()

    if "exit_time" not in tmp.columns or tmp["exit_time"].isna().all():
        st.info("No hay exit_time v√°lido para generar el heatmap.")
        return

    tmp = tmp.dropna(subset=["exit_time"]).copy()
    tmp["weekday"] = tmp["exit_time"].dt.day_name()
    if "exit_hour" not in tmp.columns or tmp["exit_hour"].isna().all():
        tmp["exit_hour"] = tmp["exit_time"].dt.hour

    weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    tmp["weekday_order"] = pd.Categorical(tmp["weekday"], categories=weekday_order, ordered=True)

    agg = tmp.groupby(["weekday_order", "exit_hour"]).agg(
        Trades=("tradeRealized", "size"),
        Promedio=("tradeRealized", "mean"),
    ).reset_index()

    agg.loc[agg["Trades"] < min_trades, "Promedio"] = np.nan
    pivot = agg.pivot(index="weekday_order", columns="exit_hour", values="Promedio")

    # Si con el m√≠nimo actual no queda nada visible, avisamos y no dibujamos un heatmap vac√≠o.
    if pivot.count().sum() == 0:
        st.info(
            f"No hay celdas con ‚â• {min_trades} trades para el heatmap. "
            "Baja el m√≠nimo o usa el panel por hora (arriba), que requiere menos muestra."
        )
        return

    # Escala azul‚Üírojo (negativo‚Üípositivo). Centramos en 0 para lectura r√°pida.
    vals = pivot.values.astype(float)
    max_abs = np.nanmax(np.abs(vals)) if np.isfinite(vals).any() else None
    zmin = -max_abs if max_abs else None
    zmax = max_abs if max_abs else None

    # Compatibilidad: algunas versiones de Plotly no soportan text_auto en imshow.
    try:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
            text_auto=True,
        )
    except TypeError:
        fig = px.imshow(
            pivot,
            aspect="auto",
            title=f"Heatmap: Promedio por trade (D√≠a x Hora) | solo celdas con ‚â• {min_trades} trades",
            origin="lower",
            color_continuous_scale="RdBu_r",
            zmin=zmin,
            zmax=zmax,
            color_continuous_midpoint=0,
        )
        # A√±adimos etiquetas manuales (valores)
        for yi, day in enumerate(pivot.index.astype(str).tolist()):
            for xi, hour in enumerate(pivot.columns.tolist()):
                v = pivot.loc[pivot.index[yi], hour]
                if pd.notna(v):
                    fig.add_annotation(
                        x=hour,
                        y=day,
                        text=f"{v:.0f}",
                        showarrow=False,
                        font=dict(size=11, color="black"),
                    )

    fig.update_layout(height=460, margin=dict(l=10, r=10, t=60, b=10))
    st.plotly_chart(fig, use_container_width=True)
    st.caption("Azul = promedio negativo, rojo = promedio positivo. Si casi todo queda vac√≠o, baja el m√≠nimo (muestra peque√±a).")

# ============================================================
# UI
# ============================================================
st.title("üìä WIC_WLF2 Analizador")

uploaded = st.file_uploader(
    "üì§ Sube uno o varios archivos .jsonl (meses)",
    type=["jsonl"],
    accept_multiple_files=True
)
if not uploaded:
    st.stop()

all_records, bad_total = [], 0
for uf in uploaded:
    recs, bad = parse_jsonl_bytes(uf.getvalue())
    bad_total += bad
    all_records.extend(recs)

if not all_records:
    st.error("No se pudo leer ning√∫n registro JSON v√°lido.")
    st.stop()

df = pd.DataFrame(all_records)
df = normalize_columns(df)
t = pair_trades(df)

if bad_total > 0:
    st.caption(f"‚ÑπÔ∏è L√≠neas inv√°lidas ignoradas al parsear: **{bad_total}**")

missing_entry = int((~t["has_entry"]).sum())
if missing_entry > 0:
    st.warning(
        f"‚ö†Ô∏è **{missing_entry} operaciones no tienen ENTRY** en los archivos cargados. "
        "En esas, no se puede saber Compra/Venta ni ORSize/ATR/EWO/DeltaRatio. "
        "Se muestran como: ‚ÄúSin datos (falt√≥ ENTRY)‚Äù."
    )

# Sidebar controls
st.sidebar.subheader("‚öôÔ∏è Ajustes")
min_trades = st.sidebar.slider("M√≠nimo trades por grupo (para mirar)", 5, 120, 30, 5)
recommended_trades = st.sidebar.slider("Trades recomendados por grupo (para decidir)", 20, 300, 80, 10)
q_bins = st.sidebar.slider("N√∫mero de rangos (cuantiles)", 3, 12, 5, 1)

show_adv_scatter = st.sidebar.checkbox("Mostrar scatter (√∫til para ver outliers)", value=False)
last_n_scatter = st.sidebar.slider("Scatter: √∫ltimos N trades (0=todo)", 0, 3000, 800, 100)

summary = summarize(t)

# ============================================================
# Summary
# ============================================================
st.subheader("‚úÖ Resumen r√°pido (lo m√°s importante)")

c1, c2, c3, c4, c5, c6 = st.columns(6)
c1.metric("Operaciones", f"{summary['n']}")
c2.metric("Ganadas", f"{summary['wins']}")
c3.metric("Perdidas", f"{summary['losses']}")
c4.metric("% Acierto", f"{summary['win_rate']:.1f}%")
c5.metric("PnL Total", f"{summary['pnl_total']:.0f}")
c6.metric("Profit Factor", f"{summary['pf']:.2f}" if not np.isnan(summary["pf"]) else "N/A")

c7, c8, c9, c10, c11, c12 = st.columns(6)
c7.metric("Promedio por trade (Expectancia)", f"{summary['expectancy']:.1f}")
c8.metric("Max Drawdown", f"{summary['max_dd']:.0f}")
c9.metric("Racha wins seguidos", f"{summary['best_win_streak']}")
c10.metric("Racha losses seguidos", f"{summary['best_loss_streak']}")
c11.metric("Mayor win", f"{summary['max_win']:.1f}")
c12.metric("Mayor loss", f"{summary['max_loss']:.1f}")

with st.expander("üìå C√≥mo leer estas m√©tricas (simple)"):
    st.write("**Promedio por trade (Expectancia)**: lo que ganas/pierdes en promedio por operaci√≥n. Si es positivo, bien.")
    st.write("**Profit Factor**: ganancias totales / p√©rdidas totales. PF > 1.0 indica ventaja. PF > 1.2 suele ser m√°s s√≥lido.")
    st.write("**Drawdown**: la peor ca√≠da desde el m√°ximo de tu equity; representa el ‚Äúdolor m√°ximo‚Äù del sistema.")
    st.write("**Rachas**: cu√°ntas operaciones ganadas/perdidas seguidas (√∫til para guardias diarias y sizing).")

st.markdown("### ‚öôÔ∏è Avisos seg√∫n tus ajustes")
total_n = int(summary.get("n", 0))
if total_n < 60:
    st.info("Muestra peque√±a (menos de 60 trades). √ösalo para orientar el tuning, pero evita cambiar reglas por 3 trades.")

# Si el usuario pide demasiados rangos o m√≠nimos para la muestra, casi todo quedar√° vac√≠o.
if q_bins * max(1, min_trades) > max(1, total_n):
    st.warning(
        "‚ö†Ô∏è Con estos ajustes vas a ver muchos paneles vac√≠os: est√°s pidiendo demasiados rangos o un m√≠nimo demasiado alto para tu muestra. "
        "Sugerencia con esta cantidad de trades: 3‚Äì5 rangos y m√≠nimo 10‚Äì20 trades por grupo."
    )
if min_trades > max(10, total_n // 2):
    st.warning("‚ö†Ô∏è M√≠nimo por grupo muy alto vs tu total de trades. Baja el m√≠nimo si quieres ver m√°s comparaciones (con cuidado).")
if recommended_trades > total_n:
    st.info("Recomendaci√≥n: tu 'trades recomendados para decidir' es mayor que tu muestra actual, as√≠ que todas las conclusiones son provisionales.")

# ============================================================
# Main charts
# ============================================================
st.subheader("üìà Gr√°ficos principales (claros + consejos)")

fig_eq, fig_dd = plot_equity_drawdown(t)
colA, colB = st.columns(2)
with colA:
    st.plotly_chart(fig_eq, use_container_width=True)
with colB:
    st.plotly_chart(fig_dd, use_container_width=True)

st.markdown("### üß† Consejos autom√°ticos (Equity / Drawdown)")
for s in equity_recovery_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.success(s)

st.plotly_chart(plot_pnl_hist(t), use_container_width=True)
st.caption("PnL ($) = dinero realizado por trade (tradeRealized). Si quieres verlo en ticks/points, se puede derivar con tickSize/pointValue, pero aqu√≠ mostramos la realidad de la cuenta.")

st.markdown("### üß† Consejos autom√°ticos (Distribuci√≥n de PnL)")
for s in pnl_shape_insights(t):
    if "üö®" in s:
        st.error(s)
    elif "‚ö†Ô∏è" in s:
        st.warning(s)
    elif "üü°" in s:
        st.info(s)
    else:
        st.info(s)


# ============================================================
# Ganancia vs Riesgo (RR) + Captura / Devoluci√≥n
# ============================================================
st.subheader("üéØ Ganancia vs Riesgo (RR) y manejo de la operaci√≥n")

if "rr" not in t.columns or t["rr"].dropna().empty:
    st.info(
        "No hay datos suficientes para calcular RR. Para esto necesitas en el log (ENTRY o EXIT): "
        "tickSize, pointValue, slTicks y cantidades (qtyTP1/qtyRunner)."
    )
else:
    rr_df = t[t["rr"].notna()].copy()

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("RR mediana", f"{rr_df['rr'].median():.2f}")
    c2.metric("RR promedio", f"{rr_df['rr'].mean():.2f}")
    c3.metric("% RR ‚â• 1", f"{(rr_df['rr'] >= 1).mean()*100:.1f}%")
    c4.metric("% RR ‚â• 2", f"{(rr_df['rr'] >= 2).mean()*100:.1f}%")
    c5.metric("Trades con RR", f"{len(rr_df)}")

    # M√©tricas extra (m√°s f√°ciles de leer con muestras peque√±as)
    rr_wins = rr_df.loc[rr_df["rr"] > 0, "rr"]
    rr_losses = rr_df.loc[rr_df["rr"] < 0, "rr"]
    small_losses = rr_df[(rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)]

    c6, c7, c8 = st.columns(3)
    c6.metric("RR promedio (ganadores)", f"{rr_wins.mean():.2f}" if not rr_wins.empty else "N/A")
    c7.metric("RR promedio (perdedores)", f"{rr_losses.mean():.2f}" if not rr_losses.empty else "N/A")
    c8.metric("% p√©rdidas peque√±as (-0.5R a 0)", f"{len(small_losses)/len(rr_df)*100:.1f}%" if len(rr_df) else "N/A")

    rr_tmp = rr_df.copy()
    rr_tmp["Resultado"] = np.where(rr_tmp["rr"] >= 0, "Ganancia", "P√©rdida")
    fig_rr = px.histogram(
        rr_tmp,
        x="rr",
        color="Resultado",
        nbins=30,
        barmode="overlay",
        title="Distribuci√≥n de RR (Ganancia/Riesgo)",
        labels={"rr": "RR"},
    )
    fig_rr.update_traces(opacity=0.75)
    fig_rr.add_vline(x=0, line_width=1, line_dash="dash")
    fig_rr.add_vline(x=1, line_width=1, line_dash="dash")
    fig_rr.update_layout(height=320, margin=dict(l=10, r=10, t=50, b=10))
    st.plotly_chart(fig_rr, use_container_width=True)

    st.markdown("**C√≥mo leer RR (r√°pido)**")
    rr_med = rr_df["rr"].median()
    rr_mean = rr_df["rr"].mean()
    if rr_mean > 0 and rr_med < 0:
        st.info("Promedio > 0 y mediana < 0: el resultado depende de pocos trades grandes; la mayor√≠a pierde.")
    elif rr_mean > 0 and rr_med > 0:
        st.info("Promedio > 0 y mediana > 0: la mayor√≠a de trades aporta; comportamiento m√°s estable.")
    elif rr_mean < 0:
        st.info("Promedio < 0: el sistema est√° perdiendo (tuning o filtros urgentes).")
    st.caption("Con pocas operaciones, confirma con m√°s trades antes de cambiar reglas.")

    st.markdown("### üß† Pistas r√°pidas (RR)")
    pct_rr1 = (rr_df["rr"] >= 1).mean()
    pct_stop = (rr_df["rr"] <= -1).mean()
    pct_small_loss = ((rr_df["rr"] < 0) & (rr_df["rr"] > -0.5)).mean()

    if pct_rr1 < 0.35:
        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if pct_stop > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if pct_small_loss < 0.05 and pct_stop > 0.15:
        st.info("üü° Casi no hay p√©rdidas peque√±as: cuando pierdes, sueles perder ~1R completo. Eso suele indicar 'stop-out' frecuente (poco margen para salir antes). Buen candidato: mejorar filtros de entrada/horario o invalidaci√≥n temprana.")

    if rr_df["rr"].median() > 0.3 and pct_rr1 > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

        st.warning("‚ö†Ô∏è Pocos trades llegan a RR‚â•1. Revisa: entrar tarde, SL muy grande, o TP demasiado corto.")
    if (rr_df["rr"] <= -1).mean() > 0.10:
        st.warning("üö® Muchas p√©rdidas de 1R o m√°s (RR ‚â§ -1). Revisa: slippage, noticias, stops muy ajustados o entradas sin confirmaci√≥n.")
    if rr_df["rr"].median() > 0.3 and (rr_df["rr"] >= 1).mean() > 0.45:
        st.success("‚úÖ Estructura de RR saludable (seg√∫n esta muestra). Aun as√≠: valida con m√°s trades.")

    # Captura / Devoluci√≥n (solo ganadores)
    if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
        wincap = t["captura_pct"].dropna()
        wingb = t["devolucion_pct"].dropna()

        c6, c7, c8 = st.columns(3)
        c6.metric("Captura mediana", f"{wincap.median()*100:.0f}%")
        c7.metric("Devoluci√≥n mediana", f"{wingb.median()*100:.0f}%")
        c8.metric("Ganadores con datos", f"{len(wincap)}")

        # Mostrar en % (0‚Äì100). Si ves valores >100%, suele ser inconsistencia de log (maxUnreal no captur√≥ el pico real).
        raw_cap = t["captura_pct"].dropna()
        n_weird = int((raw_cap > 1.05).sum())
        if n_weird > 0:
            st.warning("‚ö†Ô∏è Veo algunos valores de 'captura' > 100%. Eso suele pasar cuando maxUnreal no captur√≥ el pico real (o por parciales). "
                       "Para no confundir, el gr√°fico se limita a 0‚Äì100%.")

        cap_plot = (raw_cap.clip(0, 1) * 100.0)
        cap_df = pd.DataFrame({"Captura (%)": cap_plot})

        fig_cap = px.histogram(
            cap_df,
            x="Captura (%)",
            nbins=20,
            title="Qu√© tan cerca del pico cierras (solo ganadores)",
        )
        fig_cap.add_vline(x=50, line_width=1, line_dash="dash")
        fig_cap.update_layout(height=300, margin=dict(l=10, r=10, t=50, b=10))
        st.plotly_chart(fig_cap, use_container_width=True)

        st.markdown("**Qu√© significa esto (en simple)**")
        st.write(
            "Solo se calcula en trades **ganadores**. "
            "La idea es responder: **¬øcerr√© cerca del mejor punto, o dej√© devolver mucho?**"
        )
        st.write(
            "- **Pico del trade** = el mejor PnL flotante que tuvo antes de cerrar (*maxUnreal*).\n"
            "- **Te quedas (captura)** = qu√© % de ese pico terminaste cobrando al cerrar.\n"
            "- **Devolviste (devoluci√≥n)** = qu√© % retrocedi√≥ desde el pico hasta el cierre."
        )
        st.write(
            "Ejemplo: el trade lleg√≥ a **+$500** (pico) y cerr√≥ en **+$475** ‚Üí "
            "Te quedas ‚âà **95%** y devolviste ‚âà **5%**."
        )

        st.markdown("**üß† Consejos autom√°ticos (salidas / trailing)**")
        cap_med = wincap.median() if not wincap.empty else np.nan
        gb_med = wingb.median() if not wingb.empty else np.nan

        if cap_med == cap_med and cap_med < 0.35:
            st.warning("‚ö†Ô∏è Captura mediana baja (<35%). Est√°s cerrando muy lejos del mejor punto: revisa trailing, TP, o reglas de salida temprana.")
        elif cap_med == cap_med and cap_med > 0.60:
            st.success("‚úÖ Captura mediana alta (>60%). Buen manejo de salida (en esta muestra).")
        else:
            st.info("üü° Captura mediana intermedia. Puede estar bien; valida con m√°s trades.")

        if gb_med == gb_med and gb_med > 0.60:
            st.warning("‚ö†Ô∏è Devoluci√≥n mediana alta (>60%). Est√°s devolviendo mucho: prueba trailing m√°s agresivo o TP parcial mejor definido.")
        elif gb_med == gb_med and gb_med < 0.35:
            st.success("‚úÖ Devoluci√≥n mediana baja (<35%). Sueles proteger ganancias a tiempo.")
        else:
            st.info("üü° Devoluci√≥n mediana intermedia. Ajusta solo si ves que afecta RR/expectancia.")

        st.caption("Interpretaci√≥n r√°pida: Captura alta suele indicar salidas eficientes; Devoluci√≥n alta suele indicar trailing/TP tarde o dejar correr sin proteger.")

    # RR por plantilla / tipo de orden
    split_cols = []
    # Evitamos 'trigger' porque suele ser demasiado gen√©rico y confunde a usuarios finales.
    for c in ["template", "orderType", "exitReason", "lado"]:
        if c in rr_df.columns and rr_df[c].notna().sum() > 0:
            split_cols.append(c)

    if split_cols:
        pick = st.selectbox("Comparar RR por:", split_cols, index=0)
        rr_tbl = group_metrics(rr_df, pick, min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.dataframe(rr_tbl, use_container_width=True)
        st.caption("Tip: usa 'Estado' üü¢/üü°/üî¥ para no enamorarte de grupos con 3 trades.")

# ============================================================
# Motivos de salida
# ============================================================
st.subheader("üö™ Motivos de salida (qu√© est√° cerrando tus trades)")

colA, colB = st.columns(2)

with colA:
    if "exitReason" in t.columns and t["exitReason"].notna().sum() > 0:
        tbl_exit = group_metrics(t, "exitReason", min_trades=min_trades, recommended_trades=recommended_trades)
        st.markdown("**ExitReason**")
        st.dataframe(tbl_exit, use_container_width=True)

        # Pistas
        if not tbl_exit.empty:
            worst = tbl_exit.sort_values("Promedio por trade").iloc[0]
            if float(worst["Promedio por trade"]) < 0 and int(worst["Trades"]) >= min_trades:
                st.warning(f"‚ö†Ô∏è Peor motivo (por promedio): **{worst['Grupo']}**. Revisa ese flujo/condici√≥n.")
    else:
        st.info("No hay exitReason en los logs.")

with colB:
    if "forcedCloseReason" in t.columns and t["forcedCloseReason"].notna().sum() > 0:
        tbl_fc = group_metrics(t, "forcedCloseReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
        st.markdown("**ForcedCloseReason**")
        st.dataframe(tbl_fc, use_container_width=True)

        if not tbl_fc.empty:
            hot = tbl_fc.sort_values("Trades", ascending=False).iloc[0]
            if int(hot["Trades"]) >= min_trades and float(hot["Promedio por trade"]) < 0:
                st.warning(f"üö® Forced close frecuente y negativo: **{hot['Grupo']}**. Esto suele ser 'regla' o 'protecci√≥n' mal calibrada.")
    else:
        st.info("No hay forcedCloseReason en los logs.")

st.caption("OJO: el motivo de salida es diagn√≥stico, no filtro m√°gico. √ösalo para detectar patrones (stops, daily halt, cierre forzado, etc.).")


# ============================================================
# Long vs Short
# ============================================================
st.subheader("üß≠ Compra vs Venta (solo donde hay ENTRY)")

col1, col2, col3 = st.columns(3)
col1.metric("Compras (Long)", int((t["lado"] == "Compra (Long)").sum()))
col2.metric("Ventas (Short)", int((t["lado"] == "Venta (Short)").sum()))
col3.metric("Sin datos (falt√≥ ENTRY)", int((t["lado"].str.startswith("Sin datos")).sum()))

known = t[t["lado"].isin(["Compra (Long)", "Venta (Short)"])].copy()
if known.empty:
    st.info("No hay suficientes trades con ENTRY para separar Compra/Venta.")
else:
    side_tbl = group_metrics(known, "lado", min_trades=max(5, min_trades // 2))
    st.dataframe(side_tbl, use_container_width=True)
    advice_from_table(side_tbl, title="Compra/Venta", min_trades=max(5, min_trades // 2))

# ============================================================
# Tuning factors
# ============================================================
st.subheader("üõ†Ô∏è Ajuste de filtros (tunear settings con datos reales)")

if known.empty:
    st.info("Estos an√°lisis necesitan ENTRY (para tener ORSize/ATR/EWO/DeltaRatio por trade).")
else:
    df_known = known.copy()
    df_scatter = df_known.sort_values("exit_time")
    if last_n_scatter and last_n_scatter > 0:
        df_scatter = df_scatter.tail(last_n_scatter)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["OR Size", "ATR", "EWO", "Balance C/V", "Presi√≥n y Actividad"])

    with tab1:
        with st.expander("üìå OR Size: qu√© significa y c√≥mo usarlo"):
            st.write("OR Size = tama√±o del rango inicial (Opening Range).")
            st.write("- OR grande ‚Üí mercado m√°s 'movido'. Si tu PF cae aqu√≠, suele ser por whipsaws y entradas tard√≠as.")
            st.write("- OR peque√±o ‚Üí mercado m√°s 'apretado'. Si tu PF cae aqu√≠, suele ser por falta de recorrido.")
            st.write("Consejo: busca rangos con **PF>1**, **promedio > 0** y muestra üü¢ antes de convertirlo en filtro.")
        if "orSize" in df_known.columns and df_known["orSize"].notna().sum() > 30:
            plot_factor_bins(df_known, "orSize", q_bins, min_trades, recommended_trades, "OR Size (tama√±o del rango)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de OR Size en los logs.")

    with tab2:
        with st.expander("üìå ATR: qu√© significa y c√≥mo usarlo"):
            st.write("ATR = volatilidad (cu√°nto se mueve el precio en promedio).")
            st.write("- ATR alto ‚Üí movimientos amplios: necesitas stops/targets coherentes o te saca el ruido.")
            st.write("- ATR bajo ‚Üí poco recorrido: si tu TP es fijo, puede que no llegue.")
            st.write("Consejo: si tu estrategia tiene ATR engine, aqu√≠ ver√°s si te est√° ayudando o empeorando.")
        if "atr" in df_known.columns and df_known["atr"].notna().sum() > 30:
            plot_factor_bins(df_known, "atr", q_bins, min_trades, recommended_trades, "ATR (volatilidad)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de ATR en los logs.")

    with tab3:
        with st.expander("üìå EWO: qu√© significa y c√≥mo usarlo"):
            st.write("EWO (aqu√≠ usamos |EWO|) = fuerza de tendencia. M√°s alto suele implicar tendencia m√°s marcada.")
            st.write("- |EWO| alto ‚Üí tendencia: suele favorecer continuaciones/breakouts.")
            st.write("- |EWO| bajo ‚Üí chop/rango: suele castigar entradas por impulso.")
            st.write("Consejo: si ves PF<1 en |EWO| bajo, es un buen candidato a filtro de 'no-trade'.")
        if "ewo" in df_known.columns and df_known["ewo"].notna().sum() > 30:
            df_known2 = df_known.copy()
            df_known2["ewo_abs"] = df_known2["ewo"].abs()

            df_scatter2 = df_scatter.copy()
            df_scatter2["ewo_abs"] = df_scatter2["ewo"].abs()

            plot_factor_bins(df_known2, "ewo_abs", q_bins, min_trades, recommended_trades, "EWO (fuerza de tendencia)", show_adv_scatter, df_scatter2)
        else:
            st.info("No hay suficientes valores de EWO en los logs.")

    with tab4:
        with st.expander("üìå Balance comprador-vendedor: qu√© significa y c√≥mo usarlo"):
            st.write("Balance C/V = delta/vol (intensidad neta de compras vs ventas).")
            st.write("- Valores altos (en magnitud) ‚Üí desequilibrio fuerte (posible impulso).")
            st.write("- Cerca de 0 ‚Üí poca ventaja de flujo (m√°s f√°cil que el precio se 'devuelva').")
            st.write("Consejo: √∫salo para evitar entradas cuando no hay participaci√≥n real.")
        if "deltaRatio" in df_known.columns and df_known["deltaRatio"].notna().sum() > 30:
            plot_factor_bins(df_known, "deltaRatio", q_bins, min_trades, recommended_trades, "Balance comprador-vendedor (delta/vol)", show_adv_scatter, df_scatter)
        else:
            st.info("No hay suficientes valores de Balance C/V en los logs.")

    with tab5:
        st.markdown("### Qu√© es esto (en simple)")
        st.write(
            "Usamos los arrays pre-entrada (delta/volumen y OHLC de los √∫ltimos N segundos) para medir "
            "**actividad** y **presi√≥n** antes de entrar. Esto ayuda a detectar entradas 'con gasolina' "
            "vs entradas 'sin apoyo' o con **absorci√≥n**."
        )
        st.caption(
            "‚ö†Ô∏è OJO: con 40 trades esto es exploratorio. √ösalo para generar hip√≥tesis y valida con m√°s muestra."
        )

        needed_any = any(c in df_known.columns for c in ["pre_absorcion", "pre_actividad_rel", "pre_presion_por_vol", "pre_presion_sum"])
        if not needed_any:
            st.info("No veo arrays pre-entrada en tus logs (deltaLastN/volLastN/OHLC). Si est√°n, revisa que se est√©n logueando en ENTRY.")
        else:
            # Ajuste de bins m√°s conservador cuando la muestra es peque√±a
            q_small = min(q_bins, 6)

            colA, colB = st.columns(2)
            with colA:
                if "pre_absorcion" in df_known.columns and df_known["pre_absorcion"].notna().sum() > 20:
                    st.markdown("#### 1) Absorci√≥n (presi√≥n fuerte, avance peque√±o)")
                    plot_factor_bins(df_known, "pre_absorcion", q_small, min_trades, recommended_trades,
                                     "Absorci√≥n (presi√≥n fuerte + avance peque√±o)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Absorci√≥n'.")

            with colB:
                if "pre_actividad_rel" in df_known.columns and df_known["pre_actividad_rel"].notna().sum() > 20:
                    st.markdown("#### 2) Actividad (volumen relativo antes de entrar)")
                    plot_factor_bins(df_known, "pre_actividad_rel", q_small, min_trades, recommended_trades,
                                     "Actividad relativa (volumen hasta entrada vs mediana reciente)", show_adv_scatter, df_scatter)
                else:
                    st.info("No hay suficientes valores para 'Actividad relativa'.")

            st.markdown("#### 3) Se√±ales sin apoyo (precio avanza, presi√≥n va en contra)")
            if "pre_sin_apoyo" in df_known.columns:
                tmp = df_known.copy()
                tmp["Sin apoyo"] = np.where(tmp["pre_sin_apoyo"] == True, "S√≠", "No")
                tbl = group_metrics(tmp, "Sin apoyo", min_trades=min_trades, recommended_trades=recommended_trades)
                st.dataframe(tbl, use_container_width=True)

                # Consejos r√°pidos
                if not tbl.empty and "Grupo" in tbl.columns:
                    row_si = tbl[tbl["Grupo"] == "S√≠"]
                    row_no = tbl[tbl["Grupo"] == "No"]
                    if not row_si.empty and not row_no.empty:
                        exp_si = float(row_si.iloc[0]["Promedio por trade"])
                        exp_no = float(row_no.iloc[0]["Promedio por trade"])
                        if exp_si < exp_no:
                            st.warning("‚ö†Ô∏è Tus trades marcados como 'Sin apoyo = S√≠' rinden peor en promedio. Buen candidato para FILTRAR.")
                        else:
                            st.info("üü° Por ahora 'Sin apoyo' no empeora rendimiento, pero confirma con m√°s muestra.")
            else:
                st.info("No se detecta la bandera 'pre_sin_apoyo' (requiere arrays + dir).")

            st.markdown("### Pistas pr√°cticas (tuning)")
            st.write("‚úÖ Si **Actividad alta** + buen PF ‚Üí suele indicar entradas con participaci√≥n real.")
            st.write("üö´ Si **Absorci√≥n muy alta** + PF<1 ‚Üí suele ser 'lucha' / absorci√≥n antes del giro (candidato a evitar).")
            st.write("‚ö†Ô∏è Si 'Sin apoyo = S√≠' aparece mucho en p√©rdidas ‚Üí evita perseguir precio cuando el delta no acompa√±a.")


# ============================================================
# Hours
# ============================================================
st.subheader("‚è∞ Horarios (justo y confiable)")

hour_tbl = plot_hour_analysis(t, min_trades=min_trades)
plot_heatmap_weekday_hour(t, min_trades=min_trades)

st.markdown("### üß† Consejos autom√°ticos (Horarios)")
if hour_tbl is None or hour_tbl.empty:
    st.info("No hay datos suficientes por hora con el m√≠nimo configurado.")
else:
    best = hour_tbl.iloc[0]
    worst = hour_tbl.iloc[-1]

    st.info(
        f"üèÜ Hora recomendada: **{best['Grupo']}** | Trades={int(best['Trades'])} | "
        f"{traffic_pf(best['Profit Factor'])} | {traffic_exp(best['Promedio por trade'])}"
    )
    if best["Trades"] < min_trades * 2:
        st.warning("‚ö†Ô∏è La mejor hora a√∫n tiene muestra peque√±a. Confirma con m√°s logs.")

    if not np.isnan(worst["Profit Factor"]) and worst["Profit Factor"] < 1.0:
        st.warning(f"üö´ Hora candidata a evitar: **{worst['Grupo']}** (PF < 1 y promedio bajo).")

    st.caption("Regla de oro: prefiere horas con buen Score ponderado + buen PF + buena muestra, no solo winrate.")

# ============================================================
# ============================================================
# Entradas por d√≠a y orden del trade (tuning realista)
# ============================================================
st.subheader("üìÖ Entradas por d√≠a y orden del trade")
st.caption("Aqu√≠ miramos **cu√°ntas entradas haces por d√≠a** y si el **trade #1 / #2 / #3...** suele ser mejor o peor. "
           "Sirve para decisiones realistas como **MaxSetupsPerSession**, evitar el 'revenge trade' y cortar d√≠as malos.")

if "entry_time" in t.columns and t["entry_time"].notna().any():
    te = t.copy()
    te = te[te["entry_time"].notna()].copy()
    te = te.sort_values("entry_time").reset_index(drop=True)
    te["entry_date"] = te["entry_time"].dt.date
    te["entry_hour"] = te["entry_time"].dt.hour

    # Trades por d√≠a
    per_day = (te.groupby("entry_date", as_index=False)
                 .agg(trades=("tradeRealized","size"),
                      pnl=("tradeRealized","sum"),
                      winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    colA, colB, colC, colD = st.columns(4)
    colA.metric("Promedio trades / d√≠a", f"{per_day['trades'].mean():.2f}" if len(per_day) else "N/A")
    colB.metric("M√°ximo trades en un d√≠a", f"{int(per_day['trades'].max())}" if len(per_day) else "N/A")
    colC.metric("D√≠as con 3+ trades", f"{int((per_day['trades']>=3).sum())}" if len(per_day) else "0")
    colD.metric("D√≠as totales", f"{len(per_day)}")

    c1, c2 = st.columns([1,1])
    n_days = len(per_day)
    with c1:
        if n_days > 90:
            dist = per_day.groupby("trades", as_index=False).size().rename(columns={"size":"dias"})
            fig = px.bar(dist, x="trades", y="dias", title="Distribuci√≥n: # trades por d√≠a")
            fig.update_layout(xaxis_title="# trades en el d√≠a", yaxis_title="D√≠as")
            st.plotly_chart(fig, use_container_width=True)
            st.caption("Con muchos d√≠as, esta distribuci√≥n suele ser m√°s √∫til que una barra por fecha.")
        else:
            fig = px.bar(per_day, x="entry_date", y="trades", title="Trades por d√≠a")
            fig.update_layout(xaxis_title="D√≠a", yaxis_title="Trades")
            st.plotly_chart(fig, use_container_width=True)
    with c2:
        fig = px.scatter(per_day, x="trades", y="pnl",
                         title="¬øM√°s trades = mejor d√≠a? (PnL d√≠a vs # trades)",
                         hover_data=["entry_date","winrate"])
        fig.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="PnL del d√≠a ($)")
        st.plotly_chart(fig, use_container_width=True)

        by_n = (per_day.groupby("trades", as_index=False)
                    .agg(dias=("entry_date","size"),
                         pnl_prom=("pnl","mean"),
                         pnl_med=("pnl","median")))
        fig2 = px.bar(by_n, x="trades", y="pnl_prom", color="pnl_prom",
                      color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                      title="Promedio PnL del d√≠a por # trades")
        fig2.update_layout(xaxis_title="# trades del d√≠a", yaxis_title="Promedio PnL del d√≠a ($)")
        st.plotly_chart(fig2, use_container_width=True)

        try:
            mean_12 = by_n[by_n["trades"].isin([1,2])]["pnl_prom"].mean()
            mean_3p = by_n[by_n["trades"]>=3]["pnl_prom"].mean()
            n_3p_days = int(by_n[by_n["trades"]>=3]["dias"].sum()) if len(by_n[by_n["trades"]>=3]) else 0
            if pd.notna(mean_12) and pd.notna(mean_3p) and n_3p_days >= 5 and mean_3p < mean_12:
                st.warning("‚ö†Ô∏è En esta muestra, los d√≠as con **3+ trades** rinden peor en promedio. "
                           "Prueba en el Lab **M√°x trades/d√≠a = 2** o **MaxSetupsPerSession=2**.")
        except Exception:
            pass

    # Orden del trade dentro del d√≠a
    te["trade_num_day"] = te.groupby("entry_date").cumcount() + 1
    te["orden_trade"] = te["trade_num_day"].apply(lambda n: "1¬∫" if n==1 else ("2¬∫" if n==2 else ("3¬∫" if n==3 else "4¬∫+")))

    # Resumen por orden
    def _pf(sub):
        return profit_factor(sub) if len(sub) else np.nan

    by_order = (te.groupby("orden_trade", as_index=False)
                  .agg(trades=("tradeRealized","size"),
                       pnl_prom=("tradeRealized","mean"),
                       pnl_med=("tradeRealized","median"),
                       winrate=("tradeRealized", lambda s: float((s>0).mean()*100) if len(s) else np.nan)))
    # PF por orden
    pf_map = {k:_pf(v) for k,v in te.groupby("orden_trade")}
    by_order["pf"] = by_order["orden_trade"].map(pf_map)

    # Orden de presentaci√≥n
    orden_cat = ["1¬∫","2¬∫","3¬∫","4¬∫+"]
    by_order["orden_trade"] = pd.Categorical(by_order["orden_trade"], categories=orden_cat, ordered=True)
    by_order = by_order.sort_values("orden_trade")

    st.markdown("### üîé ¬øCu√°l trade del d√≠a suele ser el peor?")
    st.write("Si ves que **#3 o #4+** baja fuerte (PF<1 o promedio<0), suele ser se√±al de **sobre-trading**.")
    st.dataframe(by_order, use_container_width=True, hide_index=True)

    # Consejos r√°pidos por orden (con muestra m√≠nima)
    try:
        bo = by_order.copy()
        bo["orden_trade"] = bo["orden_trade"].astype(str)
        # Elegimos "peor" por promedio (y PF si existe)
        bo_sort = bo.sort_values(["pnl_prom"], ascending=True)
        worst_row = bo_sort.iloc[0] if len(bo_sort) else None
        if worst_row is not None and int(worst_row["trades"]) >= max(5, min_trades):
            if float(worst_row["pnl_prom"]) < 0:
                st.warning(f"‚ö†Ô∏è El **{worst_row['orden_trade']} trade** es el m√°s flojo en esta muestra "
                           f"(prom={float(worst_row['pnl_prom']):.0f}$, PF={float(worst_row['pf']):.2f}). "
                           "Candidato a **limitar setups** o a subir confirmaci√≥n despu√©s de 1‚Äì2 trades.")
        # Si 4¬∫+ existe y es negativo con algo de muestra
        row4 = bo[bo["orden_trade"]=="4¬∫+"]
        if len(row4) and int(row4.iloc[0]["trades"]) >= max(5, min_trades) and float(row4.iloc[0]["pnl_prom"]) < 0:
            st.warning("üö´ Los trades **4¬∫+** salen negativos en promedio con muestra suficiente: "
                       "muy t√≠pico de **sobre-trading**. Prueba **MaxSetupsPerSession=2** o **M√°x trades/d√≠a=2** en el Lab.")
    except Exception:
        pass

    fig = px.bar(by_order, x="orden_trade", y="pnl_prom", color="pnl_prom",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=0,
                 title="Promedio por trade seg√∫n orden en el d√≠a")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Promedio PnL por trade ($)")
    st.plotly_chart(fig, use_container_width=True)

    fig = px.bar(by_order, x="orden_trade", y="pf", color="pf",
                 color_continuous_scale="RdYlGn", color_continuous_midpoint=1.0,
                 title="Profit Factor seg√∫n orden en el d√≠a")
    fig.add_hline(y=1.0, line_dash="dash")
    fig.update_layout(xaxis_title="Orden del trade en el d√≠a", yaxis_title="Profit Factor")
    st.plotly_chart(fig, use_container_width=True)

    # Heatmap: hora vs orden (promedio y conteo)
    st.markdown("### üïí Hora de entrada vs orden del trade")
    st.write("√ötil para detectar cosas tipo: **'el 2¬∫ trade despu√©s de cierta hora es malo'**.")
    tmp = te.copy()
    tmp["h"] = tmp["entry_hour"].astype("Int64")
    tmp["ord"] = tmp["orden_trade"].astype(str)
    pivot_mean = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="mean")
    pivot_n = tmp.pivot_table(index="ord", columns="h", values="tradeRealized", aggfunc="size")

    # Solo mostramos si hay algo
    if pivot_mean.notna().sum().sum() > 0:
        # Formatear horas como HH:00 para que el eje sea legible (y no salga 9.5, 10.5, etc.)
        pivot_mean = pivot_mean.sort_index(axis=1)
        pivot_n = pivot_n.reindex(columns=pivot_mean.columns)

        hour_labels = [f"{int(h):02d}:00" for h in pivot_mean.columns]
        pivot_mean.columns = hour_labels
        pivot_n.columns = hour_labels

        # Texto dentro de cada celda: "promedio (n=..)"
        text = pivot_mean.copy()
        for r in text.index:
            for c in text.columns:
                a = pivot_mean.loc[r, c]
                n = pivot_n.loc[r, c]
                if pd.isna(a) or pd.isna(n) or n == 0:
                    text.loc[r, c] = ""
                else:
                    text.loc[r, c] = f"{a:.0f} (n={int(n)})"

        try:
            fig = px.imshow(
                pivot_mean,
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                aspect="auto",
            )
            fig.update_traces(
                text=text,
                texttemplate="%{text}",
                customdata=pivot_n.values,
                hovertemplate="Hora: %{x}<br>Orden: %{y}<br>Promedio: %{z:.0f}$<br>n=%{customdata}<extra></extra>",
            )
            fig.update_layout(
                title="Heatmap (promedio PnL $) ‚Äî muestra por celda",
                xaxis_title="Hora (entrada)",
                yaxis_title="Orden del trade",
            )
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.info("Tu versi√≥n de Plotly no soporta este heatmap con texto. (No afecta el an√°lisis.)")
    else:
        st.info("No hay suficientes datos con hora de entrada para el heatmap.")
else:
    st.info("No hay entry_time en los datos (faltan logs ENTRY). Esta secci√≥n necesita ENTRY.")

# ============================================================
# üß™ Lab: Simulador de reglas diarias y filtros (tuning realista)
# ============================================================
st.subheader("üß™ Lab: Simulador de reglas diarias y filtros")
st.caption("Simula reglas reales: **MaxLoss/MaxProfit por d√≠a**, **m√°ximo trades por d√≠a**, **racha de p√©rdidas**, y filtros (OR/EWO/ATR/Absorci√≥n/Actividad). "
           "La simulaci√≥n es 'what-if': te dice c√≥mo habr√≠a cambiado tu curva con esas reglas.")
def _hour_label(h: int) -> str:
    """Etiqueta humana para una hora completa (ej: 9:00‚Äì9:59 AM)."""
    h = int(h)
    ampm = "AM" if h < 12 else "PM"
    h12 = h % 12
    if h12 == 0:
        h12 = 12
    return f"{h12}:00‚Äì{h12}:59 {ampm}"

def _finite_minmax(s: pd.Series):
    s2 = pd.to_numeric(s, errors="coerce")
    s2 = s2[np.isfinite(s2)]
    if s2.empty:
        return None, None
    return float(s2.min()), float(s2.max())



def _lab_quick_suggestions(t: pd.DataFrame, min_bucket: int = 5) -> dict:
    """Heur√≠sticas r√°pidas basadas en tu historial REAL (no simulado).
    Devuelve un dict con llaves opcionales:
      - max_intraday_loss, max_intraday_profit (en $) para que NO corte nada
      - best_hour, worst_hour (int 0..23) por promedio PnL/trade (con muestra >= min_bucket)
      - rec_max_trades (int) sugerencia de m√°ximo trades/d√≠a (si se ve deterioro)
      - rec_max_consec_losses (int) p75 de racha de p√©rdidas por d√≠a
      - dir_stats (df) resumen Long/Short
    Nunca debe lanzar excepci√≥n; si falta data, devuelve {}.
    """
    out = {}
    try:
        if t is None or t.empty:
            return out

        df = t.copy()

        # PnL por trade
        if "tradeRealized" not in df.columns:
            return out
        df["tradeRealized"] = pd.to_numeric(df["tradeRealized"], errors="coerce")

        # Timestamp por trade (ENTRY preferido; si falta, EXIT como respaldo)
        ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
        ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)
        ts = ts_entry.fillna(ts_exit)

        df["_ts"] = ts
        df = df[df["_ts"].notna() & df["tradeRealized"].notna()].copy()
        if df.empty:
            return out

        df["day"] = df["_ts"].dt.date
        df["hour"] = df["_ts"].dt.hour

        # Baseline de reglas para NO cortar nada (por pnl diario total)
        per_day = df.groupby("day", as_index=False)["tradeRealized"].sum().rename(columns={"tradeRealized": "pnl_day"})
        if not per_day.empty:
            min_day = float(per_day["pnl_day"].min())
            max_day = float(per_day["pnl_day"].max())
            out["max_intraday_loss"] = abs(min_day) if min_day < 0 else 0.0
            out["max_intraday_profit"] = max_day if max_day > 0 else 0.0

        # Mejor / peor hora por promedio (si hay muestra)
        by_h = (df.groupby("hour")["tradeRealized"]
                  .agg(["size", "mean"])
                  .rename(columns={"size": "n", "mean": "mean_pnl"}))
        by_h = by_h[by_h["n"] >= int(min_bucket)]
        if len(by_h) >= 2:
            out["best_hour"] = int(by_h["mean_pnl"].idxmax())
            out["worst_hour"] = int(by_h["mean_pnl"].idxmin())

        # ¬øSe deteriora por trade # dentro del d√≠a?
        df = df.sort_values(["day", "_ts"])
        df["trade_num_day"] = df.groupby("day").cumcount() + 1
        by_k = (df.groupby("trade_num_day")["tradeRealized"]
                  .agg(["size", "mean"])
                  .rename(columns={"size": "n", "mean": "mean_pnl"}))
        # buscamos el primer k (>=2) con media negativa y muestra suficiente
        cand = by_k[(by_k.index >= 2) & (by_k["n"] >= int(min_bucket)) & (by_k["mean_pnl"] < 0)]
        if not cand.empty:
            k = int(cand.index.min())
            out["rec_max_trades"] = max(1, k - 1)

        # Racha de p√©rdidas seguidas por d√≠a (p75 de max racha diaria)
        def _max_streak_losses(s: pd.Series) -> int:
            x = (s < 0).astype(int).values
            best = cur = 0
            for v in x:
                if v == 1:
                    cur += 1
                    best = max(best, cur)
                else:
                    cur = 0
            return int(best)

        streaks = df.groupby("day")["tradeRealized"].apply(_max_streak_losses)
        if len(streaks) > 0:
            p75 = float(np.nanpercentile(streaks.values, 75))
            out["rec_max_consec_losses"] = int(max(1, round(p75)))

        # Long / Short stats si existe dir
        if "dir" in t.columns:
            d2 = t.copy()
            d2["tradeRealized"] = pd.to_numeric(d2["tradeRealized"], errors="coerce")
            d2 = d2[d2["tradeRealized"].notna()]
            d2["side"] = d2["dir"].apply(lambda v: "Long" if str(v).strip() in ("1", "Long", "LONG") else ("Short" if str(v).strip() in ("-1", "Short", "SHORT") else "Unknown"))
            ds = d2[d2["side"].isin(["Long", "Short"])].groupby("side")["tradeRealized"].agg(["size", "mean", "median"])
            if not ds.empty:
                out["dir_stats"] = ds
    except Exception:
        return {}
    return out


def _apply_filters(df_in: pd.DataFrame):
    """
    Lab filters (opcional) aplicados ANTES de simular reglas diarias.
    Devuelve: (df_filtrado, notas:list[str])
    """
    df = df_in.copy()
    notes: list[str] = []

    # --- toggle: incluir trades con datos faltantes (NaN) ---
    include_missing = bool(st.session_state.get("lab_include_missing", True))

    # --- timestamp por fila para filtrar horas (ENTRY preferido, si no EXIT) ---
    ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
    ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)

    df["_lab_ts"] = ts_entry
    # fallback a EXIT solo para filas sin ENTRY
    df.loc[df["_lab_ts"].isna(), "_lab_ts"] = ts_exit[df["_lab_ts"].isna()]
    df["_lab_hour"] = pd.to_datetime(df["_lab_ts"], errors="coerce").dt.hour

    # horas disponibles seg√∫n dataset (si no hay nada, 0..23)
    avail_hours = sorted([int(x) for x in df["_lab_hour"].dropna().unique().tolist()])
    if len(avail_hours) == 0:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours] if "_hour_label" in globals() else [f"{h:02d}:00‚Äì{h:02d}:59" for h in avail_hours]
    label_to_hour = {lab: h for lab, h in zip(hour_labels, avail_hours)}

    # --- helper UI: slider rango basado en min/max del dataset ---
    def _range_slider_for(col: str, key: str, title: str, unit_hint: str = ""):
        if col not in df.columns:
            return None
        lo0, hi0 = _finite_minmax(df[col]) if "_finite_minmax" in globals() else (None, None)
        if lo0 is None or hi0 is None:
            return None
        # default: rango completo (no filtra)
        default = st.session_state.get(key, (float(lo0), float(hi0)))
        try:
            default = (float(default[0]), float(default[1]))
        except Exception:
            default = (float(lo0), float(hi0))

        step = max((float(hi0) - float(lo0)) / 200.0, 0.01)
        label = f"{title}" + (f" ({unit_hint})" if unit_hint else "")
        rng = st.slider(label, float(lo0), float(hi0), default, step=step, key=key)
        return rng

    # --- helper: aplicar rango inclusivo (con opci√≥n de incluir NaN) ---
    def _apply_range_mask(dfx: pd.DataFrame, col: str, rng):
        if col not in dfx.columns or rng is None:
            return dfx
        lo, hi = rng
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = (s >= float(lo)) & (s <= float(hi))
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- helper: threshold m√≠nimo (>=) ---
    def _apply_min_mask(dfx: pd.DataFrame, col: str, thr):
        if col not in dfx.columns or thr is None:
            return dfx
        s = pd.to_numeric(dfx[col], errors="coerce")
        mask = s >= float(thr)
        if include_missing:
            mask = mask | s.isna()
        return dfx[mask].copy()

    # --- UI ---
    with st.container():
        st.markdown("### Filtros (opcional)")
        st.caption("Estos filtros afectan **solo** la simulaci√≥n. En Reset no deber√≠an eliminar nada.")

        include_missing = st.checkbox(
            "Incluir trades con datos faltantes (NaN) en filtros (recomendado)",
            value=include_missing,
            key="lab_include_missing",
            help="Si un trade no tiene ENTRY (o alg√∫n indicador), aparecer√° como 'Sin datos'. Activado = no se excluye por defecto."
        )

        # Direcci√≥n (Compra/Venta)
        dir_col = None
        for c in ["dir", "tradeDirection", "direction"]:
            if c in df.columns:
                dir_col = c
                break

        if dir_col:
            dnum = pd.to_numeric(df[dir_col], errors="coerce")
        else:
            dnum = pd.Series(np.nan, index=df.index)

        is_long = dnum > 0
        is_short = dnum < 0
        is_unknown = dnum.isna() | (dnum == 0)

        dir_opts = ["Venta", "Compra", "No definida"]
        # Sanear defaults guardados de versiones anteriores
        _dir_raw = st.session_state.get("lab_dirs_allowed", dir_opts)
        if not isinstance(_dir_raw, (list, tuple)):
            _dir_raw = dir_opts
        _map_dir = {
            "Largos": "Compra",
            "Long": "Compra",
            "Longs": "Compra",
            "Cortos": "Venta",
            "Short": "Venta",
            "Shorts": "Venta",
            "Sin datos": "No definida",
            "Sin datos (falt√≥ ENTRY)": "No definida",
            "Sin datos (falt√≥ Entry)": "No definida",
            "Sin datos (falt√≥ entry)": "No definida",
            "No definida": "No definida",
            "Compra": "Compra",
            "Venta": "Venta",
        }
        _dir_sane = []
        for v in _dir_raw:
            v2 = _map_dir.get(str(v), None)
            if v2 in dir_opts and v2 not in _dir_sane:
                _dir_sane.append(v2)
        if not _dir_sane:
            _dir_sane = dir_opts.copy()
        st.session_state["lab_dirs_allowed"] = _dir_sane
        sel_dirs = st.multiselect("Direcci√≥n permitida", dir_opts, default=_dir_sane, key="lab_dirs_allowed")        # Horas (entry preferido)
        _h_raw = st.session_state.get("lab_hours_allowed", hour_labels)
        if not isinstance(_h_raw, (list, tuple)):
            _h_raw = hour_labels
        _h_sane = [h for h in _h_raw if h in hour_labels]
        if not _h_sane:
            _h_sane = hour_labels.copy()
        st.session_state["lab_hours_allowed"] = _h_sane
        sel_hour_labels = st.multiselect(
            "Horas permitidas (entrada)",
            options=hour_labels,
            default=_h_sane,
            key="lab_hours_allowed",
            help="Cada hora representa el bloque completo HH:00‚ÄìHH:59. Si falta ENTRY, se usa EXIT como respaldo."
        )
        sel_hours = [label_to_hour[x] for x in sel_hour_labels if x in label_to_hour]

        # Rangos (si existen columnas)
        or_rng = _range_slider_for("orSize", "lab_or_rng", "OR Size permitido", unit_hint="(seg√∫n tu log)")
        atr_rng = _range_slider_for("atr", "lab_atr_rng", "ATR permitido", unit_hint="(seg√∫n tu log)")

    # --- aplicar filtros ---
    # Direcci√≥n
    dir_mask = pd.Series(False, index=df.index)
    if "Compra" in sel_dirs:
        dir_mask |= is_long
    if "Venta" in sel_dirs:
        dir_mask |= is_short
    if "No definida" in sel_dirs:
        dir_mask |= is_unknown
    if dir_mask.any():
        df = df[dir_mask].copy()
    else:
        notes.append("‚ö†Ô∏è No seleccionaste ninguna direcci√≥n; se ignora el filtro de direcci√≥n.")

    # Horas
    if len(sel_hours) > 0 and "_lab_hour" in df.columns:
        h = pd.to_numeric(df["_lab_hour"], errors="coerce")
        hmask = h.isin(sel_hours)
        if include_missing:
            hmask = hmask | h.isna()
        df = df[hmask].copy()

    # Rangos
    df = _apply_range_mask(df, "orSize", or_rng)
    df = _apply_range_mask(df, "atr", atr_rng)

    return df, notes


def _simulate_daily_rules(df_in: pd.DataFrame,
                          max_loss: float = 0.0,
                          max_profit: float = 0.0,
                          max_trades: int = 0,
                          max_consec_losses: int = 0,
                          stop_big_loss: bool = False,
                          stop_big_win: bool = False):
    """
    Simula reglas tipo 'Daily Guard' sobre un dataframe ya filtrado.

    - max_loss: corta el d√≠a cuando el PnL acumulado <= -max_loss (0 = sin l√≠mite)
    - max_profit: corta el d√≠a cuando el PnL acumulado >= max_profit (0 = sin l√≠mite)
    - max_trades: corta el d√≠a tras N trades ejecutados (0 = sin l√≠mite)
    - max_consec_losses: corta el d√≠a tras N p√©rdidas seguidas (0 = sin l√≠mite)
    - stop_big_loss: corta el d√≠a despu√©s de un trade con RR <= -1
    - stop_big_win: corta el d√≠a despu√©s de un trade con RR >= 2

    Devuelve:
      sim_kept: trades que ‚Äúquedar√≠an‚Äù tras aplicar reglas (incluye el trade que gatilla el corte)
      stops_df: una fila por d√≠a cortado con m√©tricas b√°sicas (para explicar impacto)
    """
    if df_in is None or df_in.empty:
        return (pd.DataFrame() if df_in is None else df_in.copy()), pd.DataFrame()

    df = df_in.copy()

    # Columna de tiempo para ordenar (ENTRY preferido; fallback EXIT)
    ts_entry = pd.to_datetime(df["entry_time"], errors="coerce") if "entry_time" in df.columns else pd.Series(pd.NaT, index=df.index)
    ts_exit  = pd.to_datetime(df["exit_time"],  errors="coerce") if "exit_time"  in df.columns else pd.Series(pd.NaT, index=df.index)

    df["_sim_ts"] = ts_entry
    df.loc[df["_sim_ts"].isna(), "_sim_ts"] = ts_exit[df["_sim_ts"].isna()]

    # Trades sin timestamp: no se pueden agrupar por d√≠a -> se conservan tal cual
    df_valid = df[df["_sim_ts"].notna()].copy()
    df_other = df[df["_sim_ts"].isna()].copy()

    if df_valid.empty:
        sim_kept = df_other.copy()
        sim_kept.drop(columns=["_sim_ts"], errors="ignore", inplace=True)
        return sim_kept, pd.DataFrame()

    df_valid = df_valid.sort_values("_sim_ts").copy()
    df_valid["day"] = df_valid["_sim_ts"].dt.date

    # Normaliza n√∫meros
    if "tradeRealized" in df_valid.columns:
        df_valid["tradeRealized"] = pd.to_numeric(df_valid["tradeRealized"], errors="coerce").fillna(0.0).astype(float)
    else:
        df_valid["tradeRealized"] = 0.0

    rr_series = pd.to_numeric(df_valid["rr"], errors="coerce") if "rr" in df_valid.columns else pd.Series(np.nan, index=df_valid.index)

    kept_idx = []
    stop_rows = []

    max_loss = float(max_loss or 0.0)
    max_profit = float(max_profit or 0.0)
    max_trades = int(max_trades or 0)
    max_consec_losses = int(max_consec_losses or 0)

    for d, sub in df_valid.groupby("day", sort=True):
        sub = sub.sort_values("_sim_ts")
        total = int(len(sub))
        cum = 0.0
        consec = 0
        taken = 0
        cut_reason = None

        for i, (idx, row) in enumerate(sub.iterrows(), start=1):
            pnl = float(row.get("tradeRealized", 0.0) or 0.0)
            rr  = rr_series.loc[idx] if idx in rr_series.index else np.nan

            taken += 1
            cum += pnl
            if pnl < 0:
                consec += 1
            else:
                consec = 0

            kept_idx.append(idx)

            # Si ya no hay m√°s trades, no tiene sentido marcar corte
            has_more = taken < total

            if has_more and cut_reason is None:
                if max_trades > 0 and taken >= max_trades:
                    cut_reason = "M√°x trades/d√≠a"
                elif max_loss > 0 and cum <= -abs(max_loss):
                    cut_reason = "M√°x p√©rdida/d√≠a"
                elif max_profit > 0 and cum >= abs(max_profit):
                    cut_reason = "M√°x ganancia/d√≠a"
                elif max_consec_losses > 0 and consec >= max_consec_losses:
                    cut_reason = f"{max_consec_losses} p√©rdidas seguidas"
                elif bool(stop_big_loss) and np.isfinite(rr) and float(rr) <= -1.0:
                    cut_reason = "Stop‚Äëout fuerte (‚â§ -1R)"
                elif bool(stop_big_win) and np.isfinite(rr) and float(rr) >= 2.0:
                    cut_reason = "Ganador grande (‚â• 2R)"

            if cut_reason is not None:
                # Registramos el corte (el trade que gatilla el corte est√° incluido)
                stop_rows.append({
                    "fecha": d,
                    "day": d,
                    "motivo": cut_reason,
                    "trades_totales_dia": total,
                    "trades_ejecutados": taken,
                    "trades_filtrados_por_stop": int(total - taken),
                    "pnl_hasta_stop": float(cum),
                })
                break  # cortar el resto del d√≠a

    sim_kept_valid = df_valid.loc[kept_idx].copy() if kept_idx else df_valid.iloc[0:0].copy()
    sim_kept = pd.concat([sim_kept_valid, df_other], axis=0, ignore_index=False)

    # Limpieza auxiliares
    sim_kept.drop(columns=["_sim_ts"], errors="ignore", inplace=True)

    stops_df = pd.DataFrame(stop_rows)
    return sim_kept, stops_df


def _reset_lab_state(base_df: pd.DataFrame):
    """Resetea el Lab para que arranque 1:1 con el Resumen r√°pido (REAL vs SIMULADO sin cortes)."""
    if base_df is None:
        base_df = pd.DataFrame()

    # -------------------- Reglas (0 = sin l√≠mite) --------------------
    st.session_state["lab_max_loss"] = 0.0
    st.session_state["lab_max_profit"] = 0.0
    st.session_state["lab_max_trades"] = 0
    st.session_state["lab_max_consec_losses"] = 0
    st.session_state["lab_stop_big_loss"] = False
    st.session_state["lab_stop_big_win"] = False

    # -------------------- Helpers --------------------
    def _minmax(col: str, default=(0.0, 1.0)):
        if col in base_df.columns:
            mn, mx = _finite_minmax(base_df[col])
            if mn is None or mx is None:
                return default
            if mn == mx:
                # Evita sliders degenerados (mismo min/max)
                eps = 1e-9 if mn == 0 else abs(mn) * 1e-6
                return float(mn - eps), float(mx + eps)
            return float(mn), float(mx)
        return default

    def _min_abs(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            s = s.abs()
            return float(s.min())
        return default

    def _min_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.min())
        return default

    def _max_val(col: str, default=0.0):
        if col in base_df.columns:
            s = pd.to_numeric(base_df[col], errors="coerce")
            s = s[np.isfinite(s)]
            if s.empty:
                return default
            return float(s.max())
        return default

    # -------------------- Filtros (opcionales) --------------------
        # Horas disponibles desde tu dataset (ENTRY preferido, si falta usa EXIT)
    ts_entry = pd.to_datetime(base_df["entry_time"], errors="coerce") if "entry_time" in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_exit  = pd.to_datetime(base_df["exit_time"],  errors="coerce") if "exit_time"  in base_df.columns else pd.Series([pd.NaT]*len(base_df), index=base_df.index)
    ts_lab   = ts_entry.fillna(ts_exit)

    if ts_lab.notna().any():
        avail_hours = sorted([int(h) for h in ts_lab.dt.hour.dropna().unique().tolist()])
    else:
        avail_hours = list(range(24))
    if not avail_hours:
        avail_hours = list(range(24))

    hour_labels = [_hour_label(h) for h in avail_hours]
    st.session_state["lab_hours_allowed"] = hour_labels[:]
    st.session_state["lab_dirs_allowed"] = ["Venta", "Compra", "No definida"]
    st.session_state["lab_include_missing"] = True


    # Rangos num√©ricos -> por defecto NO filtra (rango completo / umbral m√≠nimo)
    st.session_state["lab_or_rng"] = _minmax("orSize")
    st.session_state["lab_atr_rng"] = _minmax("atr")



reset_col, reset_info = st.columns([1, 3])
with reset_col:
    if st.button("üîÑ Reset experimento", help="Resetea TODO (reglas sin l√≠mite + sin filtros) para que el Lab coincida 1:1 con el Resumen r√°pido."):
        _reset_lab_state(t)
with reset_info:
    st.caption("Idea: el Lab **empieza igual que el Resumen r√°pido**. Luego ajustas reglas/filtros para ver el impacto (what‚Äëif).")

lab_left, lab_right = st.columns([1, 1])

with lab_left:
    st.markdown("**Reglas diarias**")
    max_loss = st.number_input(
        "Max p√©rdida por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_loss", 0.0)), step=50.0,
        key="lab_max_loss",
        help="0 = sin l√≠mite. Si el d√≠a llega a -MaxLoss, se corta el trading del d√≠a."
    )
    max_profit = st.number_input(
        "Max ganancia por d√≠a ($)",
        min_value=0.0, value=float(st.session_state.get("lab_max_profit", 0.0)), step=100.0,
        key="lab_max_profit",
        help="0 = sin l√≠mite. Si el d√≠a llega a +MaxProfit, se corta el trading del d√≠a."
    )
    max_trades = st.slider("M√°x trades por d√≠a (0 = sin l√≠mite)", min_value=0, max_value=10,
                           value=int(st.session_state.get("lab_max_trades", 0)), key="lab_max_trades")
    max_consec_losses = st.slider("M√°x p√©rdidas seguidas (0 = sin l√≠mite)", min_value=0, max_value=10,
                                  value=int(st.session_state.get("lab_max_consec_losses", 0)), key="lab_max_consec_losses")
    stop_big_loss = st.checkbox("Cortar el d√≠a tras un stop-out fuerte (RR ‚â§ -1)", value=bool(st.session_state.get("lab_stop_big_loss", False)),
                                key="lab_stop_big_loss")
    stop_big_win = st.checkbox("Cortar el d√≠a tras un ganador grande (RR ‚â• 2)", value=bool(st.session_state.get("lab_stop_big_win", False)),
                               key="lab_stop_big_win")


    st.markdown("---")
    st.markdown("**üß≠ Sugerencias r√°pidas (seg√∫n tu historial real)**")
    sugg = _lab_quick_suggestions(t)
    if not sugg:
        st.info("No hay suficientes datos para sugerir reglas (o faltan timestamps/PnL).")
    else:
        # Valores "sin recortar" (sirven como baseline 1:1 aunque actives la regla)
        if ("max_intraday_loss" in sugg) or ("max_intraday_profit" in sugg):
            loss0 = sugg.get("max_intraday_loss", 0.0)
            prof0 = sugg.get("max_intraday_profit", 0.0)
            st.caption(f"Baseline 1:1: para que las reglas NO corten nada, usa Max p√©rdida/d√≠a ‚âà **{loss0:,.0f}** y Max ganancia/d√≠a ‚âà **{prof0:,.0f}** (o deja 0 = sin l√≠mite).")

        best_h = sugg.get("best_hour", None)
        worst_h = sugg.get("worst_hour", None)
        if best_h is not None and worst_h is not None:
            st.write(f"üïí Mejor hora promedio: **{_hour_label(best_h)}** | Peor: **{_hour_label(worst_h)}** (con muestra ‚â• {5}).")

        rec_mt = sugg.get("rec_max_trades", None)
        if rec_mt is not None and rec_mt >= 1:
            st.warning(f"üìâ A partir del trade #{rec_mt+1} el promedio suele volverse negativo. Prueba **M√°x trades/d√≠a = {rec_mt}**.", icon="‚ö†Ô∏è")
        else:
            st.write("üìå No se ve un deterioro claro por # de trade (con la muestra actual).")

        rec_streak = sugg.get("rec_max_consec_losses", None)
        if rec_streak is not None:
            rec_streak = max(1, int(rec_streak))
            st.write(f"üîÅ Racha t√≠pica (p75) de p√©rdidas seguidas por d√≠a: **{rec_streak}** ‚Üí prueba M√°x p√©rdidas seguidas = {rec_streak}.")

        if "dir_stats" in sugg and not sugg["dir_stats"].empty:
            ds = sugg["dir_stats"]
            try:
                long_mean = float(ds.loc["Long","mean"]) if "Long" in ds.index else np.nan
                short_mean = float(ds.loc["Short","mean"]) if "Short" in ds.index else np.nan
                st.write(f"üìä Long avg: **{long_mean:,.0f}** | Short avg: **{short_mean:,.0f}** (por trade).")
                if np.isfinite(long_mean) and np.isfinite(short_mean):
                    if long_mean > 0 and short_mean < 0:
                        st.warning("‚û°Ô∏è Considera filtrar **solo Long** en el Lab y ver el impacto.", icon="‚ö†Ô∏è")
                    elif short_mean > 0 and long_mean < 0:
                        st.warning("‚¨ÖÔ∏è Considera filtrar **solo Short** en el Lab y ver el impacto.", icon="‚ö†Ô∏è")
            except Exception:
                pass

        # RR-based suggestions
        if "after_stopout" in sugg:
            med, n = sugg["after_stopout"]
            if n >= 5 and np.isfinite(med) and med < 0:
                st.warning(f"üßØ Tras un stop-out fuerte (RR‚â§-1), el resto del d√≠a tiende a ser negativo (mediana {med:,.0f}, n={n}). Prueba activar esa regla.", icon="‚ö†Ô∏è")
        if "after_bigwin" in sugg:
            med, n = sugg["after_bigwin"]
            if n >= 5 and np.isfinite(med) and med < 0:
                st.warning(f"üèÜ Tras un ganador grande (RR‚â•2), suele haber devoluci√≥n (mediana resto {med:,.0f}, n={n}). Prueba activar esa regla.", icon="‚ö†Ô∏è")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üöÄ Turbo Presets (A): lista de presets aplicables con 1 click
# Objetivo: sugerir combinaciones simples (filtros + reglas) y permitir aplicarlas.
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
with st.expander("üöÄ Turbo Optimus ‚Äî Presets inteligentes (Modo A / Modo B)", expanded=False):
    import time
    import random

    # -----------------------------
    # Turbo: qu√© hace (en 1 frase)
    # -----------------------------
    st.caption(
        "Turbo prueba combinaciones de reglas (horas / direcci√≥n / OR / ATR / l√≠mites diarios) y te devuelve presets listos para aplicar. "
        "T√∫ eliges el objetivo: üöÄ m√°s PnL, üõü menos DD, ‚öñÔ∏è mejor ratio PnL/DD o üß™ balance."
    )

    # -------------------------------------------------
    # Helpers: detectar columnas, filtrar y medir
    # -------------------------------------------------
    def _infer_col(df, candidates):
        if df is None or len(df) == 0:
            return None
        cols = {c.lower(): c for c in df.columns}
        for c in candidates:
            if c.lower() in cols:
                return cols[c.lower()]
        return None

    _COL_PNL = _infer_col(t, ["tradeRealized", "pnl", "profit", "realized"])
    _COL_DIR = _infer_col(t, ["dir", "entry_dir", "direction", "tradeDirection"])
    _COL_TS  = _infer_col(t, ["ts", "entry_ts", "time", "datetime", "timestamp"])
    _COL_HOUR = _infer_col(t, ["entry_hour", "hour", "hh", "hora"])
    _COL_DATE = _infer_col(t, ["entry_date", "date", "day"])
    _COL_OR  = _infer_col(t, ["or_size", "orSize", "openingRange", "or_range", "or"])
    _COL_ATR = _infer_col(t, ["atr", "ATR", "atr_value", "atrValue"])

    # Si no existe entry_hour, intentamos derivarlo desde ts
    def _ensure_entry_hour(df):
        if df is None or len(df) == 0:
            return df
        if _COL_HOUR is not None:
            return df
        if _COL_TS is None:
            return df
        try:
            dd = df.copy()
            dd["_entry_hour"] = pd.to_datetime(dd[_COL_TS]).dt.hour.astype(int)
            return dd
        except Exception:
            return df

    # Si no existe entry_date, intentamos derivarlo desde ts
    def _ensure_entry_date(df):
        if df is None or len(df) == 0:
            return df
        if _COL_DATE is not None:
            return df
        if _COL_TS is None:
            return df
        try:
            dd = df.copy()
            dd["_entry_date"] = pd.to_datetime(dd[_COL_TS]).dt.date
            return dd
        except Exception:
            return df

    def _dd_mag_from_pnl_series(pnl_series):
        if pnl_series is None or len(pnl_series) == 0:
            return 0.0
        eq = pnl_series.fillna(0.0).cumsum()
        run_max = eq.cummax()
        dd = (run_max - eq)
        dd_max = float(dd.max()) if len(dd) else 0.0
        if np.isnan(dd_max):
            dd_max = 0.0
        return dd_max

    def _compute_metrics(df_filtered):
        # pnl / dd / corr(pnl, dd_depth) + n
        if df_filtered is None or len(df_filtered) == 0 or _COL_PNL is None:
            return dict(n=0, pnl=0.0, dd=0.0, corr=np.nan, ratio=0.0)

        pnl_s = pd.to_numeric(df_filtered[_COL_PNL], errors="coerce").fillna(0.0)
        pnl = float(pnl_s.sum())
        dd = float(_dd_mag_from_pnl_series(pnl_s))

        # dd depth series
        eq = pnl_s.cumsum()
        run_max = eq.cummax()
        dd_depth = (run_max - eq)

        corr = np.nan
        try:
            if len(pnl_s) >= 8 and dd_depth.std() > 1e-9 and pnl_s.std() > 1e-9:
                corr = float(np.corrcoef(pnl_s.values, dd_depth.values)[0, 1])
        except Exception:
            corr = np.nan

        denom = max(dd, 1.0)  # evita dividir por 0
        ratio = float(pnl / denom)
        return dict(n=int(len(df_filtered)), pnl=pnl, dd=dd, corr=corr, ratio=ratio)

    def _hour_label(h):
        # 9 -> "9:00-9:59 AM" (portable: no %-I)
        h = int(h)
        h12 = h % 12
        h12 = 12 if h12 == 0 else h12
        ampm = "AM" if h < 12 else "PM"
        return f"{h12}:00-{h12}:59 {ampm}" 

    def _filter_df_params(df, params):
        # params keys:
        # max_trades_per_day, max_consecutive_losses, stop_after_big_loss, stop_after_big_win,
        # allowed_dirs, allowed_hours, or_range, atr_range
        if df is None or len(df) == 0:
            return df

        ddf = df.copy()
        ddf = _ensure_entry_hour(ddf)
        ddf = _ensure_entry_date(ddf)

        pnl_col = _COL_PNL
        if pnl_col is None:
            return ddf

        # Direcci√≥n
        if params.get("allowed_dirs") and _COL_DIR is not None:
            ddf = ddf[ddf[_COL_DIR].isin(params["allowed_dirs"])]

        # Horas
        if params.get("allowed_hours"):
            hour_col = _COL_HOUR if _COL_HOUR is not None else ("_entry_hour" if "_entry_hour" in ddf.columns else None)
            if hour_col is not None:
                ddf = ddf[ddf[hour_col].isin(params["allowed_hours"])]

        # OR range
        if params.get("or_range") and _COL_OR is not None:
            lo, hi = params["or_range"]
            ddf = ddf[(ddf[_COL_OR] >= lo) & (ddf[_COL_OR] <= hi)]

        # ATR range
        if params.get("atr_range") and _COL_ATR is not None:
            lo, hi = params["atr_range"]
            ddf = ddf[(ddf[_COL_ATR] >= lo) & (ddf[_COL_ATR] <= hi)]

        # Daily guard: max trades/day + max losses seguidas + stop after big loss/win
        date_col = _COL_DATE if _COL_DATE is not None else ("_entry_date" if "_entry_date" in ddf.columns else None)
        if date_col is None:
            return ddf

        if any([
            (params.get("max_trades_per_day", 0) or 0) > 0,
            (params.get("max_consecutive_losses", 0) or 0) > 0,
            params.get("stop_after_big_loss", False),
            params.get("stop_after_big_win", False),
        ]):
            max_trades = int(params.get("max_trades_per_day", 0) or 0)
            max_losses = int(params.get("max_consecutive_losses", 0) or 0)
            stop_big_loss = bool(params.get("stop_after_big_loss", False))
            stop_big_win = bool(params.get("stop_after_big_win", False))

            keep_idx = []
            for day, g in ddf.groupby(date_col):
                g2 = g.copy()
                g2 = g2.sort_index()

                kept = []
                losses_streak = 0
                trade_count = 0

                for idx, row in g2.iterrows():
                    trade_pnl = float(pd.to_numeric(row[pnl_col], errors="coerce") or 0.0)
                    is_win = trade_pnl > 0
                    is_loss = trade_pnl < 0

                    if max_trades > 0 and trade_count >= max_trades:
                        break

                    if max_losses > 0:
                        if is_loss:
                            losses_streak += 1
                        else:
                            losses_streak = 0
                        if losses_streak > max_losses:
                            break

                    kept.append(idx)
                    trade_count += 1

                    if stop_big_loss and trade_pnl <= -1.0:
                        break
                    if stop_big_win and trade_pnl >= 2.0:
                        break

                keep_idx.extend(kept)

            ddf = ddf.loc[keep_idx]

        return ddf

    # ---------------------------------------
    # Base (sin cortar) para comparaciones
    # ---------------------------------------
    def _build_base_preset(df_real):
        # Ojo: esto NO toca horas/dir/OR/ATR. Solo "guardrails" gigantes para no cortar nada.
        max_day_loss = 0
        max_day_profit = 0

        # Si tienes columnas diarias de PnL en otro lado, perfecto; aqu√≠ lo dejamos "sin l√≠mites".
        return dict(
            _label="Baseline (sin cortar)",
            max_trades_per_day=0,
            max_consecutive_losses=0,
            stop_after_big_loss=False,
            stop_after_big_win=False,
            allowed_dirs=None,
            allowed_hours=None,
            or_range=None,
            atr_range=None,
            _meta="Baseline: sin l√≠mites (0 = sin l√≠mite)."
        )

    df_real = t.copy()
    df_real = _ensure_entry_hour(_ensure_entry_date(df_real))

    base_params = _build_base_preset(df_real)
    df_base = _filter_df_params(df_real, base_params)
    base_m = _compute_metrics(df_base)

    # ---------------------------------------
    # Candidatos (grid) ‚Äî Modo A y Modo B
    # ---------------------------------------
    def _direction_candidates():
        # valores reales que existen
        if _COL_DIR is None:
            return [None]
        vals = list(pd.Series(df_real[_COL_DIR]).dropna().unique())
        # si el log usa Compra/Venta/No definida, mantenlo
        cands = [None]
        if "Compra" in vals and "Venta" in vals:
            cands += [["Compra"], ["Venta"], ["Compra", "Venta"]]
        else:
            # fallback: usa valores existentes
            if len(vals) >= 1:
                cands += [[vals[0]]]
            if len(vals) >= 2:
                cands += [[vals[1]]]
            if len(vals) > 2:
                cands += [vals]
        return cands

    def _hours_candidates(mode="A"):
        hour_col = _COL_HOUR if _COL_HOUR is not None else ("_entry_hour" if "_entry_hour" in df_real.columns else None)
        if hour_col is None:
            return [None]

        g = df_real.copy()
        pnl = pd.to_numeric(g[_COL_PNL], errors="coerce").fillna(0.0)
        g["_pnl"] = pnl
        grp = g.groupby(hour_col)["_pnl"].agg(["count", "mean"]).reset_index()
        grp = grp[grp["count"] >= (5 if mode == "A" else 8)]
        if len(grp) == 0:
            return [None]

        grp = grp.sort_values("mean", ascending=False)
        top_hours = [int(x) for x in grp[hour_col].head(6 if mode == "A" else 10).tolist()]
        # candidates: 1 bloque, 2 bloques, 3 bloques (top)
        cands = [None]
        cands += [[h] for h in top_hours[:4]]
        if len(top_hours) >= 2:
            cands += [top_hours[:2], top_hours[:3]]
        return cands

    def _range_candidates(colname, mode="A"):
        if colname is None:
            return [None]
        s = pd.to_numeric(df_real[colname], errors="coerce").dropna()
        if len(s) < 30:
            return [None]
        qs = [0.05, 0.15, 0.25, 0.35, 0.50, 0.65, 0.75, 0.85, 0.95]
        qv = s.quantile(qs).values.tolist()
        qv = sorted(list({float(x) for x in qv if not np.isnan(x)}))
        if len(qv) < 4:
            return [None]
        pairs = []
        step = 2 if mode == "A" else 1
        for i in range(0, len(qv)-2, step):
            lo = qv[i]
            hi = qv[min(i+2, len(qv)-1)]
            if hi > lo:
                pairs.append((lo, hi))
        # a√±ade un rango "medio" m√°s amplio
        mid_lo = qv[max(0, len(qv)//4)]
        mid_hi = qv[min(len(qv)-1, 3*len(qv)//4)]
        if mid_hi > mid_lo:
            pairs.insert(0, (mid_lo, mid_hi))
        # sin duplicados
        seen = set()
        out = [None]
        for p in pairs:
            key = (round(p[0], 6), round(p[1], 6))
            if key not in seen:
                seen.add(key)
                out.append(p)
        return out[:(8 if mode == "A" else 18)]

    def _build_grid(mode="A"):
        dirs = _direction_candidates()
        hours = _hours_candidates(mode=mode)
        or_ranges = _range_candidates(_COL_OR, mode=mode)
        atr_ranges = _range_candidates(_COL_ATR, mode=mode)

        # l√≠mites diarios
        max_trades = [0, 2, 3, 4] if mode == "A" else [0, 1, 2, 3, 4, 5]
        max_losses = [0, 1, 2, 3] if mode == "A" else [0, 1, 2, 3, 4]

        # stop rules (deja en A minimal; en B incluye)
        stop_big_loss = [False] if mode == "A" else [False, True]
        stop_big_win = [False] if mode == "A" else [False, True]

        return dict(
            max_trades=max_trades,
            max_losses=max_losses,
            stop_big_loss=stop_big_loss,
            stop_big_win=stop_big_win,
            dirs=dirs,
            hours=hours,
            or_ranges=or_ranges,
            atr_ranges=atr_ranges,
        )

    # ---------------------------------------
    # Scoring (objetivos)
    # ---------------------------------------
    def _score(metrics, objective):
        # objective: "pnl" | "dd" | "ratio" | "balance"
        pnl = metrics["pnl"]
        dd = metrics["dd"]
        ratio = metrics["ratio"]
        corr = metrics["corr"]
        abs_corr = abs(corr) if (corr is not None and not np.isnan(corr)) else 0.0

        if objective == "pnl":
            return pnl
        if objective == "dd":
            return -dd
        if objective == "ratio":
            return ratio
        # balance: ratio + bonus por mejoras vs baseline + penalizaci√≥n por corr extrema
        pnl_delta = pnl - base_m["pnl"]
        dd_delta = base_m["dd"] - dd  # positivo si mejora
        score = ratio
        score += 0.002 * pnl_delta
        score += 0.002 * dd_delta
        score -= 0.15 * abs_corr
        return score

    def _make_label(params):
        parts = []
        if params.get("allowed_dirs"):
            parts.append("Dir=" + "/".join(params["allowed_dirs"]))
        if params.get("allowed_hours"):
            parts.append("Hora=" + ",".join([_hour_label(h) for h in params["allowed_hours"]]))
        if params.get("or_range"):
            lo, hi = params["or_range"]
            parts.append(f"OR={lo:.2f}-{hi:.2f}")
        if params.get("atr_range"):
            lo, hi = params["atr_range"]
            parts.append(f"ATR={lo:.2f}-{hi:.2f}")
        mt = int(params.get("max_trades_per_day", 0) or 0)
        ml = int(params.get("max_consecutive_losses", 0) or 0)
        if mt > 0: parts.append(f"MaxT={mt}")
        if ml > 0: parts.append(f"MaxL={ml}")
        if params.get("stop_after_big_loss"): parts.append("CutSL‚úÖ")
        if params.get("stop_after_big_win"): parts.append("CutTP‚úÖ")
        return " ‚Ä¢ ".join(parts) if parts else "Sin filtros (baseline)"

    def _apply_to_lab(params):
        # Traduce params -> session_state keys de tu UI
        st.session_state["lab_max_trades"] = int(params.get("max_trades_per_day", 0) or 0)
        st.session_state["lab_max_consec_losses"] = int(params.get("max_consecutive_losses", 0) or 0)
        st.session_state["lab_stop_big_loss"] = bool(params.get("stop_after_big_loss", False))
        st.session_state["lab_stop_big_win"] = bool(params.get("stop_after_big_win", False))

        # estos widgets existen en el lab_right
        if params.get("allowed_dirs") is None:
            st.session_state["lab_dir_allowed"] = ["Venta", "Compra", "No definida"]
        else:
            st.session_state["lab_dir_allowed"] = params["allowed_dirs"]

        if params.get("allowed_hours") is None:
            st.session_state["lab_hours_allowed"] = []
        else:
            st.session_state["lab_hours_allowed"] = [_hour_label(h) for h in params["allowed_hours"]]

        if params.get("or_range") is None:
            # no tocar si ya existe
            pass
        else:
            st.session_state["lab_or_range"] = tuple(params["or_range"])

        if params.get("atr_range") is None:
            pass
        else:
            st.session_state["lab_atr_range"] = tuple(params["atr_range"])

        st.session_state["__turbo_applied"] = True
        st.rerun()

    # ---------------------------------------
    # UI: elegir modo + objetivo + generar
    # ---------------------------------------
    mode = st.radio(
        "Modo",
        ["A ‚Äî 1 click (r√°pido)", "B ‚Äî Lab experiment (muchas combinaciones)"],
        horizontal=True,
        key="turbo_mode_select",
    )

    obj_map = {
        "üöÄ Rocket (subir PnL)": "pnl",
        "üõü Submarine (bajar DD)": "dd",
        "‚öñÔ∏è Ratio (PnL/DD)": "ratio",
        "üß™ Balance (PnL + DD + Corr)": "balance",
    }
    obj_label = st.radio(
        "Objetivo",
        list(obj_map.keys()),
        horizontal=True,
        key="turbo_obj_select",
    )
    objective = obj_map[obj_label]

    top_n = st.slider("Cu√°ntos presets mostrar", 3, 20, 10, 1, key="turbo_topn")

    # -------------------------------------------------
    # Ejecutar b√∫squeda (A: acotada, B: m√°s grande)
    # -------------------------------------------------
    run_btn_label = "üöÄ Generar presets (A)" if mode.startswith("A") else "üß™ Generar combos (B)"
    run = st.button(run_btn_label, use_container_width=True)

    if run:
        grid = _build_grid(mode=("A" if mode.startswith("A") else "B"))

        # construye combinaciones
        combos = []
        for mt in grid["max_trades"]:
            for ml in grid["max_losses"]:
                for sbl in grid["stop_big_loss"]:
                    for sbw in grid["stop_big_win"]:
                        for d in grid["dirs"]:
                            for h in grid["hours"]:
                                for or_r in grid["or_ranges"]:
                                    for atr_r in grid["atr_ranges"]:
                                        combos.append(dict(
                                            max_trades_per_day=mt,
                                            max_consecutive_losses=ml,
                                            stop_after_big_loss=sbl,
                                            stop_after_big_win=sbw,
                                            allowed_dirs=d,
                                            allowed_hours=h,
                                            or_range=or_r,
                                            atr_range=atr_r,
                                        ))

        # limita por seguridad
        hard_cap = 2500 if mode.startswith("A") else 12000
        if len(combos) > hard_cap:
            random.seed(7)
            combos = random.sample(combos, hard_cap)

        fun_msgs = [
            "üî¨ Mezclando pociones cuantitativas‚Ä¶",
            "üß™ Cargando combustible para el cohete‚Ä¶",
            "üß† Buscando el combo menos doloroso para tu DD‚Ä¶",
            "üõ∞Ô∏è Calibrando la nave: PnL arriba, DD abajo‚Ä¶",
            "ü•∑ Filtrando ruido como un ninja‚Ä¶",
        ]

        progress = st.progress(0)
        with st.spinner(random.choice(fun_msgs)):
            scored = []
            total = max(1, len(combos))
            for i, p in enumerate(combos, start=1):
                df_sim = _filter_df_params(df_real, p)
                m = _compute_metrics(df_sim)

                # confianza m√≠nima: evita presets con poqu√≠simos trades
                if m["n"] < 10:
                    continue

                s = _score(m, objective)
                scored.append((s, m, p))

                if i % 50 == 0 or i == total:
                    progress.progress(min(1.0, i / total))

            progress.progress(1.0)

        if len(scored) == 0:
            st.error("No encontr√© presets confiables (n>=10). Prueba Modo B o relaja el grid.")
        else:
            scored.sort(key=lambda x: x[0], reverse=True)
            best = scored[:top_n]

            st.markdown("#### üßæ Top presets (listos para aplicar)")
            st.caption("Tip: si un preset se ve *demasiado* bueno con muy pocos trades, desconf√≠a (por eso exigimos n‚â•10).")

            # guarda para no recalcular si expandes/colapsas
            st.session_state["turbo_last_results"] = dict(
                mode=mode,
                objective=objective,
                results=best,
                base=base_m,
            )

    # ---------------------------------------
    # Mostrar resultados guardados (si existen)
    # ---------------------------------------
    if "turbo_last_results" in st.session_state:
        res = st.session_state["turbo_last_results"]
        best = res["results"]
        base = res["base"]

        for rank, (s, m, p) in enumerate(best, start=1):
            icon = "üöÄ" if objective == "pnl" else ("üõü" if objective == "dd" else ("‚öñÔ∏è" if objective == "ratio" else "üß™"))
            title = f"{icon} Preset #{rank} ‚Äî { _make_label(p) }"

            c1, c2, c3, c4, c5 = st.columns([1.6, 1, 1, 1, 1])
            with c1:
                st.markdown(f"**{title}**")
                st.caption(f"Trades: **{m['n']}** | Score: **{s:,.3f}**")
            with c2:
                st.metric("PnL", f"{m['pnl']:,.0f}", f"{m['pnl']-base['pnl']:,.0f}")
            with c3:
                st.metric("DD", f"{m['dd']:,.0f}", f"{base['dd']-m['dd']:,.0f}")
            with c4:
                corr_disp = "‚Äî" if (m["corr"] is None or np.isnan(m["corr"])) else f"{m['corr']:.2f}"
                st.metric("Corr", corr_disp)
            with c5:
                if st.button("‚úÖ Aplicar", key=f"turbo_apply_{rank}"):
                    _apply_to_lab(p)

            st.divider()
with lab_right:
    st.markdown("**Filtros (opcional)**")
    base_for_lab = t.copy()  # <-- mismo universo que Resumen r√°pido

    # Aviso si faltan ENTRY (solo afecta a filtros que dependan de ENTRY/OR/EWO/ATR)
    missing_entry = int(base_for_lab["entry_time"].isna().sum()) if ("entry_time" in base_for_lab.columns) else 0
    if missing_entry > 0:
        st.warning(f"{missing_entry} operaciones no tienen ENTRY. En esas no se conoce Compra/Venta ni OR/EWO/ATR/DeltaRatio; "
                   "solo se podr√°n filtrar por hora usando EXIT como respaldo.", icon="‚ö†Ô∏è")

    filtered, filter_notes = _apply_filters(base_for_lab)

    st.write(f"Trades tras filtros: **{len(filtered)}** (de {len(base_for_lab)})")
    if filter_notes:
        st.caption("Filtros activos: " + ", ".join(filter_notes))
    else:
        st.caption("Filtros activos: ninguno (equivale al Resumen r√°pido).")
# Simulaci√≥n
if filtered is None or filtered.empty:
    st.info("Con los filtros actuales no quedan trades para simular.")
else:
    sim_kept, stops_df = _simulate_daily_rules(filtered, max_loss, max_profit, max_trades, max_consec_losses, stop_big_loss, stop_big_win)

    # Comparativa principal: real vs simulado (filtros + reglas)
    
    # ------------------------------------------------------------
    # Comparativa principal: REAL (historial) vs SIMULADO (real + filtros + reglas)
    # ------------------------------------------------------------
    real_df = base_for_lab
    cand_df = filtered        # candidatos tras filtros
    sim_df  = sim_kept        # candidatos tras reglas diarias

    n_real = int(len(real_df))
    n_cand = int(len(cand_df))
    n_sim  = int(len(sim_df))

    omit_filtros = max(0, n_real - n_cand)
    omit_reglas  = max(0, n_cand - n_sim)

    pnl_real = float(real_df["tradeRealized"].fillna(0).sum()) if ("tradeRealized" in real_df.columns and len(real_df)) else 0.0
    pnl_sim  = float(sim_df["tradeRealized"].fillna(0).sum()) if ("tradeRealized" in sim_df.columns and len(sim_df)) else 0.0

    pf_real = profit_factor(real_df) if len(real_df) else np.nan
    pf_sim  = profit_factor(sim_df)  if len(sim_df)  else np.nan

    st.markdown("### üìä Resultados del Lab (real vs simulado)")
    # Defaults defensivos (evita NameError si no se calculan a√∫n)
    dd_base_f = np.nan
    dd_sim_mag = np.nan

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("Trades reales", f"{n_real}")
    c2.metric("Trades simulados", f"{n_sim}", delta=f"{n_sim - n_real}")
    c3.metric("PnL real ($)", f"{pnl_real:.0f}")
    c4.metric("PnL simulado ($)", f"{pnl_sim:.0f}", delta=f"{(pnl_sim - pnl_real):.0f}")
    c5.metric("PF real / sim", f"{fmt(pf_real,2)} / {fmt(pf_sim,2)}")

    d1, d2, d3 = st.columns(3)
    d1.metric("Omitidos por filtros", f"{omit_filtros}")
    d2.metric("Omitidos por reglas", f"{omit_reglas}")
    dias_cortados = int(stops_df["fecha"].nunique()) if (stops_df is not None and not stops_df.empty and "fecha" in stops_df.columns) else 0
    d3.metric("D√≠as 'cortados' (reglas)", f"{dias_cortados}")

    # Drawdown (aprox) por curva de equity
    def _equity_df(df_):
        z = df_.copy()
        z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
        z["equity"] = z["tradeRealized"].fillna(0).cumsum()
        z["equity_peak"] = z["equity"].cummax()
        z["drawdown"] = z["equity"] - z["equity_peak"]
        return z

    real_eq = _equity_df(real_df) if len(real_df) else pd.DataFrame()
    sim_eq  = _equity_df(sim_df)  if len(sim_df)  else pd.DataFrame()

    dd_real = float(real_eq["drawdown"].min()) if len(real_eq) else np.nan
    dd_sim  = float(sim_eq["drawdown"].min())  if len(sim_eq)  else np.nan

    colx, coly = st.columns(2)
    colx.metric("M√°x ca√≠da real ($)", f"{abs(dd_real):.0f}" if not np.isnan(dd_real) else "‚Äî")
    coly.metric("M√°x ca√≠da sim ($)",  f"{abs(dd_sim):.0f}"  if not np.isnan(dd_sim)  else "‚Äî",
                delta=f"{(abs(dd_real) - abs(dd_sim)):.0f}" if (not np.isnan(dd_real) and not np.isnan(dd_sim)) else None)

    st.caption("Nota: el **simulado** aplica tus filtros (selectividad) y luego reglas diarias (corte). "
               "Por eso puede tener menos trades que lo real. Para que coincida 1:1, deja filtros en 'todo' y reglas en 0.")

    # Equity curve
    st.markdown("#### Curva de equity (real vs simulado)")
    if len(real_eq) and len(sim_eq) and ("exit_time" in real_eq.columns) and ("exit_time" in sim_eq.columns):
        real_plot = real_eq[["exit_time","equity"]].rename(columns={"equity":"Equity real"})
        sim_plot  = sim_eq[["exit_time","equity"]].rename(columns={"equity":"Equity sim"})
        plot_df = pd.merge_asof(real_plot.sort_values("exit_time"),
                                sim_plot.sort_values("exit_time"),
                                on="exit_time", direction="nearest", tolerance=pd.Timedelta("1D"))
        plot_df = plot_df.sort_values("exit_time")
        fig = px.line(plot_df, x="exit_time", y=["Equity real","Equity sim"], title="Equity ($)")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No hay datos suficientes para comparar curvas de equity.")
# Impacto de las reglas (en vez de solo frecuencia)
    if stops_df is not None and not stops_df.empty:
        st.markdown("#### ¬øQu√© regla detuvo el d√≠a y qu√© impacto tuvo?")

        # Construimos, por d√≠a, la secuencia de PnL en el orden real de entrada
        _lab_base = filtered.copy()
        _time_col = "entry_time" if "entry_time" in _lab_base.columns else "exit_time"
        _lab_base = _lab_base[_lab_base[_time_col].notna()].copy()
        _lab_base = _lab_base.sort_values(_time_col)
        _lab_base["lab_day"] = _lab_base[_time_col].dt.date

        def _day_dd_mag(pnls):
            if pnls is None or len(pnls) == 0:
                return 0.0
            c = np.cumsum(pnls)
            peak = np.maximum.accumulate(c)
            dd = c - peak
            return float(abs(np.min(dd))) if len(dd) else 0.0

        day_to_pnls = {}
        for d, subd in _lab_base.groupby("lab_day"):
            pnls = subd["tradeRealized"].fillna(0).astype(float).tolist()
            day_to_pnls[d] = pnls

        enriched = stops_df.copy()

        # Enriquecemos con "qu√© PnL qued√≥ fuera" y "mejora de DD intrad√≠a" (aprox)
        pnl_total_base = []
        pnl_omitido = []
        delta_pnl = []
        dd_day_base = []
        dd_day_sim = []
        delta_dd = []
        stop_ahorra = []

        for _, r in enriched.iterrows():
            d = r["fecha"]
            taken = int(r.get("trades_ejecutados", 0) or 0)
            pnls = day_to_pnls.get(d, [])
            base_total = float(np.sum(pnls)) if pnls else 0.0
            kept_total = float(np.sum(pnls[:taken])) if pnls else 0.0
            skipped = base_total - kept_total              # lo que "se pierde" por cortar
            d_pnl = kept_total - base_total                # impacto vs base (positivo = mejora)

            dd_b = _day_dd_mag(pnls)
            dd_s = _day_dd_mag(pnls[:taken])
            d_dd = dd_b - dd_s                             # positivo = reduce ca√≠da intrad√≠a

            pnl_total_base.append(base_total)
            pnl_omitido.append(skipped)
            delta_pnl.append(d_pnl)
            dd_day_base.append(dd_b)
            dd_day_sim.append(dd_s)
            delta_dd.append(d_dd)
            stop_ahorra.append(skipped < 0)                # si lo omitido era negativo, el corte evit√≥ p√©rdidas

        enriched["pnl_total_dia_base"] = pnl_total_base
        enriched["pnl_omitido_por_corte"] = pnl_omitido
        enriched["delta_pnl_vs_base"] = delta_pnl
        enriched["dd_dia_base"] = dd_day_base
        enriched["dd_dia_sim"] = dd_day_sim
        enriched["mejora_dd_dia"] = delta_dd
        enriched["evito_perdidas"] = stop_ahorra

        # Resumen por motivo (lo realmente √∫til)
        impact = (
            enriched.groupby("motivo", as_index=False)
            .agg(
                dias=("fecha", "count"),
                trades_omitidos=("trades_filtrados_por_stop", "sum"),
                delta_pnl_total=("delta_pnl_vs_base", "sum"),
                delta_pnl_prom=("delta_pnl_vs_base", "mean"),
                mejora_dd_total=("mejora_dd_dia", "sum"),
                mejora_dd_prom=("mejora_dd_dia", "mean"),
                pct_evito_perdidas=("evito_perdidas", "mean"),
            )
        )
        impact["pct_evito_perdidas"] = (impact["pct_evito_perdidas"] * 100).round(0)

        # Gr√°ficos de impacto (PnL y DD) ‚Äî mucho m√°s interpretables que "frecuencia"
        leftg, rightg = st.columns(2)

        with leftg:
            st.markdown("**Impacto en PnL al cortar el d√≠a**")
            figp = px.bar(
                impact.sort_values("delta_pnl_total"),
                x="motivo",
                y="delta_pnl_total",
                color="delta_pnl_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("delta_pnl_total")["delta_pnl_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="ŒîPnL total vs base ($) ‚Äî positivo = mejora",
            )
            figp.update_layout(xaxis_title="Regla", yaxis_title="ŒîPnL ($)")
            st.plotly_chart(figp, use_container_width=True)

        with rightg:
            st.markdown("**Impacto en Drawdown intrad√≠a (aprox.)**")
            figd = px.bar(
                impact.sort_values("mejora_dd_total"),
                x="motivo",
                y="mejora_dd_total",
                color="mejora_dd_total",
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0,
                text=impact.sort_values("mejora_dd_total")["mejora_dd_total"].round(0).astype(int),
                hover_data={"dias": True, "trades_omitidos": True, "pct_evito_perdidas": True},
                title="Mejora DD total ($) ‚Äî positivo = reduce ca√≠das",
            )
            figd.update_layout(xaxis_title="Regla", yaxis_title="Mejora DD ($)")
            
            st.plotly_chart(figd, use_container_width=True)

        # Relaci√≥n entre reglas: trade-off PnL vs reducci√≥n de drawdown (visi√≥n de cuadrantes)
        if len(impact) >= 1:
            impact_sc = impact.copy()
            def _quad(row):
                dp = float(row.get("delta_pnl_total", 0) or 0)
                dd = float(row.get("mejora_dd_total", 0) or 0)
                if dp >= 0 and dd >= 0:
                    return "Mejora PnL y reduce DD"
                if dp < 0 and dd >= 0:
                    return "Reduce DD pero cuesta PnL"
                if dp >= 0 and dd < 0:
                    return "Mejora PnL pero empeora DD"
                return "Empeora ambos"
            impact_sc["cuadrante"] = impact_sc.apply(_quad, axis=1)

            st.markdown("**Mapa PnL vs Drawdown por regla (trade‚Äëoff)**")
            figs = px.scatter(
                impact_sc,
                x="delta_pnl_total",
                y="mejora_dd_total",
                size="dias" if "dias" in impact_sc.columns else None,
                color="cuadrante",
                hover_name="motivo",
                hover_data={
                    "dias": True,
                    "trades_omitidos": True,
                    "pct_evito_perdidas": True,
                    "delta_pnl_total": ":.0f",
                    "mejora_dd_total": ":.0f",
                },
                labels={
                    "delta_pnl_total": "ŒîPnL vs base ($)",
                    "mejora_dd_total": "Mejora DD total ($)",
                    "dias": "D√≠as activada",
                },
                title="Cada punto = una regla. Derecha/arriba = mejor. Tama√±o = d√≠as activada.",
            )
            figs.add_vline(x=0, line_dash="dash", opacity=0.4)
            figs.add_hline(y=0, line_dash="dash", opacity=0.4)
            figs.update_layout(xaxis_title="ŒîPnL ($)  (positivo = mejora)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figs, use_container_width=True)

            if len(impact_sc) >= 3:
                try:
                    r = float(np.corrcoef(impact_sc["delta_pnl_total"], impact_sc["mejora_dd_total"])[0,1])
                    st.caption(f"Correlaci√≥n entre ŒîPnL y Mejora DD (entre reglas): r = {r:.2f}. "
                               "Con pocas reglas, √∫salo solo como referencia visual.")
                except Exception:
                    pass

        st.caption(

            "Interpretaci√≥n: **ŒîPnL** positivo significa que cortar evit√≥ m√°s p√©rdidas de las que dej√≥ pasar. "
            "**Mejora DD** positiva significa menor ca√≠da intrad√≠a en los d√≠as donde se activ√≥ esa regla. "
            "Esto es una aproximaci√≥n por d√≠a (no reemplaza el DD global)."
        )

        # Tabla detallada (para quien quiera auditar)
        
        # ------------------------------------------------------------
        # Extra: "What-if" por regla (una regla a la vez)
        # Esto evita confusi√≥n cuando varias reglas est√°n activas a la vez.
        # ------------------------------------------------------------
        st.markdown("#### üß© What‚Äëif por regla (una regla a la vez)")
        st.caption("Aqu√≠ se simula **cada regla por separado** (manteniendo los filtros) y se compara contra los **candidatos tras filtros**. "
                   "Sirve para ver el **trade‚Äëoff PnL vs Drawdown** sin mezclar reglas.")

        def _dd_mag_from_df(df_):
            if df_ is None or df_.empty:
                return 0.0
            z = df_.copy()
            z = z.sort_values("exit_time" if "exit_time" in z.columns else "entry_time")
            eq = z["tradeRealized"].fillna(0).astype(float).cumsum()
            peak = eq.cummax()
            dd = eq - peak
            return float(abs(dd.min())) if len(dd) else 0.0

        pnl_base_f = float(filtered["tradeRealized"].fillna(0).astype(float).sum()) if (filtered is not None and not filtered.empty) else 0.0
        dd_base_f  = _dd_mag_from_df(filtered)
        pf_base_f  = profit_factor(filtered) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else np.nan

        # Construye escenarios individuales en funci√≥n de lo que el usuario activ√≥
        scenarios = []
        if max_loss > 0:
            scenarios.append(("Max p√©rdida/d√≠a", dict(max_loss=max_loss, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_profit > 0:
            scenarios.append(("Max ganancia/d√≠a", dict(max_loss=0.0, max_profit=max_profit, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_trades > 0:
            scenarios.append(("M√°x trades/d√≠a", dict(max_loss=0.0, max_profit=0.0, max_trades=max_trades, max_consec_losses=0, stop_big_loss=False, stop_big_win=False)))
        if max_consec_losses > 0:
            scenarios.append((f"{max_consec_losses} p√©rdidas seguidas", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=max_consec_losses, stop_big_loss=False, stop_big_win=False)))
        if stop_big_loss:
            scenarios.append(("Stop‚Äëout fuerte (‚â§ -1R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=True, stop_big_win=False)))
        if stop_big_win:
            scenarios.append(("Cierre tras ganador grande (‚â• 2R)", dict(max_loss=0.0, max_profit=0.0, max_trades=0, max_consec_losses=0, stop_big_loss=False, stop_big_win=True)))

        rows = []
        for name, params in scenarios:
            sim_one, stops_one = _simulate_daily_rules(filtered, **params)
            pnl_sim_one = float(sim_one["tradeRealized"].fillna(0).astype(float).sum()) if (sim_one is not None and not sim_one.empty) else 0.0
            dd_sim_one  = _dd_mag_from_df(sim_one)
            pf_sim_one  = profit_factor(sim_one) if (sim_one is not None and not sim_one.empty and "tradeRealized" in sim_one.columns) else np.nan

            rows.append({
                "regla": name,
                "trades_sim": int(len(sim_one)) if sim_one is not None else 0,
                "dias_cortados": int(len(stops_one)) if stops_one is not None else 0,
                "delta_pnl": pnl_sim_one - pnl_base_f,
                "mejora_dd": dd_base_f - dd_sim_one,
                "pf_sim": pf_sim_one,
            })

        # Punto "Combinado" (todas las reglas activas) si hay m√°s de 1 regla
        if len(scenarios) >= 2:
            pnl_base_comb = float(filtered["tradeRealized"].sum()) if (filtered is not None and not filtered.empty and "tradeRealized" in filtered.columns) else 0.0
            pnl_sim_comb  = float(sim_kept["tradeRealized"].sum()) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else 0.0
            dd_sim_mag = _dd_mag_from_df(sim_kept) if (sim_kept is not None and not sim_kept.empty) else 0.0
            cut_days_total = int(stops_df["day"].nunique()) if (stops_df is not None and not stops_df.empty and "day" in stops_df.columns) else 0
            rows.append({
                "regla": "Combinado (todas)",
                "trades_sim": int(len(sim_kept)) if sim_kept is not None else 0,
                "dias_cortados": cut_days_total,
                "delta_pnl": pnl_sim_comb - pnl_base_comb,
                "mejora_dd": dd_base_f - dd_sim_mag,
                "pf_sim": profit_factor(sim_kept) if (sim_kept is not None and not sim_kept.empty and "tradeRealized" in sim_kept.columns) else np.nan,
            })


        if rows:
            wf = pd.DataFrame(rows)
            def _quad2(r):
                dp = float(r["delta_pnl"])
                ddm = float(r["mejora_dd"])
                if dp >= 0 and ddm >= 0: return "‚úÖ Mejora PnL y DD"
                if dp < 0 and ddm >= 0:  return "üü° Reduce DD pero cuesta PnL"
                if dp >= 0 and ddm < 0:  return "üü† Mejora PnL pero empeora DD"
                return "‚ùå Empeora ambos"
            wf["cuadrante"] = wf.apply(_quad2, axis=1)

            # Gr√°fico trade-off (m√°s estable con muchas reglas)
            figwf = px.scatter(
                wf,
                x="delta_pnl",
                y="mejora_dd",
                size="dias_cortados",
                color="cuadrante",
                hover_name="regla",
                hover_data={"trades_sim": True, "dias_cortados": True, "pf_sim": True},
                title="Mapa (what‚Äëif) por regla ‚Äî ŒîPnL vs mejora DD (cada regla por separado)",
            )
            figwf.add_vline(x=0, line_dash="dash", opacity=0.4)
            figwf.add_hline(y=0, line_dash="dash", opacity=0.4)

            # Asegura que el 0 siempre sea visible (evita ejes ‚Äúpegados‚Äù a un lado)
            try:
                xmin = float(wf["delta_pnl"].min()); xmax = float(wf["delta_pnl"].max())
                ymin = float(wf["mejora_dd"].min()); ymax = float(wf["mejora_dd"].max())
                padx = max(100.0, (xmax - xmin) * 0.15)
                pady = max(100.0, (ymax - ymin) * 0.15)
                figwf.update_xaxes(range=[min(xmin, 0.0) - padx, max(xmax, 0.0) + padx])
                figwf.update_yaxes(range=[min(ymin, 0.0) - pady, max(ymax, 0.0) + pady])
            except Exception:
                pass

            figwf.update_layout(xaxis_title="ŒîPnL vs base ($)  (positivo = mejor)", yaxis_title="Mejora DD ($)  (positivo = reduce ca√≠das)")
            st.plotly_chart(figwf, use_container_width=True)

            with st.expander("Ver tabla (what‚Äëif por regla)"):
                wf2 = wf.sort_values(["cuadrante","mejora_dd","delta_pnl"], ascending=[True, False, False]).copy()
                wf2["delta_pnl"] = wf2["delta_pnl"].round(0).astype(int)
                wf2["mejora_dd"] = wf2["mejora_dd"].round(0).astype(int)
                st.dataframe(wf2[["regla","delta_pnl","mejora_dd","dias_cortados","trades_sim","pf_sim","cuadrante"]], use_container_width=True, hide_index=True)

            # Consejo r√°pido autom√°tico
            best = wf[wf["regla"] != "Combinado (todas)"].copy()
            if not best.empty and (best["dias_cortados"].sum() > 0):
                cand = best.sort_values(["mejora_dd","delta_pnl"], ascending=False).iloc[0]
                st.success(f"‚úÖ Regla con mejor equilibrio (en esta muestra): **{cand['regla']}** "
                           f"(ŒîPnL {cand['delta_pnl']:.0f}$, mejora DD {cand['mejora_dd']:.0f}$). "
                           "Ojo: valida con m√°s trades y no optimices 5 cosas a la vez.")
        else:
            st.info("Activa al menos una regla diaria para ver el 'what‚Äëif por regla'.")

        with st.expander("Ver detalle por d√≠a (qu√© se omiti√≥ al cortar)"):
            show_cols = [
                "fecha", "motivo",
                "trades_ejecutados", "trades_totales_dia", "trades_filtrados_por_stop",
                "pnl_total_dia_base", "pnl_hasta_stop", "pnl_omitido_por_corte", "delta_pnl_vs_base",
                "dd_dia_base", "dd_dia_sim", "mejora_dd_dia",
            ]
            cols_present = [c for c in show_cols if c in enriched.columns]
            cols_missing = [c for c in show_cols if c not in enriched.columns]
            if cols_missing:
                st.caption('Columnas no disponibles en este dataset: ' + ', '.join(cols_missing))
            st.dataframe(
                enriched[cols_present].sort_values(['fecha']) if cols_present else enriched.sort_values(['fecha']),
                use_container_width=True,
                hide_index=True,
            )
    else:
        st.info("Con estas reglas, no se activ√≥ ning√∫n 'corte del d√≠a'.")
    # Consejos autom√°ticos del Lab
    st.markdown("### üí° Consejos autom√°ticos (Lab)")
    if len(filtered) < 30:
        st.warning("Muestra peque√±a tras filtros: toma estas conclusiones como hip√≥tesis, no como regla.")
    if len(sim_kept) < max(10, int(0.25*len(filtered))):
        st.warning("La simulaci√≥n est√° eliminando demasiados trades. Revisa si est√°s filtrando/cortando en exceso.")

    # OJO: dd_base/dd_sim son negativos (ca√≠da desde el pico). Para comparar "mejor/peor" usamos magnitudes.
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.success("‚úÖ Menor drawdown con reglas: buen candidato para un 'Daily Guard' realista.")
    if (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.warning("‚ö†Ô∏è El drawdown empeor√≥ en la simulaci√≥n: estas reglas podr√≠an estar cortando recuperaci√≥n o dejando p√©rdidas grandes.")

    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim > pf_real + 0.2 and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag > dd_base_f:
        st.info("Mejor√≥ PF pero empeor√≥ DD: t√≠pico cuando eliminas muchos trades peque√±os pero te quedas con p√©rdidas grandes. Revisa filtros/horarios.")
    if (not np.isnan(pf_real)) and (not np.isnan(pf_sim)) and pf_sim < pf_real and (not np.isnan(dd_base_f)) and (not np.isnan(dd_sim_mag)) and dd_sim_mag < dd_base_f:
        st.info("Baj√≥ PF pero tambi√©n baj√≥ el DD: a veces vale la pena si tu objetivo es estabilidad (menos estr√©s / menos reset).")
# Resumen final (muy user-friendly)
# ============================================================
st.subheader("üßæ Resumen final y recomendaciones")

st.write(
    "Este bloque resume lo m√°s accionable. No es una verdad absoluta: con muestra peque√±a, √∫salo para orientar, no para 'sobre-optimizar'."
)

# 1) Salud general
pf_val = summary.get("pf", np.nan)
exp_val = summary.get("expectancy", np.nan)
if pf_val == pf_val and pf_val < 1.0:
    st.error("üö® Salud general: Profit Factor < 1 (pierde). Prioridad: filtrar condiciones malas antes de ajustar targets.")
elif exp_val == exp_val and exp_val < 0:
    st.warning("‚ö†Ô∏è Salud general: promedio por trade < 0. Revisa filtros (horario/volatilidad/tendencia) y disciplina de salida.")
else:
    st.success("‚úÖ Salud general: no se ve rojo inmediato (seg√∫n esta muestra). Ahora toca mejorar consistencia.")

# 2) RR y estructura
if "rr" in t.columns and t["rr"].notna().any():
    _rr = t[t["rr"].notna()]["rr"].astype(float)
    rr_median = float(_rr.median())
    rr_mean = float(_rr.mean())
    rr_ge2 = float((_rr >= 2).mean() * 100)
    rr_le_1 = float((_rr <= -1).mean() * 100)

    st.markdown("**Estructura RR**")
    st.write(f"- RR mediana: {rr_median:.2f} | RR promedio: {rr_mean:.2f} | %RR‚â•2: {rr_ge2:.1f}% | %RR‚â§-1: {rr_le_1:.1f}%")
    if rr_mean > 0 and rr_median < 0:
        st.info("Promedio > 0 y mediana < 0: dependes de pocos ganadores grandes. Enf√≥cate en reducir stop-outs feos sin matar tus runners.")
    if rr_le_1 > 15:
        st.warning("‚ö†Ô∏è %RR‚â§-1 alto: est√°s tomando muchas p√©rdidas completas. Buen objetivo: mejorar confirmaci√≥n/evitar chop/horas malas.")

# 3) Manejo de ganadores (captura/devoluci√≥n)
if "captura_pct" in t.columns and t["captura_pct"].notna().sum() >= 5:
    cap_med = float(t["captura_pct"].dropna().median())
    gb_med = float(t["devolucion_pct"].dropna().median()) if "devolucion_pct" in t.columns and t["devolucion_pct"].notna().any() else np.nan
    st.markdown("**Manejo de ganadores**")
    st.write(f"- Captura mediana: {cap_med*100:.0f}%" + (f" | Devoluci√≥n mediana: {gb_med*100:.0f}%" if gb_med == gb_med else ""))
    if cap_med < 0.35:
        st.warning("‚ö†Ô∏è Captura baja: est√°s dejando mucho en la mesa. Ajusta trailing/TP parcial o reglas de salida temprana.")
    if gb_med == gb_med and gb_med > 0.60:
        st.warning("‚ö†Ô∏è Devoluci√≥n alta: el trade va bien, pero no proteges a tiempo. Prueba trailing m√°s agresivo cuando ya est√©s en +1R.")

# 4) Motivos de salida (top problema)
if "exitReason" in t.columns and t["exitReason"].notna().any():
    _tbl = group_metrics(t, "exitReason", min_trades=max(5, min_trades//2), recommended_trades=recommended_trades)
    if not _tbl.empty:
        worst = _tbl.sort_values("Promedio por trade").iloc[0]
        if float(worst["Promedio por trade"]) < 0:
            st.markdown("**Motivo de salida a vigilar**")
            st.write(f"- {worst['Grupo']}: promedio {float(worst['Promedio por trade']):.1f} con {int(worst['Trades'])} trades")

# 5) Horarios (si hay)
if hour_tbl is not None and not hour_tbl.empty:
    best = hour_tbl.iloc[0]
    st.markdown("**Horario con mejor Score (ponderado)**")
    st.write(f"- {best['Grupo']} | Trades={int(best['Trades'])} | PF={float(best['Profit Factor']):.2f} | Promedio={float(best['Promedio por trade']):.1f}")
    if int(best["Trades"]) < min_trades * 2:
        st.info("Nota: el mejor horario a√∫n tiene poca muestra. Confirma con m√°s meses antes de convertirlo en regla.")

recommend_settings_block(known, min_trades=min_trades, recommended_trades=recommended_trades)

st.markdown("**Siguientes pasos recomendados (orden)**")
st.write("1) Primero elimina lo rojo: horarios peores + condiciones con PF<1 (muestra üü¢).")
st.write("2) Luego ajusta manejo: reduce devoluciones grandes y evita stop-outs completos recurrentes.")
st.write("3) Al final optimiza targets/trailing: no mates los winners grandes si tu edge depende de ellos.")

# ============================================================
# Trades table
# ============================================================
with st.expander("üìÑ Tabla de trades (una fila por atmId)", expanded=False):
    cols_show = [c for c in [
        "exit_time", "entry_time", "lado", "outcome", "tradeRealized",
        "maxUnreal", "minUnreal", "exitReason", "forcedCloseReason",
        "orSize", "ewo", "atr", "deltaRatio", "atrSlMult", "tp1R", "tp2R",
        "duration_sec"
    ] if c in t.columns]
    st.dataframe(t[cols_show].sort_values("exit_time", ascending=False), use_container_width=True)

st.caption(
    "Tip: para eliminar ‚ÄúSin datos (falt√≥ ENTRY)‚Äù, aseg√∫rate de cargar meses que contengan los ENTRY y EXIT juntos. "
    "Si quieres 100% robustez, a√±ade `dir` tambi√©n en el EXIT (en NinjaScript) o guarda logs en bloques por trade."
)
